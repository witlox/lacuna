{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Lacuna","text":"<p>Protected space for data governance, lineage, and privacy-aware operations</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>Organizations deploying local LLMs and data platforms face a critical challenge: How do you enable self-service data access while maintaining governance, lineage tracking, and compliance?</p> <p>Current solutions force a choice between:</p> <ul> <li>Strict centralized control \u2192 Bottlenecks, slow innovation</li> <li>Complete self-service \u2192 Compliance violations, data leaks, audit failures</li> </ul> <p>Lacuna solves this by creating a protected space where sensitive data stays secure while enabling self-service access within compliance boundaries.</p>"},{"location":"#what-is-lacuna","title":"What is Lacuna?","text":"<p>Lacuna is a policy-aware data governance engine that provides:</p> <ul> <li> <p> Automatic Classification</p> <p>Three-layer pipeline (heuristics \u2192 embeddings \u2192 LLM) classifies data operations in real-time</p> </li> <li> <p> Policy Enforcement</p> <p>Real-time policy evaluation with clear, actionable feedback to users</p> </li> <li> <p> Complete Lineage</p> <p>Automatic tracking across transformations, joins, and exports</p> </li> <li> <p> Audit Compliance</p> <p>ISO 27001-compliant logs with tamper-evident hash chains</p> </li> <li> <p> Easy Integration</p> <p>Works with dbt, Databricks, Snowflake, and Open Policy Agent</p> </li> <li> <p> High Performance</p> <p>&lt;10ms classification for 98% of operations</p> </li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#three-layer-classification-pipeline","title":"Three-Layer Classification Pipeline","text":"<p>Lacuna achieves 98%+ throughput at &lt;10ms latency through an intelligent pipeline:</p> <ul> <li>Layer 1: Heuristics - Regex patterns and keyword matching handle 90% of operations in &lt;1ms</li> <li>Layer 2: Embeddings - Semantic similarity for 8% of operations in ~10ms</li> <li>Layer 3: LLM Reasoning - Complex decisions for 2% of operations in ~200ms</li> </ul>"},{"location":"#sensitivity-tiers","title":"Sensitivity Tiers","text":"<p>All data is classified into three tiers:</p> Tier Definition Examples PROPRIETARY Competitive advantage or confidentiality concerns Customer PII, proprietary algorithms, strategic plans INTERNAL Within organization but not sensitive Internal tooling, team processes, general analytics PUBLIC Publicly available or publishable Documentation, open-source code, published research <p>Classification Inheritance</p> <p>When data is joined or transformed, the most restrictive tier propagates. For example: <code>PUBLIC + PROPRIETARY = PROPRIETARY</code></p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#development-mode","title":"Development Mode","text":"<p>Try Lacuna locally with zero external dependencies:</p> <pre><code># Clone and install\ngit clone https://github.com/witlox/lacuna.git\ncd lacuna\npip install -e .\n\n# Start in dev mode (uses SQLite, no external dependencies)\nlacuna dev\n\n# Open in browser\n# API Docs: http://127.0.0.1:8000/docs\n# User Dashboard: http://127.0.0.1:8000/user/dashboard\n# Admin Dashboard: http://127.0.0.1:8000/admin/\n</code></pre>"},{"location":"#production-deployment","title":"Production Deployment","text":"<p>For production with full features:</p> DockerDocker ComposeKubernetespip <pre><code>docker pull ghcr.io/witlox/lacuna:latest\ndocker run -d -p 8000:8000 ghcr.io/witlox/lacuna:latest\n</code></pre> <pre><code># Production stack\ndocker compose -f deploy/docker/docker-compose.prod.yaml up -d\n\n# High-availability with replication\ndocker compose -f deploy/docker/docker-compose.ha.yaml up -d\n</code></pre> <pre><code>helm install lacuna ./deploy/helm/lacuna \\\n  -f deploy/helm/lacuna/values-production.yaml\n</code></pre> <pre><code>pip install lacuna\nlacuna serve --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#real-time-policy-enforcement","title":"Real-Time Policy Enforcement","text":"<pre><code># User's notebook\nimport pandas as pd\n\ncustomers = pd.read_csv(\"customers.csv\")\n# \u2713 Lacuna detects: PII data loaded, context updated\n\nanalysis = customers.merge(sales, on=\"customer_id\")\n# \u2713 Lacuna classifies: PII propagates through join\n\nanalysis.to_csv(\"~/Downloads/export.csv\")\n# \u2717 Lacuna blocks with clear message:\n\"\"\"\n\u274c Governance Policy Violation\n\nAction: Export to ~/Downloads/export.csv\nReason: Cannot export PII data to unmanaged location\nClassification: PROPRIETARY (inherited from customers.csv)\nTags: PII, GDPR, FINANCIAL\n\nAlternatives:\n1. Use anonymized version: analysis_anon = anonymize(analysis, ['customer_id', 'email'])\n2. Save to governed location: analysis.to_csv(\"/governed/workspace/analysis.csv\")\n3. Request exception: https://governance.example.com/exception\n\nPolicy: P-2024-001 (PII Export Restrictions)\nSteward: data-governance@example.com\n\"\"\"\n</code></pre>"},{"location":"#automated-lineage-tracking","title":"Automated Lineage Tracking","text":"<pre><code>from lacuna import LineageTracker\n\n# Query lineage\nlineage = LineageTracker.get_lineage(\"analysis.csv\")\n\nprint(lineage.to_graph())\n\"\"\"\nanalysis.csv (PROPRIETARY, tags: PII, GDPR, FINANCIAL)\n\u251c\u2500 customers.csv (PROPRIETARY, tags: PII, GDPR)\n\u2502  \u2514\u2500 raw.customer_master (PROPRIETARY, tags: PII)\n\u2502     \u2514\u2500 salesforce.contacts (PROPRIETARY, tags: PII)\n\u2514\u2500 sales.csv (INTERNAL, tags: FINANCIAL)\n   \u2514\u2500 raw.transactions (INTERNAL, tags: FINANCIAL)\n\"\"\"\n\n# Check downstream impact\ndownstream = LineageTracker.get_downstream(\"customers.csv\")\nprint(f\"Changing customers.csv will impact {len(downstream)} artifacts\")\n</code></pre>"},{"location":"#iso-27001-compliance","title":"ISO 27001 Compliance","text":"<pre><code>from lacuna.audit import ComplianceReporter\n\n# Generate ISO 27001 A.9.4 report (Access Control)\nreport = ComplianceReporter.generate_a_9_4_report(\n    start_date=\"2025-01-01\",\n    end_date=\"2025-12-31\"\n)\n\n# Report includes:\n# - All data access attempts (successful and failed)\n# - Classification decisions with reasoning\n# - Policy violations with user responses\n# - Administrative actions\n# - Complete audit trail with hash chain verification\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[User Data Operation] --&gt; B[Operation Interceptor]\n    B --&gt; C[Classification Pipeline]\n    C --&gt; D[Layer 1: Heuristics&lt;br/&gt;&lt;1ms, 90%]\n    C --&gt; E[Layer 2: Embeddings&lt;br/&gt;~10ms, 8%]\n    C --&gt; F[Layer 3: LLM&lt;br/&gt;~200ms, 2%]\n    D --&gt; G[Lineage Engine]\n    E --&gt; G\n    F --&gt; G\n    G --&gt; H[Policy Engine OPA]\n    H --&gt; I[Audit Logger]\n    I --&gt; J[User Feedback]</code></pre>"},{"location":"#why-lacuna","title":"Why Lacuna?","text":""},{"location":"#the-name","title":"The Name","text":"<p>Lacuna (Latin): A gap, cavity, or protected space</p> <p>In anatomy, a lacuna is a small cavity that protects cells. In manuscripts, it's a missing section that reveals what's intentionally kept private.</p> <p>In data governance, Lacuna creates the protected space where:</p> <ul> <li>Sensitive data stays secure</li> <li>Appropriate data flows freely</li> <li>Boundaries are enforced automatically</li> </ul>"},{"location":"#the-market-gap","title":"The Market Gap","text":"<p>Existing solutions address either data catalogs, access control, DLP, or policy engines - but none combine all four.</p> <p>Lacuna uniquely provides:</p> <ul> <li>Real-time operation interception</li> <li>Automatic classification with lineage</li> <li>Policy enforcement with user feedback</li> <li>ISO 27001-compliant audit logging</li> <li>Self-service model with central governance</li> </ul>"},{"location":"#who-this-is-for","title":"Who This Is For","text":"<p>Organizations:</p> <ul> <li>Enterprises with data governance requirements</li> <li>Regulated industries (finance, healthcare, government)</li> <li>Companies with proprietary data assets</li> <li>Teams deploying local data platforms</li> </ul> <p>Users:</p> <ul> <li>Data analysts (self-service access)</li> <li>Data engineers (building pipelines)</li> <li>Data governance teams (defining policies)</li> <li>Compliance officers (audit reports)</li> <li>Security teams (monitoring access)</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p> Quick Start Guide</p> <p>Get up and running in minutes</p> </li> <li> <p> User Guide</p> <p>Learn how to use Lacuna's features</p> </li> <li> <p> Architecture</p> <p>Understand how Lacuna works</p> </li> <li> <p> API Reference</p> <p>Integrate Lacuna into your stack</p> </li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub: witlox/lacuna</li> <li>Issues: Report bugs or request features</li> <li>Discussions: Ask questions</li> </ul>"},{"location":"#license","title":"License","text":"<p>Lacuna is licensed under the Apache 2.0 License.</p>"},{"location":"ARCHITECTURE/","title":"Lacuna Architecture Overview","text":""},{"location":"ARCHITECTURE/#system-architecture","title":"System Architecture","text":""},{"location":"ARCHITECTURE/#high-level-components","title":"High-Level Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          User Layer                                 \u2502\n\u2502  \u2022 Jupyter Notebooks  \u2022 VS Code  \u2022 CLI  \u2022 Web Dashboard             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n                 \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Lacuna Core Engine                              \u2502\n\u2502                                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502  Operation      \u2502  \u2502 Classificat. \u2502  \u2502  Policy Engine     \u2502      \u2502\n\u2502  \u2502  Interceptor    \u2502\u2192 \u2502 Pipeline     \u2502\u2192 \u2502  (OPA)             \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502           \u2502                   \u2502                     \u2502               \u2502\n\u2502           \u2193                   \u2193                     \u2193               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502  Lineage        \u2502  \u2502  Provenance  \u2502  \u2502  Audit Logger      \u2502      \u2502\n\u2502  \u2502  Tracker        \u2502  \u2502  Capture     \u2502  \u2502  (PostgreSQL)      \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n                 \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Integration Layer                               \u2502\n\u2502  \u2022 dbt  \u2022 Databricks Unity Catalog  \u2022 Snowflake  \u2022 File Systems     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#detailed-component-architecture","title":"Detailed Component Architecture","text":""},{"location":"ARCHITECTURE/#1-operation-interceptor","title":"1. Operation Interceptor","text":"<p>Purpose: Capture all data operations before execution</p> <p>Implementations:</p> <p>File System Operations (FUSE) <pre><code>class LacunaFUSE:\n    \"\"\"Intercept file read/write operations.\"\"\"\n\n    def open(self, path: str, flags: int) -&gt; int:\n        # Before opening file\n        operation = DataOperation(\n            action=\"read\" if flags &amp; os.O_RDONLY else \"write\",\n            resource_type=\"file\",\n            resource_id=path,\n            user=get_current_user()\n        )\n\n        # Classify and check policy\n        result = lacuna.evaluate(operation)\n\n        if not result.allowed:\n            raise PermissionError(result.reasoning)\n\n        # Log and proceed\n        lacuna.audit_log(operation, result)\n        return os.open(path, flags)\n</code></pre></p> <p>Database Operations (SQLAlchemy Middleware) <pre><code>class LacunaQueryInterceptor:\n    \"\"\"Intercept SQL queries.\"\"\"\n\n    def before_cursor_execute(self, conn, cursor, statement, params, ...):\n        # Parse SQL to extract tables\n        tables = parse_sql_tables(statement)\n\n        # Classify operation\n        operation = DataOperation(\n            action=get_sql_action(statement),  # SELECT, INSERT, UPDATE\n            resource_type=\"table\",\n            resource_ids=tables,\n            user=get_current_user()\n        )\n\n        # Check policy\n        result = lacuna.evaluate(operation)\n\n        if not result.allowed:\n            raise PermissionError(f\"Query denied: {result.reasoning}\")\n</code></pre></p> <p>Jupyter Notebook (IPython Magic) <pre><code>@register_line_magic\n@register_cell_magic\ndef lacuna(line, cell=None):\n    \"\"\"Intercept notebook operations.\"\"\"\n\n    # Extract operations from code\n    operations = parse_python_code(cell or line)\n\n    # Check each operation\n    for op in operations:\n        result = lacuna.evaluate(op)\n\n        if not result.allowed:\n            # Show inline warning\n            display(HTML(format_warning(result)))\n            return\n\n    # Execute code\n    get_ipython().run_cell(cell or line)\n</code></pre></p>"},{"location":"ARCHITECTURE/#2-classification-pipeline","title":"2. Classification Pipeline","text":"<p>Three-Layer Design:</p> <pre><code>class ClassificationPipeline:\n    \"\"\"Three-layer classification with fallback.\"\"\"\n\n    def classify(self, operation: DataOperation) -&gt; Classification:\n        # Layer 1: Heuristics (&lt;1ms)\n        result = self.heuristic_classifier.classify(operation)\n        if result.confidence &gt; 0.9:\n            return result\n\n        # Layer 2: Embeddings (&lt;10ms)\n        result = self.embedding_classifier.classify(operation)\n        if result.confidence &gt; 0.8:\n            return result\n\n        # Layer 3: LLM (&lt;200ms)\n        result = self.llm_classifier.classify(operation)\n        return result\n</code></pre> <p>Layer 1: Heuristic Classifier <pre><code>class HeuristicClassifier:\n    \"\"\"Fast pattern matching.\"\"\"\n\n    def __init__(self, patterns: List[Pattern]):\n        # Compile regex patterns\n        self.patterns = [\n            (re.compile(p.regex), p.tier, p.tags)\n            for p in patterns\n        ]\n\n    def classify(self, operation: DataOperation) -&gt; Classification:\n        # Check file path\n        for regex, tier, tags in self.patterns:\n            if regex.match(operation.resource_id):\n                return Classification(\n                    tier=tier,\n                    confidence=1.0,\n                    tags=tags,\n                    reasoning=f\"Matched pattern: {regex.pattern}\"\n                )\n\n        # Check for known PII columns\n        if operation.resource_type == \"table\":\n            columns = get_table_columns(operation.resource_id)\n            pii_columns = [c for c in columns if self.is_pii_column(c)]\n\n            if pii_columns:\n                return Classification(\n                    tier=Tier.PROPRIETARY,\n                    confidence=1.0,\n                    tags=[\"PII\"],\n                    reasoning=f\"Contains PII columns: {pii_columns}\"\n                )\n\n        # No match\n        return Classification(tier=None, confidence=0.0)\n</code></pre></p> <p>Layer 2: Embedding Classifier <pre><code>class EmbeddingClassifier:\n    \"\"\"Semantic similarity matching.\"\"\"\n\n    def __init__(self, model_name: str, examples: Dict[Tier, List[str]]):\n        self.model = SentenceTransformer(model_name)\n\n        # Pre-compute embeddings for examples\n        self.example_embeddings = {}\n        for tier, texts in examples.items():\n            embeddings = self.model.encode(texts)\n            self.example_embeddings[tier] = embeddings\n\n    def classify(self, operation: DataOperation) -&gt; Classification:\n        # Create description of operation\n        description = self.describe_operation(operation)\n\n        # Compute embedding\n        query_embedding = self.model.encode([description])[0]\n\n        # Find most similar example\n        best_tier = None\n        best_similarity = 0.0\n\n        for tier, examples in self.example_embeddings.items():\n            similarities = cosine_similarity([query_embedding], examples)[0]\n            max_sim = max(similarities)\n\n            if max_sim &gt; best_similarity:\n                best_similarity = max_sim\n                best_tier = tier\n\n        return Classification(\n            tier=best_tier,\n            confidence=best_similarity,\n            reasoning=f\"Semantic similarity: {best_similarity:.2f}\"\n        )\n</code></pre></p> <p>Layer 3: LLM Classifier <pre><code>class LLMClassifier:\n    \"\"\"LLM-based reasoning for complex cases.\"\"\"\n\n    def classify(self, operation: DataOperation) -&gt; Classification:\n        # Build context\n        context = self.build_context(operation)\n\n        # Construct prompt\n        prompt = f\"\"\"\n        Classify this data operation:\n\n        Action: {operation.action}\n        Resource: {operation.resource_id}\n        User: {operation.user.role}\n        Context: {context}\n\n        Classification tiers:\n        - PROPRIETARY: Competitive secrets, PII, regulated data\n        - INTERNAL: Internal use only, not competitive\n        - PUBLIC: Publicly available or could be\n\n        Respond with JSON:\n        {{\n          \"tier\": \"PROPRIETARY\" | \"INTERNAL\" | \"PUBLIC\",\n          \"confidence\": 0.0-1.0,\n          \"reasoning\": \"explanation\",\n          \"tags\": [\"tag1\", \"tag2\"]\n        }}\n        \"\"\"\n\n        # Call LLM\n        response = self.llm.chat([\n            {\"role\": \"user\", \"content\": prompt}\n        ])\n\n        # Parse response\n        result = json.loads(response.content)\n\n        return Classification(\n            tier=Tier[result[\"tier\"]],\n            confidence=result[\"confidence\"],\n            reasoning=result[\"reasoning\"],\n            tags=result[\"tags\"]\n        )\n</code></pre></p>"},{"location":"ARCHITECTURE/#3-lineage-tracker","title":"3. Lineage Tracker","text":"<p>Purpose: Build complete data lineage graph</p> <pre><code>class LineageTracker:\n    \"\"\"Track data lineage across operations.\"\"\"\n\n    def __init__(self):\n        self.graph = nx.DiGraph()  # NetworkX directed graph\n\n    def track_operation(self, operation: DataOperation):\n        \"\"\"Record operation in lineage graph.\"\"\"\n\n        # Add nodes\n        for source in operation.sources:\n            if source not in self.graph:\n                self.graph.add_node(source, **self.get_metadata(source))\n\n        self.graph.add_node(\n            operation.destination,\n            **self.get_metadata(operation.destination)\n        )\n\n        # Add edges (sources \u2192 destination)\n        for source in operation.sources:\n            self.graph.add_edge(\n                source,\n                operation.destination,\n                operation=operation.action,\n                timestamp=datetime.now(),\n                user=operation.user.id,\n                code=operation.code  # Transformation code if available\n            )\n\n    def get_upstream(self, resource: str) -&gt; List[str]:\n        \"\"\"Get all upstream dependencies.\"\"\"\n        return list(nx.ancestors(self.graph, resource))\n\n    def get_downstream(self, resource: str) -&gt; List[str]:\n        \"\"\"Get all downstream dependencies.\"\"\"\n        return list(nx.descendants(self.graph, resource))\n\n    def get_lineage_chain(self, resource: str) -&gt; List[str]:\n        \"\"\"Get full lineage path.\"\"\"\n        # Find all paths to root nodes (sources with no parents)\n        roots = [n for n in self.graph.nodes() if self.graph.in_degree(n) == 0]\n\n        chains = []\n        for root in roots:\n            try:\n                path = nx.shortest_path(self.graph, root, resource)\n                chains.append(path)\n            except nx.NetworkXNoPath:\n                continue\n\n        return chains\n</code></pre> <p>Classification Inheritance <pre><code>class ClassificationInheritance:\n    \"\"\"Apply inheritance rules to derived data.\"\"\"\n\n    def infer_classification(\n        self,\n        operation: DataOperation,\n        source_classifications: List[Classification]\n    ) -&gt; Classification:\n        \"\"\"Infer classification for operation result.\"\"\"\n\n        if operation.action == \"join\":\n            # Maximum classification of sources\n            max_tier = max(c.tier for c in source_classifications)\n            union_tags = set()\n            for c in source_classifications:\n                union_tags.update(c.tags)\n\n            return Classification(\n                tier=max_tier,\n                tags=list(union_tags),\n                reasoning=\"Inherited maximum classification from join sources\"\n            )\n\n        elif operation.action == \"aggregate\":\n            # May downgrade if no individual-level data\n            if self.preserves_individual_data(operation):\n                # Group-by with low cardinality \u2192 individuals still identifiable\n                return max(source_classifications, key=lambda c: c.tier)\n            else:\n                # High cardinality aggregation \u2192 safe to downgrade\n                max_tier = max(c.tier for c in source_classifications)\n                downgraded = self.downgrade_tier(max_tier)\n\n                return Classification(\n                    tier=downgraded,\n                    tags=[\"DERIVED_FROM_\" + max_tier.name],\n                    reasoning=\"Downgraded due to aggregation without individual data\"\n                )\n\n        elif operation.action == \"filter\":\n            # Inherit source classification\n            return source_classifications[0]\n\n        elif operation.action == \"anonymize\":\n            # Downgrade to INTERNAL if anonymization verified\n            if self.verify_anonymization(operation):\n                return Classification(\n                    tier=Tier.INTERNAL,\n                    tags=[\"ANONYMIZED\"],\n                    reasoning=\"Anonymization verified, downgraded from PROPRIETARY\"\n                )\n            else:\n                # Keep original classification if anonymization insufficient\n                return source_classifications[0]\n\n        else:\n            # Default: inherit maximum classification\n            return max(source_classifications, key=lambda c: c.tier)\n</code></pre></p>"},{"location":"ARCHITECTURE/#4-policy-engine-opa","title":"4. Policy Engine (OPA)","text":"<p>Integration with Open Policy Agent:</p> <pre><code>class OPAPolicyEngine:\n    \"\"\"Evaluate policies using OPA.\"\"\"\n\n    def __init__(self, opa_url: str):\n        self.opa_url = opa_url\n\n    def evaluate(\n        self,\n        operation: DataOperation,\n        classification: Classification\n    ) -&gt; PolicyDecision:\n        \"\"\"Evaluate operation against policies.\"\"\"\n\n        # Build OPA input\n        input_data = {\n            \"action\": operation.action,\n            \"source\": {\n                \"classification\": classification.tier.value,\n                \"tags\": classification.tags,\n                \"lineage\": operation.lineage_chain\n            },\n            \"destination\": {\n                \"type\": operation.destination_type,\n                \"path\": operation.destination,\n                \"encrypted\": operation.destination_encrypted\n            },\n            \"user\": {\n                \"id\": operation.user.id,\n                \"role\": operation.user.role,\n                \"clearance\": operation.user.clearance,\n                \"department\": operation.user.department\n            },\n            \"context\": {\n                \"purpose\": operation.purpose,\n                \"environment\": os.getenv(\"ENVIRONMENT\", \"production\")\n            }\n        }\n\n        # Query OPA\n        response = requests.post(\n            f\"{self.opa_url}/v1/data/governance/allow\",\n            json={\"input\": input_data},\n            timeout=0.1  # 100ms timeout\n        )\n\n        result = response.json()[\"result\"]\n\n        return PolicyDecision(\n            allowed=result.get(\"allow\", False),\n            policy_id=result.get(\"policy_id\"),\n            policy_version=result.get(\"policy_version\"),\n            reasoning=result.get(\"reasoning\", \"\"),\n            alternatives=result.get(\"alternatives\", [])\n        )\n</code></pre> <p>Example OPA Policy: <pre><code>package governance\n\n# Allow export if all conditions met\nallow {\n    # Not PROPRIETARY data\n    input.source.classification != \"PROPRIETARY\"\n}\n\nallow {\n    # Or destination is approved\n    approved_destination\n}\n\nallow {\n    # Or exception granted\n    input.exception.approved == true\n}\n\n# Helper: Check approved destinations\napproved_destination {\n    input.destination.type == \"governed_storage\"\n    input.destination.encrypted == true\n}\n\napproved_destination {\n    input.destination.type == \"database\"\n    startswith(input.destination.path, \"/approved/\")\n}\n\n# Provide alternatives when denied\nalternatives[msg] {\n    not allow\n    input.source.tags[_] == \"PII\"\n    msg := \"Anonymize PII: lacuna.anonymize(data, pii_columns)\"\n}\n\nalternatives[msg] {\n    not allow\n    msg := sprintf(\"Save to governed storage: %v\", [approved_paths[0]])\n}\n\n# List of approved paths\napproved_paths := [\n    \"/governed/workspace/\",\n    \"s3://company-governed-data/\"\n]\n</code></pre></p>"},{"location":"ARCHITECTURE/#5-audit-logger","title":"5. Audit Logger","text":"<p>Tamper-Evident Logging with Hash Chains:</p> <pre><code>class AuditLogger:\n    \"\"\"ISO 27001-compliant audit logging.\"\"\"\n\n    def __init__(self, backend: AuditBackend):\n        self.backend = backend\n        self.queue = Queue()  # Async logging\n\n        # Start background writer\n        self.writer_thread = threading.Thread(\n            target=self._writer_loop,\n            daemon=True\n        )\n        self.writer_thread.start()\n\n    def log(self, event: AuditEvent):\n        \"\"\"Log audit event (non-blocking).\"\"\"\n\n        # Create audit record\n        record = AuditRecord(\n            event_id=str(uuid.uuid4()),\n            timestamp=self.get_ntp_time(),\n            event_type=event.type,\n            severity=event.severity,\n            user_id=event.user.id,\n            resource_id=event.resource_id,\n            action=event.action,\n            action_result=event.result,\n            # ... full record fields\n        )\n\n        # Queue for async write\n        self.queue.put(record)\n\n    def _writer_loop(self):\n        \"\"\"Background thread that writes batches.\"\"\"\n        batch = []\n\n        while True:\n            try:\n                # Collect batch\n                while len(batch) &lt; 100:\n                    record = self.queue.get(timeout=1.0)\n                    batch.append(record)\n            except Empty:\n                pass  # Timeout, write what we have\n\n            # Write batch\n            if batch:\n                self._write_batch(batch)\n                batch = []\n\n    def _write_batch(self, records: List[AuditRecord]):\n        \"\"\"Write batch with hash chain.\"\"\"\n\n        # Get last record hash\n        last_hash = self.backend.get_last_hash()\n\n        # Link records in batch\n        for i, record in enumerate(records):\n            if i == 0:\n                record.previous_record_hash = last_hash\n            else:\n                record.previous_record_hash = records[i-1].record_hash\n\n            # Compute this record's hash\n            record.record_hash = self._compute_hash(record)\n            last_hash = record.record_hash\n\n        # Write batch atomically\n        self.backend.write_batch(records)\n</code></pre> <p>Hash Computation: <pre><code>def _compute_hash(self, record: AuditRecord) -&gt; str:\n    \"\"\"Compute SHA-256 hash of record.\"\"\"\n\n    # Serialize record deterministically\n    data = {\n        \"event_id\": record.event_id,\n        \"timestamp\": record.timestamp.isoformat(),\n        \"event_type\": record.event_type.value,\n        \"user_id\": record.user_id,\n        \"resource_id\": record.resource_id,\n        \"action\": record.action,\n        \"action_result\": record.action_result,\n        \"previous_record_hash\": record.previous_record_hash,\n        # Include all relevant fields...\n    }\n\n    serialized = json.dumps(data, sort_keys=True)\n    return hashlib.sha256(serialized.encode()).hexdigest()\n</code></pre></p>"},{"location":"ARCHITECTURE/#data-flow-example","title":"Data Flow Example","text":"<p>Scenario: User exports customer data</p> <pre><code>1. User Code:\n   customers.to_csv(\"~/Downloads/export.csv\")\n\n2. Operation Interceptor (IPython magic):\n   \u251c\u2500 Detects: file write operation\n   \u251c\u2500 Creates DataOperation object\n   \u2514\u2500 Passes to Classification Pipeline\n\n3. Classification Pipeline:\n   \u251c\u2500 Layer 1 (Heuristics):\n   \u2502  \u251c\u2500 Checks file path patterns \u2192 no match\n   \u2502  \u2514\u2500 Checks DataFrame columns \u2192 finds \"email\", \"phone\"\n   \u2502  \u2514\u2500 Returns: PROPRIETARY (confidence: 1.0)\n   \u2502\n   \u2514\u2500 [Layers 2, 3 skipped due to high confidence]\n\n4. Lineage Tracker:\n   \u251c\u2500 Traces: customers.csv \u2192 customers DataFrame \u2192 export.csv\n   \u251c\u2500 Inherits classification: export.csv = PROPRIETARY\n   \u2514\u2500 Tags: [PII, CUSTOMER_DATA, EMAIL, PHONE]\n\n5. Policy Engine (OPA):\n   \u251c\u2500 Query: Can user export PROPRIETARY to ~/Downloads?\n   \u251c\u2500 Policy evaluation:\n   \u2502  \u251c\u2500 Check: classification != PROPRIETARY \u2192 FALSE\n   \u2502  \u251c\u2500 Check: destination approved \u2192 FALSE\n   \u2502  \u2514\u2500 Check: exception granted \u2192 FALSE\n   \u2502\n   \u2514\u2500 Decision: DENY\n      \u2514\u2500 Alternatives:\n         \u2022 \"Anonymize: lacuna.anonymize(customers, ['email', 'phone'])\"\n         \u2022 \"Save to: /governed/workspace/export.csv\"\n\n6. Audit Logger:\n   \u251c\u2500 Create audit record:\n   \u2502  \u251c\u2500 event_type: DATA_EXPORT\n   \u2502  \u251c\u2500 action_result: denied\n   \u2502  \u251c\u2500 reasoning: \"Cannot export PROPRIETARY to unmanaged location\"\n   \u2502  \u2514\u2500 previous_record_hash: &lt;hash of last record&gt;\n   \u2502\n   \u251c\u2500 Compute hash chain:\n   \u2502  \u2514\u2500 record_hash: SHA256(record + previous_hash)\n   \u2502\n   \u2514\u2500 Write to PostgreSQL (async)\n\n7. User Feedback:\n   Display inline error with alternatives\n\n8. Alerting (if configured):\n   \u251c\u2500 Check alert rules\n   \u251c\u2500 Match: \"proprietary_data_export\"\n   \u2514\u2500 Notify: #data-governance on Slack\n</code></pre>"},{"location":"ARCHITECTURE/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"ARCHITECTURE/#latency-targets","title":"Latency Targets","text":"Component Target Typical Notes Heuristic Classification &lt;1ms 0.5ms Regex matching Embedding Classification &lt;10ms 5ms Cached embeddings LLM Classification &lt;200ms 150ms Rare (2% of ops) Policy Evaluation (OPA) &lt;50ms 20ms Cached policies Audit Logging Non-blocking 0ms (async) Queued writes Total (98% of ops) &lt;50ms 25ms Heuristic + policy Total (2% of ops) &lt;300ms 190ms LLM + policy"},{"location":"ARCHITECTURE/#throughput-targets","title":"Throughput Targets","text":"Operation Target Scalability Classifications/second 1,000+ Horizontal scaling Policy evaluations/second 5,000+ OPA sidecars Audit log writes/second 10,000+ Batching + async"},{"location":"ARCHITECTURE/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"ARCHITECTURE/#single-tenant-deployment","title":"Single-Tenant Deployment","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                Load Balancer                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                 \u2502\n\u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510\n\u2502 Lacuna \u2502      \u2502 Lacuna \u2502  (Multiple instances)\n\u2502 Core   \u2502      \u2502 Core   \u2502\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n    \u2502                \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  PostgreSQL     \u2502 (Audit logs)\n    \u2502  Cluster        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  OPA Server     \u2502 (Policy engine)\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Redis Cache    \u2502 (Classifications, embeddings)\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#multi-tenant-deployment","title":"Multi-Tenant Deployment","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           API Gateway + Tenant Router            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                      \u2502\n\u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n\u2502 Tenant A \u2502        \u2502 Tenant B \u2502\n\u2502 Namespace\u2502        \u2502 Namespace\u2502\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n    \u2502                     \u2502\n\u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n\u2502     Shared PostgreSQL         \u2502\n\u2502     (Row-level security)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     Shared OPA Server          \u2502\n\u2502     (Per-tenant policies)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#summary","title":"Summary","text":"<p>Lacuna's architecture provides:</p> <p>\u2713 Modular design - Components can be deployed/scaled independently \u2713 Performance - 98% of operations complete in &lt;50ms \u2713 Scalability - Horizontal scaling for all components \u2713 Extensibility - Pluggable classifiers, policies, integrations \u2713 Reliability - Async logging, graceful degradation \u2713 Compliance - Tamper-evident audit logs, complete provenance</p>"},{"location":"AUDIT_LOGGING/","title":"ISO 27001 Audit Logging","text":""},{"location":"AUDIT_LOGGING/#overview","title":"Overview","text":"<p>Lacuna provides ISO 27001/27002-compliant audit logging with: - Tamper-evident hash chains - Complete provenance capture (who, what, when, why, how) - Append-only storage with integrity verification - Real-time alerting for critical events - 7-year retention with automated archival - Compliance report generation</p>"},{"location":"AUDIT_LOGGING/#iso-27001-control-mapping","title":"ISO 27001 Control Mapping","text":""},{"location":"AUDIT_LOGGING/#a94-system-and-application-access-control","title":"A.9.4: System and Application Access Control","text":"<p>A.9.4.1 Information access restriction</p> <p>Lacuna logs: - Every data access attempt (successful and failed) - Classification decisions for all accessed data - Policy evaluations (allow/deny with reasoning) - User identity, role, and clearance level</p> <p>A.9.4.5 Access to source code</p> <p>Lacuna logs: - Access to code repositories - Execution of transformation code - dbt model runs with complete SQL - Custom script executions</p>"},{"location":"AUDIT_LOGGING/#a124-logging-and-monitoring","title":"A.12.4: Logging and Monitoring","text":"<p>A.12.4.1 Event logging</p> <p>Lacuna captures: - User IDs and timestamps (NTP-synchronized) - Successful/failed authentication - Data and system access attempts - System configuration changes - Privileged account usage - Audit trail function activation</p> <p>A.12.4.2 Protection of log information</p> <p>Lacuna ensures: - Append-only storage (no updates/deletes) - Hash chain prevents tampering - Separate credentials for audit access - Encryption at rest and in transit - Regular integrity verification</p> <p>A.12.4.3 Administrator and operator logs</p> <p>Lacuna tracks: - All policy changes (create, update, delete) - User permission grants/revokes - Configuration modifications - System maintenance actions</p> <p>A.12.4.4 Clock synchronization</p> <p>Lacuna synchronizes: - All timestamps via NTP - Fallback warnings if NTP fails - Timezone-aware storage (UTC)</p>"},{"location":"AUDIT_LOGGING/#a181-compliance-with-legal-and-contractual-requirements","title":"A.18.1: Compliance with Legal and Contractual Requirements","text":"<p>A.18.1.3 Protection of records</p> <p>Lacuna provides: - 7-year minimum retention - Automated archival to cold storage - Tamper-evident storage - Compliance report generation</p>"},{"location":"AUDIT_LOGGING/#audit-record-schema","title":"Audit Record Schema","text":""},{"location":"AUDIT_LOGGING/#core-audit-record","title":"Core Audit Record","text":"<p>Every event in Lacuna generates a comprehensive audit record:</p> <pre><code>@dataclass\nclass AuditRecord:\n    \"\"\"ISO 27001-compliant audit record.\"\"\"\n\n    # Core Identity\n    event_id: str  # UUID for unique identification\n    timestamp: datetime  # ISO 8601, NTP-synchronized\n    event_type: EventType  # Categorized event\n    severity: Severity  # INFO, WARNING, ERROR, CRITICAL\n\n    # Actor Identification\n    user_id: str  # Who performed the action\n    user_session_id: str  # Session identifier\n    user_ip_address: str  # Source IP\n    user_role: str  # Role/clearance level\n    user_department: Optional[str]\n\n    # Target Resource\n    resource_type: str  # \"dataset\", \"table\", \"file\", \"query\"\n    resource_id: str  # Unique identifier\n    resource_classification: Optional[str]  # PROPRIETARY/INTERNAL/PUBLIC\n    resource_tags: List[str]  # PII, PHI, FINANCIAL, etc.\n\n    # Action Details\n    action: str  # \"read\", \"write\", \"classify\", \"export\"\n    action_result: str  # \"success\", \"denied\", \"error\"\n    action_metadata: Dict[str, Any]  # Action-specific details\n\n    # Policy/Governance\n    policy_id: Optional[str]  # Which policy was evaluated\n    policy_version: Optional[str]  # Policy version\n    classification_tier: Optional[str]\n    classification_confidence: Optional[float]\n    classification_reasoning: Optional[str]\n\n    # Lineage/Provenance\n    parent_event_id: Optional[str]  # For chained operations\n    lineage_chain: List[str]  # Upstream data sources\n\n    # Compliance Metadata\n    compliance_flags: List[str]  # GDPR, HIPAA, SOX, etc.\n    retention_period_days: int  # Default: 2555 (7 years)\n\n    # Tamper Detection\n    previous_record_hash: Optional[str]  # Hash of previous record\n    record_hash: str  # Hash of this record\n    signature: Optional[str]  # Digital signature\n\n    # System Context\n    system_id: str\n    system_version: str\n</code></pre>"},{"location":"AUDIT_LOGGING/#event-types","title":"Event Types","text":"<pre><code>class EventType(Enum):\n    # Access Events (A.9.4.1)\n    DATA_ACCESS = \"data.access\"\n    DATA_READ = \"data.read\"\n    DATA_WRITE = \"data.write\"\n    DATA_DELETE = \"data.delete\"\n    DATA_EXPORT = \"data.export\"\n\n    # Classification Events\n    CLASSIFICATION_AUTO = \"classification.automatic\"\n    CLASSIFICATION_MANUAL = \"classification.manual_override\"\n    CLASSIFICATION_POLICY_CHANGE = \"classification.policy_change\"\n\n    # Policy Events\n    POLICY_EVALUATION = \"policy.evaluation\"\n    POLICY_ALLOW = \"policy.allow\"\n    POLICY_DENY = \"policy.deny\"\n    POLICY_EXCEPTION = \"policy.exception_granted\"\n\n    # Administrative Events (A.12.4.3)\n    ADMIN_POLICY_CREATE = \"admin.policy.create\"\n    ADMIN_POLICY_UPDATE = \"admin.policy.update\"\n    ADMIN_POLICY_DELETE = \"admin.policy.delete\"\n    ADMIN_USER_GRANT = \"admin.user.grant_access\"\n    ADMIN_USER_REVOKE = \"admin.user.revoke_access\"\n\n    # Authentication Events\n    AUTH_SUCCESS = \"auth.success\"\n    AUTH_FAILURE = \"auth.failure\"\n    AUTH_LOGOUT = \"auth.logout\"\n\n    # System Events\n    SYSTEM_CONFIG_CHANGE = \"system.config.change\"\n    AUDIT_LOG_ACCESS = \"audit.log.access\"\n</code></pre>"},{"location":"AUDIT_LOGGING/#storage-architecture","title":"Storage Architecture","text":""},{"location":"AUDIT_LOGGING/#postgresql-backend","title":"PostgreSQL Backend","text":"<p>Lacuna uses PostgreSQL with: - Partitioned tables by month for performance - Append-only constraints (no UPDATE/DELETE) - Hash chain linking records chronologically - Indexes optimized for audit queries</p> <pre><code>CREATE TABLE audit_log (\n    event_id UUID PRIMARY KEY,\n    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,\n    event_type VARCHAR(50) NOT NULL,\n    severity VARCHAR(20) NOT NULL,\n\n    user_id VARCHAR(255) NOT NULL,\n    user_session_id VARCHAR(255),\n    user_ip_address INET,\n    user_role VARCHAR(100),\n\n    resource_type VARCHAR(50) NOT NULL,\n    resource_id VARCHAR(500) NOT NULL,\n    resource_classification VARCHAR(20),\n    resource_tags TEXT[],\n\n    action VARCHAR(100) NOT NULL,\n    action_result VARCHAR(20) NOT NULL,\n    action_metadata JSONB,\n\n    policy_id VARCHAR(100),\n    policy_version VARCHAR(50),\n    classification_tier VARCHAR(20),\n    classification_confidence FLOAT,\n    classification_reasoning TEXT,\n\n    parent_event_id UUID,\n    lineage_chain TEXT[],\n\n    compliance_flags TEXT[],\n    retention_period_days INTEGER DEFAULT 2555,\n\n    previous_record_hash VARCHAR(64),\n    record_hash VARCHAR(64) NOT NULL,\n    signature TEXT,\n\n    system_id VARCHAR(100),\n    system_version VARCHAR(50),\n\n    CONSTRAINT no_updates CHECK (true)\n) PARTITION BY RANGE (timestamp);\n\n-- Prevent DELETE operations\nCREATE RULE audit_log_no_delete AS \n    ON DELETE TO audit_log DO INSTEAD NOTHING;\n\n-- Prevent UPDATE operations  \nCREATE RULE audit_log_no_update AS \n    ON UPDATE TO audit_log DO INSTEAD NOTHING;\n\n-- Indexes for common queries\nCREATE INDEX idx_audit_timestamp ON audit_log(timestamp DESC);\nCREATE INDEX idx_audit_user ON audit_log(user_id, timestamp DESC);\nCREATE INDEX idx_audit_resource ON audit_log(resource_id, timestamp DESC);\nCREATE INDEX idx_audit_classification ON audit_log(resource_classification, timestamp DESC);\nCREATE INDEX idx_audit_tags ON audit_log USING GIN(resource_tags);\n</code></pre>"},{"location":"AUDIT_LOGGING/#hash-chain","title":"Hash Chain","text":"<p>Every record links to previous via cryptographic hash:</p> <pre><code>Record 1: hash = SHA256(record_1_data)\nRecord 2: hash = SHA256(record_2_data + Record_1.hash)\nRecord 3: hash = SHA256(record_3_data + Record_2.hash)\n...\n\nBreaking the chain = Tampering detected\n</code></pre> <p>Verification: <pre><code>def verify_integrity(start_time: datetime) -&gt; bool:\n    \"\"\"Verify hash chain integrity.\"\"\"\n    records = query_records(start_time, order=\"ASC\")\n\n    previous_hash = None\n    for record in records:\n        # Check link to previous\n        if previous_hash and record.previous_record_hash != previous_hash:\n            return False  # Chain broken!\n\n        # Verify this record's hash\n        computed = compute_hash(record)\n        if computed != record.record_hash:\n            return False  # Record modified!\n\n        previous_hash = record.record_hash\n\n    return True  # Chain intact\n</code></pre></p>"},{"location":"AUDIT_LOGGING/#audit-workflow-example","title":"Audit Workflow Example","text":""},{"location":"AUDIT_LOGGING/#scenario-user-exports-customer-data","title":"Scenario: User Exports Customer Data","text":"<pre><code># User code\ncustomers = pd.read_csv(\"customers.csv\")\ncustomers.to_csv(\"~/Downloads/export.csv\")\n</code></pre>"},{"location":"AUDIT_LOGGING/#generated-audit-trail","title":"Generated Audit Trail","text":"<p>Event 1: Data Access Attempt <pre><code>{\n  \"event_id\": \"550e8400-e29b-41d4-a716-446655440001\",\n  \"timestamp\": \"2025-01-17T10:30:00Z\",\n  \"event_type\": \"DATA_ACCESS\",\n  \"severity\": \"INFO\",\n  \"user_id\": \"alice@example.com\",\n  \"user_role\": \"data_analyst\",\n  \"resource_type\": \"file\",\n  \"resource_id\": \"customers.csv\",\n  \"action\": \"read\",\n  \"action_result\": \"attempting\"\n}\n</code></pre></p> <p>Event 2: Classification Decision <pre><code>{\n  \"event_id\": \"550e8400-e29b-41d4-a716-446655440002\",\n  \"timestamp\": \"2025-01-17T10:30:00.123Z\",\n  \"event_type\": \"CLASSIFICATION_AUTO\",\n  \"severity\": \"INFO\",\n  \"user_id\": \"alice@example.com\",\n  \"resource_type\": \"file\",\n  \"resource_id\": \"customers.csv\",\n  \"resource_classification\": \"PROPRIETARY\",\n  \"resource_tags\": [\"PII\", \"GDPR\", \"CUSTOMER_DATA\"],\n  \"action\": \"classify\",\n  \"action_result\": \"success\",\n  \"classification_tier\": \"PROPRIETARY\",\n  \"classification_confidence\": 0.95,\n  \"classification_reasoning\": \"File contains email, phone columns (PII detected)\",\n  \"parent_event_id\": \"550e8400-e29b-41d4-a716-446655440001\",\n  \"previous_record_hash\": \"a3c9f...\"\n}\n</code></pre></p> <p>Event 3: Policy Evaluation <pre><code>{\n  \"event_id\": \"550e8400-e29b-41d4-a716-446655440003\",\n  \"timestamp\": \"2025-01-17T10:30:00.145Z\",\n  \"event_type\": \"POLICY_DENY\",\n  \"severity\": \"WARNING\",\n  \"user_id\": \"alice@example.com\",\n  \"resource_type\": \"file\",\n  \"resource_id\": \"customers.csv\",\n  \"resource_classification\": \"PROPRIETARY\",\n  \"action\": \"export\",\n  \"action_result\": \"denied\",\n  \"action_metadata\": {\n    \"destination\": \"~/Downloads/export.csv\",\n    \"destination_encrypted\": false,\n    \"policy_reasoning\": \"Cannot export PROPRIETARY data to unmanaged location\"\n  },\n  \"policy_id\": \"P-2024-001\",\n  \"policy_version\": \"1.2.0\",\n  \"parent_event_id\": \"550e8400-e29b-41d4-a716-446655440002\",\n  \"compliance_flags\": [\"GDPR\", \"CCPA\"],\n  \"previous_record_hash\": \"b7f1e...\"\n}\n</code></pre></p> <p>Event 4: User Override Attempt (if user requests exception) <pre><code>{\n  \"event_id\": \"550e8400-e29b-41d4-a716-446655440004\",\n  \"timestamp\": \"2025-01-17T10:35:00Z\",\n  \"event_type\": \"POLICY_EXCEPTION\",\n  \"severity\": \"WARNING\",\n  \"user_id\": \"alice@example.com\",\n  \"resource_type\": \"file\",\n  \"resource_id\": \"customers.csv\",\n  \"action\": \"request_exception\",\n  \"action_result\": \"pending_approval\",\n  \"action_metadata\": {\n    \"business_justification\": \"Board presentation Q4 metrics\",\n    \"requested_approver\": \"data-steward@example.com\",\n    \"duration_hours\": 2\n  },\n  \"parent_event_id\": \"550e8400-e29b-41d4-a716-446655440003\",\n  \"previous_record_hash\": \"c2d4f...\"\n}\n</code></pre></p>"},{"location":"AUDIT_LOGGING/#real-time-alerting","title":"Real-Time Alerting","text":""},{"location":"AUDIT_LOGGING/#alert-rules","title":"Alert Rules","text":"<p>Lacuna monitors audit stream for critical patterns:</p> <pre><code>class AlertRule:\n    \"\"\"Define alerting conditions.\"\"\"\n\n    name: str\n    condition: Callable[[List[AuditRecord]], bool]\n    severity: Severity\n    notification_channels: List[str]\n    window_minutes: int = 5\n\n# Example rules\nALERT_RULES = [\n    AlertRule(\n        name=\"repeated_denials\",\n        condition=lambda events: count_denials(events, minutes=5) &gt;= 5,\n        severity=Severity.CRITICAL,\n        notification_channels=[\"security@example.com\", \"slack:#security\"]\n    ),\n    AlertRule(\n        name=\"proprietary_export_attempt\",\n        condition=lambda event: (\n            event.event_type == EventType.DATA_EXPORT and\n            event.resource_classification == \"PROPRIETARY\"\n        ),\n        severity=Severity.WARNING,\n        notification_channels=[\"governance@example.com\"]\n    ),\n    AlertRule(\n        name=\"admin_policy_change\",\n        condition=lambda event: event.event_type.value.startswith(\"admin.policy\"),\n        severity=Severity.WARNING,\n        notification_channels=[\"governance@example.com\", \"security@example.com\"]\n    ),\n    AlertRule(\n        name=\"integrity_check_failure\",\n        condition=lambda event: (\n            event.event_type == EventType.SYSTEM_EVENT and\n            \"integrity_failure\" in event.action_metadata\n        ),\n        severity=Severity.CRITICAL,\n        notification_channels=[\"security@example.com\", \"on-call\"]\n    )\n]\n</code></pre>"},{"location":"AUDIT_LOGGING/#alert-example","title":"Alert Example","text":"<pre><code>\ud83d\udea8 CRITICAL ALERT: repeated_denials\n\nUser: alice@example.com\nPattern: 5 policy denials in 3 minutes\nResources: customers.csv, sales.csv, partners.csv\nAction: export attempts to ~/Downloads/\n\nPossible causes:\n\u2022 User unaware of governance policies\n\u2022 Misconfigured classification\n\u2022 Attempted data exfiltration\n\nRecommended actions:\n1. Contact user for clarification\n2. Review user's recent activity\n3. Verify classification accuracy\n4. Consider security incident response\n\nEvent IDs: 550e8400-..., 661f9511-..., 772g0622-...\nTime: 2025-01-17 10:30-10:33 UTC\n</code></pre>"},{"location":"AUDIT_LOGGING/#retention-and-archival","title":"Retention and Archival","text":""},{"location":"AUDIT_LOGGING/#retention-tiers","title":"Retention Tiers","text":"Tier Duration Storage Access Speed Cost Hot 0-90 days PostgreSQL &lt;100ms High Warm 90 days - 1 year Compressed PostgreSQL &lt;1s Medium Cold 1-7 years S3 Glacier / Tape Minutes Low"},{"location":"AUDIT_LOGGING/#automated-archival","title":"Automated Archival","text":"<pre><code># Runs daily as scheduled job\ndef archive_old_records():\n    \"\"\"Archive records older than 90 days.\"\"\"\n    cutoff = datetime.now() - timedelta(days=90)\n\n    # Query records to archive\n    records = query_audit_log(end_date=cutoff)\n\n    # Verify integrity before archival\n    if not verify_integrity(start_time=min(r.timestamp for r in records)):\n        raise Exception(\"Cannot archive: integrity check failed\")\n\n    # Create encrypted archive\n    archive_file = create_archive(\n        records=records,\n        compression=\"gzip\",\n        encryption=\"AES-256-CBC\"\n    )\n\n    # Upload to cold storage\n    upload_to_glacier(archive_file)\n\n    # Verify cold storage\n    if not verify_cold_storage(archive_file):\n        raise Exception(\"Cannot delete from hot storage: verification failed\")\n\n    # Delete from hot storage (only after verified)\n    delete_archived_records(records)\n</code></pre>"},{"location":"AUDIT_LOGGING/#retrieval-from-archive","title":"Retrieval from Archive","text":"<pre><code>def retrieve_from_archive(start_date: datetime, end_date: datetime) -&gt; List[AuditRecord]:\n    \"\"\"Retrieve archived records (slow operation).\"\"\"\n\n    # Find relevant archive files\n    archives = find_archives_for_period(start_date, end_date)\n\n    # Download from Glacier (may take hours)\n    for archive in archives:\n        initiate_retrieval(archive)\n\n    # Wait for retrieval\n    wait_for_retrieval_completion(archives)\n\n    # Download, decrypt, decompress\n    records = []\n    for archive in archives:\n        archive_records = extract_archive(archive)\n        records.extend([\n            r for r in archive_records\n            if start_date &lt;= r.timestamp &lt;= end_date\n        ])\n\n    return records\n</code></pre>"},{"location":"AUDIT_LOGGING/#compliance-reporting","title":"Compliance Reporting","text":""},{"location":"AUDIT_LOGGING/#a94-report-access-control","title":"A.9.4 Report: Access Control","text":"<pre><code>from lacuna.compliance import ISO27001Reporter\n\nreporter = ISO27001Reporter()\n\n# Generate A.9.4 report\nreport = reporter.generate_a_9_4_report(\n    start_date=\"2024-01-01\",\n    end_date=\"2024-12-31\"\n)\n\nprint(report)\n</code></pre> <p>Output: <pre><code>ISO 27001 Control A.9.4 Audit Report\nPeriod: 2024-01-01 to 2024-12-31\n\n1. ACCESS SUMMARY\nTotal access attempts: 1,245,892\nSuccessful: 1,238,451 (99.4%)\nFailed/Denied: 7,441 (0.6%)\n\n2. USER ACCESS PATTERNS\nTop Users by Access Count:\n- alice@example.com: 45,231 accesses (98.2% success)\n- bob@example.com: 38,912 accesses (99.1% success)\n- charlie@example.com: 32,445 accesses (97.8% success)\n\n3. FAILED ACCESS ATTEMPTS\nPolicy Denials: 6,822 (91.7% of failures)\nAuthentication Failures: 445 (6.0%)\nSystem Errors: 174 (2.3%)\n\nTop Denied Resources:\n- customers.csv: 2,341 denials (PII export attempts)\n- financial_data.db: 1,892 denials (insufficient clearance)\n- strategic_plans/: 981 denials (department restrictions)\n\n4. PRIVILEGE CHANGES\nUser Grants: 145\nUser Revocations: 67\nClearance Upgrades: 23\nClearance Downgrades: 12\n\n5. SENSITIVE DATA ACCESS\nPROPRIETARY tier: 234,567 accesses (18.8%)\n- 99.2% by authorized users\n- 0.8% denied (policy violations)\n\nPII Data Access: 89,234 instances\n- All logged with lineage\n- 127 exceptions granted\n- 0 unauthorized access detected\n\n6. COMPLIANCE ISSUES\nCritical: 0\nHigh: 3 (under investigation)\nMedium: 12 (resolved)\nLow: 45 (normal variation)\n</code></pre></p>"},{"location":"AUDIT_LOGGING/#gdpr-report","title":"GDPR Report","text":"<pre><code># Generate GDPR compliance report\ngdpr_report = reporter.generate_gdpr_report(\n    start_date=\"2024-01-01\",\n    end_date=\"2024-12-31\"\n)\n</code></pre> <p>Output: <pre><code>GDPR Compliance Report\nPeriod: 2024-01-01 to 2024-12-31\n\nARTICLE 5: Principles\n\u2713 Lawfulness: All PII access logged with purpose\n\u2713 Fairness: User notifications implemented\n\u2713 Transparency: Audit trail available to data subjects\n\u2713 Purpose Limitation: Purpose tracked for all access\n\u2713 Data Minimization: Aggregation preferred where possible\n\u2713 Accuracy: Quality checks logged\n\u2713 Storage Limitation: Retention policies enforced\n\u2713 Integrity: Hash chain verified\n\nARTICLE 30: Records of Processing\nTotal PII Processing Activities: 89,234\n- Customer Data: 67,891\n- Employee Data: 18,234\n- Partner Data: 3,109\n\nAll activities logged with:\n\u2713 Purpose\n\u2713 Data categories\n\u2713 Recipients\n\u2713 Retention periods\n\u2713 Security measures\n\nARTICLE 32: Security of Processing\n\u2713 Pseudonymization: Available and tracked\n\u2713 Encryption: Enforced for PROPRIETARY data\n\u2713 Integrity: Hash chain verification\n\u2713 Availability: 99.97% uptime\n\u2713 Testing: Monthly integrity checks\n\nDATA SUBJECT RIGHTS\nAccess Requests (Art. 15): 234 (avg response: 3.2 days)\nRectification Requests (Art. 16): 45 (all completed)\nErasure Requests (Art. 17): 12 (all completed)\nRestriction Requests (Art. 18): 5 (all completed)\nPortability Requests (Art. 20): 8 (all completed)\n\nBREACHES\nPersonal Data Breaches: 0\nNear-Miss Incidents: 3 (prevented by Lacuna)\n</code></pre></p>"},{"location":"AUDIT_LOGGING/#querying-audit-logs","title":"Querying Audit Logs","text":""},{"location":"AUDIT_LOGGING/#query-interface","title":"Query Interface","text":"<pre><code>from lacuna.audit import AuditQuery\n\n# Query user activity\nuser_activity = AuditQuery.for_user(\n    user_id=\"alice@example.com\",\n    start_date=\"2025-01-01\",\n    end_date=\"2025-01-31\"\n)\n\nprint(f\"Total events: {len(user_activity)}\")\nprint(f\"Access attempts: {user_activity.count(event_type='DATA_ACCESS')}\")\nprint(f\"Denials: {user_activity.count(action_result='denied')}\")\n\n# Query resource access\nresource_access = AuditQuery.for_resource(\n    resource_id=\"customers.csv\",\n    start_date=\"2025-01-01\",\n    end_date=\"2025-01-31\"\n)\n\nprint(f\"Accessed by {resource_access.unique_users()} users\")\nprint(f\"Most common action: {resource_access.most_common_action()}\")\n\n# Query policy violations\nviolations = AuditQuery.violations(\n    start_date=\"2025-01-01\",\n    end_date=\"2025-01-31\"\n)\n\nprint(f\"Total violations: {len(violations)}\")\nprint(f\"By policy: {violations.group_by('policy_id')}\")\n\n# Complex query\nhigh_risk_activity = AuditQuery.where(\n    resource_classification=\"PROPRIETARY\",\n    action=\"export\",\n    user_role=\"contractor\"  # External contractors\n).and_where(\n    action_result=\"success\"  # Actually succeeded\n).order_by(\"timestamp\", desc=True)\n</code></pre>"},{"location":"AUDIT_LOGGING/#accessing-audit-logs-is-audited","title":"Accessing Audit Logs is Audited","text":"<pre><code># Querying audit logs generates its own audit event\nquery_result = AuditQuery.for_user(\"alice@example.com\", ...)\n\n# This creates an audit record:\n{\n  \"event_type\": \"AUDIT_LOG_ACCESS\",\n  \"user_id\": \"admin@example.com\",\n  \"resource_type\": \"audit_log\",\n  \"resource_id\": \"user_activity:alice@example.com\",\n  \"action\": \"query\",\n  \"action_result\": \"success\",\n  \"action_metadata\": {\n    \"records_returned\": 1234,\n    \"query_parameters\": {...}\n  }\n}\n</code></pre> <p>Important: Only authorized roles (auditor, compliance_officer, security_admin) can access audit logs.</p>"},{"location":"AUDIT_LOGGING/#best-practices","title":"Best Practices","text":""},{"location":"AUDIT_LOGGING/#1-regular-integrity-verification","title":"1. Regular Integrity Verification","text":"<pre><code># Run weekly\nlacuna audit verify-integrity --since 2025-01-01\n\n# Output\n\u2713 Verified 1,245,892 records\n\u2713 Hash chain intact\n\u2713 No tampering detected\n\u2713 Last verification: 2025-01-17 10:00 UTC\n</code></pre>"},{"location":"AUDIT_LOGGING/#2-test-archival-and-retrieval","title":"2. Test Archival and Retrieval","text":"<pre><code># Quarterly test\nlacuna audit test-archive-retrieval --date 2024-10-01\n\n# Ensures:\n# - Archives can be retrieved\n# - Decryption works\n# - Data integrity preserved\n# - Retrieval time acceptable\n</code></pre>"},{"location":"AUDIT_LOGGING/#3-review-alert-rules","title":"3. Review Alert Rules","text":"<pre><code># Monthly review\nfrom lacuna.audit import AlertMetrics\n\nmetrics = AlertMetrics(period=\"last_30_days\")\n\nprint(f\"Alerts fired: {metrics.total_alerts}\")\nprint(f\"False positives: {metrics.false_positive_rate}%\")\nprint(f\"Response time: {metrics.avg_response_time_minutes} min\")\n\n# Adjust thresholds if needed\n</code></pre>"},{"location":"AUDIT_LOGGING/#4-compliance-report-automation","title":"4. Compliance Report Automation","text":"<pre><code># Schedule compliance reports\ncompliance_reports:\n  iso27001_a94:\n    frequency: monthly\n    recipients: [compliance@example.com]\n\n  gdpr:\n    frequency: quarterly\n    recipients: [dpo@example.com, legal@example.com]\n\n  hipaa:\n    frequency: annually\n    recipients: [compliance@example.com, security@example.com]\n</code></pre>"},{"location":"AUDIT_LOGGING/#summary","title":"Summary","text":"<p>Lacuna's audit logging provides:</p> <p>\u2713 ISO 27001 compliance out-of-the-box \u2713 Tamper-evident storage with hash chains \u2713 Complete provenance for every data operation \u2713 Real-time alerting for security events \u2713 Automated archival with 7-year retention \u2713 Compliance reports ready for auditors \u2713 Query interface for investigations</p> <p>No manual effort required. Audit logging is automatic, comprehensive, and ready for any compliance audit.</p>"},{"location":"CONTRIBUTING/","title":"Contributing to Lacuna","text":"<p>Thank you for your interest in contributing! This is a data governance and lineage tracking project focused on enabling self-service data access while maintaining compliance and policy enforcement.</p>"},{"location":"CONTRIBUTING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Code of Conduct</li> <li>Getting Started</li> <li>Development Setup</li> <li>How to Contribute</li> <li>Pull Request Process</li> <li>Coding Standards</li> <li>Testing Requirements</li> <li>Documentation</li> </ul>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":""},{"location":"CONTRIBUTING/#our-pledge","title":"Our Pledge","text":"<p>We pledge to make participation in this project a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CONTRIBUTING/#our-standards","title":"Our Standards","text":"<p>Positive behavior includes: - Using welcoming and inclusive language - Being respectful of differing viewpoints - Gracefully accepting constructive criticism - Focusing on what is best for the community - Showing empathy towards other community members</p> <p>Unacceptable behavior includes: - Harassment, trolling, or discriminatory comments - Publishing others' private information - Other conduct inappropriate in a professional setting</p>"},{"location":"CONTRIBUTING/#getting-started","title":"Getting Started","text":""},{"location":"CONTRIBUTING/#areas-we-need-help","title":"Areas We Need Help","text":"<p>\ud83d\udd10 Classification Pipeline - Improve heuristics for common data patterns - Add embedding models for semantic classification - Optimize LLM prompts for context-aware decisions - Add support for custom data types</p> <p>\ud83d\udcca Lineage Tracking - Track lineage across SQL transformations - Support for complex joins and aggregations - Integration with dbt lineage graphs - Visualization improvements</p> <p>\ud83d\udee1\ufe0f Policy Engine - OPA policy templates for common use cases - Policy testing framework - Integration with external policy systems - Real-time policy evaluation optimization</p> <p>\ud83d\udcda Documentation - Examples and tutorials - Architecture decision records - Best practices guides - Integration guides for various platforms</p> <p>\ud83c\udfa8 Tooling - IDE plugins (VS Code, PyCharm) - Jupyter notebook integration improvements - Web dashboard features - CLI enhancements</p> <p>\ud83d\udd0d Audit &amp; Compliance - ISO 27001 report generators - GDPR compliance utilities - HIPAA audit trail support - Retention policy automation</p> <p>\ud83d\udd0c Integrations - Databricks Unity Catalog integration - Snowflake governance features - AWS Lake Formation support - Azure Purview connectors</p>"},{"location":"CONTRIBUTING/#development-setup","title":"Development Setup","text":""},{"location":"CONTRIBUTING/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>Git</li> <li>Optional: PostgreSQL 14+ (for production mode)</li> <li>Optional: Docker (for containerized deployment)</li> </ul>"},{"location":"CONTRIBUTING/#clone-repository","title":"Clone Repository","text":"<pre><code>git clone https://github.com/witlox/lacuna.git\ncd lacuna\n</code></pre>"},{"location":"CONTRIBUTING/#python-setup","title":"Python Setup","text":"<pre><code># Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install dependencies\npip install -e \".[dev]\"\n\n# Run tests\npytest\n</code></pre>"},{"location":"CONTRIBUTING/#quick-start-with-dev-mode","title":"Quick Start with Dev Mode","text":"<p>The fastest way to run Lacuna locally is dev mode, which uses SQLite and in-memory backends:</p> <pre><code># Start in dev mode (no external dependencies required)\nlacuna dev\n\n# Open in browser\n# API Docs: http://127.0.0.1:8000/docs\n# User Dashboard: http://127.0.0.1:8000/user/dashboard\n# Admin Dashboard: http://127.0.0.1:8000/admin/\n</code></pre> <p>See DEVELOPMENT.md for detailed development setup.</p>"},{"location":"CONTRIBUTING/#full-production-setup-optional","title":"Full Production Setup (Optional)","text":"<p>For testing with production-like services:</p> <pre><code># Database Setup\ncreatedb lacuna_dev\n\n# Run migrations\nalembic upgrade head\n\n# OPA (Open Policy Agent) Setup\nbrew install opa  # macOS\n# Or download from https://www.openpolicyagent.org/docs/latest/#running-opa\n\n# Start with full services\nlacuna serve --reload\n</code></pre>"},{"location":"CONTRIBUTING/#verify-installation","title":"Verify Installation","text":"<pre><code># Test CLI\nlacuna --version\n\n# Run example classification\nlacuna classify --file examples/sample_data.csv\n</code></pre>"},{"location":"CONTRIBUTING/#how-to-contribute","title":"How to Contribute","text":""},{"location":"CONTRIBUTING/#1-find-an-issue","title":"1. Find an Issue","text":"<p>Browse open issues or create a new one.</p> <p>Good first issues are labeled: <code>good-first-issue</code>, <code>help-wanted</code>, <code>documentation</code></p>"},{"location":"CONTRIBUTING/#2-discuss-your-approach","title":"2. Discuss Your Approach","text":"<p>For significant changes: 1. Create an issue first 2. Discuss the approach 3. Get feedback before coding</p> <p>For small fixes (typos, bugs): - Just submit a PR</p>"},{"location":"CONTRIBUTING/#3-create-a-branch","title":"3. Create a Branch","text":"<pre><code>git checkout -b feature/your-feature-name\n# or\ngit checkout -b fix/bug-description\n</code></pre> <p>Branch naming: - <code>feature/</code> - New features - <code>fix/</code> - Bug fixes - <code>docs/</code> - Documentation - <code>test/</code> - Test improvements - <code>refactor/</code> - Code refactoring</p>"},{"location":"CONTRIBUTING/#4-make-changes","title":"4. Make Changes","text":"<p>Follow our coding standards and write tests.</p>"},{"location":"CONTRIBUTING/#5-commit","title":"5. Commit","text":"<p>Use clear, descriptive commit messages:</p> <pre><code>git commit -m \"feat: add PII detection to classification pipeline\"\ngit commit -m \"fix: handle lineage tracking for complex SQL joins\"\ngit commit -m \"docs: add example for policy enforcement workflow\"\n</code></pre> <p>Commit message format: <pre><code>type: short description\n\nLonger explanation if needed.\n\nFixes #123\n</code></pre></p> <p>Types: - <code>feat</code> - New feature - <code>fix</code> - Bug fix - <code>docs</code> - Documentation - <code>test</code> - Tests - <code>refactor</code> - Code refactoring - <code>perf</code> - Performance improvement - <code>chore</code> - Maintenance</p>"},{"location":"CONTRIBUTING/#6-push-and-create-pr","title":"6. Push and Create PR","text":"<pre><code>git push origin your-branch-name\n</code></pre> <p>Then create a Pull Request on GitHub.</p>"},{"location":"CONTRIBUTING/#pull-request-process","title":"Pull Request Process","text":""},{"location":"CONTRIBUTING/#pr-checklist","title":"PR Checklist","text":"<p>Before submitting, ensure:</p> <ul> <li> Code follows style guidelines</li> <li> Tests added/updated</li> <li> Tests pass (<code>pytest</code> for Python, <code>cargo test</code> for Rust)</li> <li> Documentation updated</li> <li> Commit messages are clear</li> <li> Branch is up to date with main</li> </ul>"},{"location":"CONTRIBUTING/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes.\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Testing\nHow was this tested?\n\n## Related Issues\nFixes #123\n\n## Checklist\n- [ ] Tests pass\n- [ ] Documentation updated\n- [ ] Follows coding standards\n</code></pre>"},{"location":"CONTRIBUTING/#review-process","title":"Review Process","text":"<ol> <li>Automated checks run (tests, linting, type checking)</li> <li>Maintainer reviews (usually within 2-3 days)</li> <li>Address feedback</li> <li>Approval &amp; merge</li> </ol>"},{"location":"CONTRIBUTING/#coding-standards","title":"Coding Standards","text":""},{"location":"CONTRIBUTING/#python","title":"Python","text":"<p>Style Guide: PEP 8 with modifications</p> <pre><code># Good\ndef classify_data_operation(\n    operation: DataOperation,\n    context: ClassificationContext,\n    use_llm: bool = False\n) -&gt; ClassificationResult:\n    \"\"\"\n    Classify a data operation using the three-layer pipeline.\n\n    Args:\n        operation: The data operation to classify (read, write, export, etc.)\n        context: Contextual information (user, lineage, conversation)\n        use_llm: Whether to use LLM layer for complex decisions\n\n    Returns:\n        ClassificationResult with tier, tags, and confidence\n\n    Raises:\n        ValidationError: If operation data is invalid\n        ClassificationError: If classification fails\n    \"\"\"\n    # Implementation\n    pass\n\n# Bad\ndef classify(op, ctx, llm=False):  # No type hints, unclear names\n    pass\n</code></pre> <p>Key points: - Type hints required (Python 3.10+ syntax) - Docstrings for all public functions (Google style) - Max line length: 100 characters - Use <code>black</code> for formatting - Use <code>mypy</code> for type checking - Use <code>ruff</code> for linting</p> <p>Run formatters: <pre><code>black python/\nruff check python/\nmypy python/\n</code></pre></p>"},{"location":"CONTRIBUTING/#opa-open-policy-agent-policies","title":"OPA (Open Policy Agent) Policies","text":"<p>Style Guide: Rego best practices</p> <pre><code># Good - clear, well-documented policy\npackage lacuna.policies.pii_export\n\nimport future.keywords.if\nimport future.keywords.in\n\n# Deny PII exports to unmanaged locations\ndeny[msg] if {\n    input.operation.type == \"export\"\n    input.data.classification.tier == \"PROPRIETARY\"\n    \"PII\" in input.data.tags\n    not is_managed_location(input.operation.destination)\n\n    msg := sprintf(\n        \"Cannot export PII data to unmanaged location: %s\",\n        [input.operation.destination]\n    )\n}\n\n# Helper: Check if destination is managed\nis_managed_location(path) if {\n    startswith(path, \"/governed/\")\n}\n\n# Bad - unclear, no documentation\ndeny[msg] if {\n    input.op.t == \"exp\"\n    input.d.c == \"P\"\n    msg := \"denied\"\n}\n</code></pre> <p>Key points: - Use descriptive package names - Document policy intent and rules - Use helper functions for clarity - Include examples in comments - Test policies with sample data</p> <p>Run tests: <pre><code>opa test policies/\n</code></pre></p>"},{"location":"CONTRIBUTING/#sql-database","title":"SQL &amp; Database","text":"<pre><code>-- Good - properly structured migration\n-- Migration: 2025_01_add_lineage_tracking\n-- Description: Add lineage tracking tables for data operations\n\nCREATE TABLE IF NOT EXISTS lineage_edges (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    source_artifact_id UUID NOT NULL REFERENCES artifacts(id),\n    target_artifact_id UUID NOT NULL REFERENCES artifacts(id),\n    operation_type VARCHAR(50) NOT NULL,  -- 'transform', 'join', 'export', etc.\n    created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n    metadata JSONB,\n    CONSTRAINT unique_lineage_edge UNIQUE (source_artifact_id, target_artifact_id, operation_type)\n);\n\nCREATE INDEX idx_lineage_source ON lineage_edges(source_artifact_id);\nCREATE INDEX idx_lineage_target ON lineage_edges(target_artifact_id);\n\n-- Bad - unclear structure, no constraints\nCREATE TABLE lineage (\n    id SERIAL,\n    src TEXT,\n    dst TEXT,\n    op TEXT\n);\n</code></pre> <p>Key points: - Use descriptive table and column names - Add comments explaining purpose - Include appropriate constraints and indexes - Use proper data types (UUID, TIMESTAMP, JSONB) - Follow migration naming conventions</p>"},{"location":"CONTRIBUTING/#testing-requirements","title":"Testing Requirements","text":""},{"location":"CONTRIBUTING/#test-coverage","title":"Test Coverage","text":"<ul> <li>Minimum: 80% code coverage</li> <li>Target: 90%+ for critical paths</li> <li>Required: 100% for contract validation</li> </ul>"},{"location":"CONTRIBUTING/#test-types","title":"Test Types","text":"<p>1. Unit Tests</p> <p>Test individual functions:</p> <pre><code>def test_pii_classifier_detection():\n    \"\"\"Test PII detection in data classification\"\"\"\n    classifier = PIIClassifier()\n\n    # Valid case - should detect PII\n    result = classifier.classify_dataframe(\n        df=pd.DataFrame({\"email\": [\"user@example.com\"], \"name\": [\"John Doe\"]}),\n        context={}\n    )\n    assert \"PII\" in result.tags\n    assert result.tier == DataTier.PROPRIETARY\n\n    # Invalid case - no PII\n    result = classifier.classify_dataframe(\n        df=pd.DataFrame({\"count\": [100], \"category\": [\"A\"]}),\n        context={}\n    )\n    assert \"PII\" not in result.tags\n</code></pre> <p>2. Integration Tests</p> <p>Test components together:</p> <pre><code>def test_policy_enforcement_end_to_end():\n    \"\"\"Test complete policy enforcement pipeline\"\"\"\n    # Create test data with PII\n    test_df = pd.DataFrame({\n        \"customer_id\": [1, 2, 3],\n        \"email\": [\"test@example.com\", \"user@example.com\", \"admin@example.com\"],\n        \"purchase_amount\": [100.0, 200.0, 150.0]\n    })\n\n    # Classify data\n    classifier = DataClassifier()\n    classification = classifier.classify(test_df)\n    assert classification.tier == DataTier.PROPRIETARY\n\n    # Try to export (should be blocked)\n    policy_engine = PolicyEngine()\n    result = policy_engine.evaluate_operation(\n        operation=DataOperation(type=\"export\", destination=\"~/Downloads/data.csv\"),\n        classification=classification,\n        user=User(role=\"analyst\")\n    )\n\n    assert result.allowed is False\n    assert \"PII\" in result.reason\n    assert len(result.alternatives) &gt; 0\n</code></pre> <p>3. Lineage Validation Tests</p> <p>Validate lineage tracking across operations:</p> <pre><code>def test_lineage_propagation_through_joins():\n    \"\"\"Test that classification propagates correctly through joins\"\"\"\n    # Create proprietary data\n    customers = pd.DataFrame({\"customer_id\": [1, 2], \"email\": [\"a@b.com\", \"c@d.com\"]})\n    customers_classified = classify_dataframe(customers, tier=DataTier.PROPRIETARY)\n\n    # Create internal data\n    orders = pd.DataFrame({\"customer_id\": [1, 2], \"amount\": [100, 200]})\n    orders_classified = classify_dataframe(orders, tier=DataTier.INTERNAL)\n\n    # Join operation\n    lineage_tracker = LineageTracker()\n    result = customers_classified.merge(orders_classified, on=\"customer_id\")\n\n    # Verify lineage tracking\n    lineage = lineage_tracker.get_lineage(result.artifact_id)\n    assert len(lineage.sources) == 2\n    assert customers_classified.artifact_id in lineage.sources\n    assert orders_classified.artifact_id in lineage.sources\n\n    # Verify classification propagation (should inherit highest tier)\n    assert result.classification.tier == DataTier.PROPRIETARY\n</code></pre> <p>4. Property-Based Tests</p> <p>Test invariants:</p> <pre><code>from hypothesis import given, strategies as st\n\n@given(\n    tier1=st.sampled_from([DataTier.PUBLIC, DataTier.INTERNAL, DataTier.PROPRIETARY]),\n    tier2=st.sampled_from([DataTier.PUBLIC, DataTier.INTERNAL, DataTier.PROPRIETARY])\n)\ndef test_classification_propagation_invariant(tier1, tier2):\n    \"\"\"Property: Classification always inherits highest tier\"\"\"\n    # Create two dataframes with different tiers\n    df1 = pd.DataFrame({\"id\": [1, 2], \"value\": [100, 200]})\n    df1_classified = classify_dataframe(df1, tier=tier1)\n\n    df2 = pd.DataFrame({\"id\": [1, 2], \"amount\": [10, 20]})\n    df2_classified = classify_dataframe(df2, tier=tier2)\n\n    # Merge them\n    result = df1_classified.merge(df2_classified, on=\"id\")\n\n    # Result should have the highest tier\n    expected_tier = max(tier1, tier2, key=lambda t: t.value)\n    assert result.classification.tier == expected_tier\n\n@given(operation=st.text(min_size=1))\ndef test_audit_log_immutability(operation):\n    \"\"\"Property: Audit log entries are immutable once written\"\"\"\n    logger = AuditLogger()\n\n    # Create audit entry\n    entry_id = logger.log_operation(operation_type=operation, user=\"test_user\")\n\n    # Retrieve entry\n    entry1 = logger.get_entry(entry_id)\n\n    # Attempt to modify (should fail or create new entry)\n    with pytest.raises(ImmutabilityError):\n        logger.modify_entry(entry_id, operation_type=\"modified\")\n\n    # Verify entry unchanged\n    entry2 = logger.get_entry(entry_id)\n    assert entry1 == entry2\n</code></pre>"},{"location":"CONTRIBUTING/#running-tests","title":"Running Tests","text":"<pre><code># All tests\npytest                                  # All tests\npytest -v                               # Verbose\npytest --cov=lacuna                     # With coverage\npytest -k test_classification           # Specific tests\npytest -m integration                   # Integration tests only\npytest -m \"not slow\"                    # Skip slow tests\n\n# Policy tests\nopa test policies/                      # Test OPA policies\nopa test -v policies/                   # Verbose policy tests\n\n# Database migrations\nalembic upgrade head                    # Apply migrations\nalembic downgrade -1                    # Rollback one migration\npytest tests/test_migrations.py         # Test migrations\n</code></pre>"},{"location":"CONTRIBUTING/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 test_classification.py\n\u2502   \u251c\u2500\u2500 test_lineage.py\n\u2502   \u251c\u2500\u2500 test_policy_engine.py\n\u2502   \u2514\u2500\u2500 test_audit_logger.py\n\u251c\u2500\u2500 integration/\n\u2502   \u251c\u2500\u2500 test_end_to_end.py\n\u2502   \u251c\u2500\u2500 test_cli.py\n\u2502   \u2514\u2500\u2500 test_jupyter_integration.py\n\u251c\u2500\u2500 lineage/\n\u2502   \u251c\u2500\u2500 test_lineage_propagation.py\n\u2502   \u2514\u2500\u2500 test_tag_inheritance.py\n\u251c\u2500\u2500 property/\n\u2502   \u2514\u2500\u2500 test_invariants.py\n\u251c\u2500\u2500 policies/\n\u2502   \u251c\u2500\u2500 test_pii_policies.py\n\u2502   \u2514\u2500\u2500 test_export_policies.py\n\u2514\u2500\u2500 fixtures/\n    \u251c\u2500\u2500 sample_data/\n    \u2502   \u251c\u2500\u2500 customers.csv\n    \u2502   \u251c\u2500\u2500 transactions.csv\n    \u2502   \u2514\u2500\u2500 public_data.csv\n    \u251c\u2500\u2500 policies/\n    \u2502   \u251c\u2500\u2500 pii_export.rego\n    \u2502   \u2514\u2500\u2500 test_policies.rego\n    \u2514\u2500\u2500 expected_classifications/\n        \u2514\u2500\u2500 expected_results.json\n</code></pre>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":""},{"location":"CONTRIBUTING/#what-to-document","title":"What to Document","text":"<p>Code changes: - Update relevant .md files in docs/ - Add docstrings to new functions - Update API documentation</p> <p>New features: - Add usage examples to README.md - Create example in examples/ - Update docs/ARCHITECTURE.md if needed - Document new policies in docs/POLICY_AS_CODE.md - Add to CHANGELOG.md</p> <p>New integrations: - Add to docs/INTEGRATIONS.md - Include setup instructions - Provide example configurations</p> <p>Bug fixes: - Note in commit message - Add regression test - Update known issues if applicable</p>"},{"location":"CONTRIBUTING/#documentation-style","title":"Documentation Style","text":"<p>Markdown files: - Use clear headings - Include code examples - Add cross-references - Keep examples up-to-date</p> <p>Code comments: <pre><code># Good: Explain WHY, not WHAT\n# Use three-layer pipeline to balance speed (&lt;10ms for 98%) with accuracy\nclassification = self._classify_with_fallback(operation, context)\n\n# Bad: State the obvious\n# Classify the operation\nclassification = self._classify_with_fallback(operation, context)\n</code></pre></p> <p>Docstrings: <pre><code>def classify_data_operation(\n    operation: DataOperation,\n    context: ClassificationContext\n) -&gt; ClassificationResult:\n    \"\"\"\n    Classify a data operation using the three-layer pipeline.\n\n    This function uses heuristics, embeddings, and LLM reasoning\n    to determine data sensitivity tier and applicable tags.\n\n    Args:\n        operation: The data operation to classify (read, write, export, etc.)\n        context: Contextual information including user, lineage, and conversation\n\n    Returns:\n        ClassificationResult with tier, tags, confidence, and reasoning\n\n    Raises:\n        ValidationError: If operation data is invalid\n        ClassificationError: If classification pipeline fails\n\n    Example:\n        &gt;&gt;&gt; operation = DataOperation(type=\"read\", path=\"/data/customers.csv\")\n        &gt;&gt;&gt; context = ClassificationContext(user=current_user)\n        &gt;&gt;&gt; result = classify_data_operation(operation, context)\n        &gt;&gt;&gt; print(result.tier)\n        DataTier.PROPRIETARY\n        &gt;&gt;&gt; print(result.tags)\n        ['PII', 'GDPR']\n    \"\"\"\n</code></pre></p>"},{"location":"CONTRIBUTING/#architecture-decision-records-adrs","title":"Architecture Decision Records (ADRs)","text":"<p>For significant architectural decisions, create an ADR:</p> <pre><code># ADR-001: Three-Layer Classification Pipeline\n\n## Status\nAccepted\n\n## Context\nWe need a classification system that is both fast and accurate,\nhandling 90%+ of operations with &lt;10ms latency while maintaining\nhigh accuracy for complex edge cases.\n\n## Decision\nUse a three-layer pipeline:\n1. Heuristics layer (regex, path analysis) - &lt;1ms, 90% of operations\n2. Embeddings layer (semantic similarity) - &lt;10ms, 8% of operations\n3. LLM reasoning layer (context-aware) - &lt;200ms, 2% of operations\n\n## Consequences\n- Fast classification for common cases\n- Accurate handling of complex scenarios\n- Increased system complexity (three layers to maintain)\n- Requires embedding model deployment\n- LLM costs for 2% of operations\n\n## Alternatives Considered\n- Pure LLM classification (rejected: too slow and expensive)\n- Pure heuristics (rejected: insufficient accuracy)\n- Two-layer system without embeddings (rejected: accuracy gap too large)\n</code></pre> <p>Store in <code>docs/adr/</code>.</p>"},{"location":"CONTRIBUTING/#communication","title":"Communication","text":""},{"location":"CONTRIBUTING/#github-discussions","title":"GitHub Discussions","text":"<p>Use for: - Feature proposals - Design discussions - Help requests - Sharing ideas</p>"},{"location":"CONTRIBUTING/#github-issues","title":"GitHub Issues","text":"<p>Use for: - Bug reports - Feature requests - Specific tasks</p> <p>Good issue example: <pre><code>Title: Add Snowflake data sharing governance support\n\n**Description:**\nCurrently Lacuna tracks lineage within a single system, but doesn't\nhandle Snowflake data sharing scenarios where data is shared across\ndifferent Snowflake accounts.\n\n**Proposed Solution:**\nExtend lineage tracking to capture cross-account data sharing:\n- Track when data is shared to external accounts\n- Maintain classification across account boundaries\n- Generate audit trail for shared data access\n\n**Example Use Case:**\n```python\n# Share data to partner account\nshare_data(\n    data=\"customer_analytics\",\n    target_account=\"partner_account\",\n    classification=DataTier.INTERNAL,\n    allowed_operations=[\"read\"]\n)\n</code></pre></p> <p>Impact: - Changes to lineage tracking system - New Snowflake integration module - Policy engine updates for cross-account rules - Audit logging for data sharing events - Tests for cross-account scenarios</p> <p>Questions: - How to handle classification when external account has different policies? - Should we require manual approval for PROPRIETARY data sharing? - How to track data access in external accounts? <pre><code>## Release Process\n\n### Versioning\n\nWe use a date-based versioning scheme: **year.major.buildnumber**\n- YEAR: Current year (e.g., 2026)\n- MAJOR: Major version increment within the year (set in `lacuna/__version__.py`)\n- BUILDNUMBER: Incremental build number (automatically generated from git commit count)\n\n**Version is automatically generated** from git history. To increment the major version, update the `major` variable in `lacuna/__version__.py`.\n\nFor building packages locally with proper version:\n```bash\nLACUNA_BUILD=1 python -m build\n</code></pre></p>"},{"location":"CONTRIBUTING/#release-checklist","title":"Release Checklist","text":"<ol> <li>Update CHANGELOG.md</li> <li>Update major version if needed (in <code>lacuna/__version__.py</code>)</li> <li>Run full test suite: <code>pytest</code></li> <li>Test OPA policies: <code>opa test policies/</code></li> <li>Tag release: <code>git tag v2026.1.100</code></li> <li>Push tags: <code>git push --tags</code></li> <li>Create GitHub release with notes</li> <li>Publish to PyPI: <code>LACUNA_BUILD=1 python -m build &amp;&amp; twine upload dist/*</code></li> <li>Update documentation site (if applicable)</li> </ol>"},{"location":"CONTRIBUTING/#recognition","title":"Recognition","text":"<p>Contributors are recognized in: - CONTRIBUTORS.md - GitHub contribution graphs - Release notes - Project documentation</p>"},{"location":"CONTRIBUTING/#questions","title":"Questions?","text":"<ul> <li>Check GitHub Discussions</li> <li>Read the documentation</li> <li>Join our community channels</li> </ul>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the Apache 2.0 License.</p> <p>Thank you for contributing to self-service data governance and compliance!</p>"},{"location":"DATA_GOVERNANCE/","title":"Data Governance with Lacuna","text":""},{"location":"DATA_GOVERNANCE/#self-service-governance-model","title":"Self-Service Governance Model","text":""},{"location":"DATA_GOVERNANCE/#the-challenge","title":"The Challenge","text":"<p>Traditional data governance faces a fundamental tension:</p> <p>Centralized Control - \u2713 Consistent policy enforcement - \u2713 Clear audit trails - \u2717 Bottlenecks slow innovation - \u2717 Users find workarounds</p> <p>Complete Self-Service - \u2713 Fast, autonomous data access - \u2713 Innovation enabled - \u2717 Compliance violations - \u2717 Data leaks and shadow IT</p> <p>Lacuna's Solution: Central teams define policies, users see violations in real-time and can self-correct</p>"},{"location":"DATA_GOVERNANCE/#core-principles","title":"Core Principles","text":""},{"location":"DATA_GOVERNANCE/#1-policy-as-code","title":"1. Policy-as-Code","text":"<p>Policies are defined declaratively in version control, not hidden in application logic:</p> <pre><code># policies/pii_export.rego\npackage governance\n\n# Default deny for safety\ndefault allow_export = false\n\n# Allow export if all conditions met\nallow_export {\n    # Data is not classified as PROPRIETARY\n    input.classification != \"PROPRIETARY\"\n\n    # OR user has explicit exemption\n    not input.classification == \"PROPRIETARY\"\n} {\n    # OR destination is approved\n    input.destination.type == \"governed_storage\"\n    input.destination.encrypted == true\n}\n\n# Provide alternatives when denied\nalternatives[msg] {\n    not allow_export\n    input.classification == \"PROPRIETARY\"\n    msg := \"Use anonymized version: lacuna.anonymize(data, pii_columns)\"\n} {\n    not allow_export\n    input.classification == \"PROPRIETARY\"\n    msg := sprintf(\"Save to governed location: %s\", [approved_paths[_]])\n}\n</code></pre> <p>Benefits: - Policies are versioned and auditable - Changes go through code review - Rollback is trivial (git revert) - Testing is automated</p>"},{"location":"DATA_GOVERNANCE/#2-real-time-feedback","title":"2. Real-Time Feedback","text":"<p>Users see policy violations before they happen, with actionable guidance:</p> <pre><code># User attempts operation\ndf.to_csv(\"~/Downloads/customers.csv\")\n\n# Lacuna intercepts and evaluates\n\u274c Governance Policy Violation\n\nAction: Export to ~/Downloads/customers.csv\nReason: Cannot export PROPRIETARY data to unmanaged location\nClassification: PROPRIETARY\nTags: PII, GDPR\n\nWhy this matters:\n- Contains customer PII (email, phone)\n- Destination is not encrypted or monitored\n- Violates GDPR data minimization principle\n\nHow to proceed:\n1. Anonymize first:\n   anon_df = lacuna.anonymize(df, columns=['email', 'phone', 'address'])\n   anon_df.to_csv(\"~/Downloads/customers_anon.csv\")\n\n2. Use governed location:\n   df.to_csv(\"/governed/workspace/customers.csv\")\n   # Automatically encrypted, access logged, retention enforced\n\n3. Request exception (requires business justification):\n   lacuna.request_exception(\n       data=df,\n       destination=\"~/Downloads/customers.csv\",\n       purpose=\"Customer analysis for Q4 board presentation\",\n       approver=\"data-steward@example.com\"\n   )\n\nPolicy: P-2024-001 (PII Export Restrictions)\nSteward: data-governance@example.com\nDocumentation: https://governance.example.com/policies/P-2024-001\n</code></pre> <p>Key insight: This isn't just an error message\u2014it's a learning moment. The user understands: - What they're doing wrong - Why the policy exists - How to achieve their goal compliantly</p>"},{"location":"DATA_GOVERNANCE/#3-classification-inheritance","title":"3. Classification Inheritance","text":"<p>Data classification propagates automatically through lineage:</p> <pre><code># Source data\ncustomers = pd.read_csv(\"customers.csv\")  # PROPRIETARY (PII)\nsales = pd.read_csv(\"sales.csv\")          # INTERNAL (revenue)\n\n# Operation: Join\nanalysis = customers.merge(sales, on=\"customer_id\")\n\n# Result classification\nprint(analysis.lacuna_classification)\n# \u2192 PROPRIETARY (inherits most restrictive parent)\n\nprint(analysis.lacuna_tags)\n# \u2192 ['PII', 'GDPR', 'FINANCIAL']  (union of parent tags)\n\nprint(analysis.lacuna_lineage)\n# \u2192 customers.csv \u2192 analysis\n#   sales.csv \u2192 analysis\n\n# Operation: Aggregation\nsummary = analysis.groupby('region')['revenue'].sum()\n\n# Result classification (downgraded by aggregation)\nprint(summary.lacuna_classification)\n# \u2192 INTERNAL (no individual PII in aggregates)\n\nprint(summary.lacuna_tags)\n# \u2192 ['FINANCIAL', 'DERIVED_FROM_PII']  (provenance preserved)\n</code></pre> <p>Classification Rules:</p> <ol> <li>Joins: Maximum classification of all sources</li> <li>Aggregations: May downgrade if no individual PII remains</li> <li>Filters: Inherit source classification</li> <li>Transformations: Inherit unless explicitly anonymized</li> <li>Exports: Classification travels with data</li> </ol>"},{"location":"DATA_GOVERNANCE/#4-graduated-access-tiers","title":"4. Graduated Access Tiers","text":"<p>Not all data requires the same level of control:</p> Tier Definition Examples Routing Retention PROPRIETARY Competitive secrets, regulated data Customer PII, pricing algorithms, strategic plans Local only, approval required for export 7+ years INTERNAL Internal use, not competitively sensitive Team processes, internal analytics, tool configurations Internal systems, no external sharing 1-3 years PUBLIC Publicly available or could be Open-source code, published docs, public research No restrictions 1 year minimum <p>Why three tiers? - Two tiers (sensitive/not-sensitive) are too coarse\u2014most data falls in middle - Four+ tiers create confusion and classification paralysis - Three tiers map naturally to organizational boundaries: external, internal, restricted</p>"},{"location":"DATA_GOVERNANCE/#implementation-architecture","title":"Implementation Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   User Data Operation                       \u2502\n\u2502  (read, write, join, export, transform)                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              1. Operation Interception                      \u2502\n\u2502                                                             \u2502\n\u2502  \u2022 File system: FUSE intercepts read/write                  \u2502\n\u2502  \u2022 Databases: SQLAlchemy middleware                         \u2502\n\u2502  \u2022 Notebooks: IPython magic commands                        \u2502\n\u2502  \u2022 dbt: Post-hooks in models                                \u2502\n\u2502  \u2022 APIs: HTTP proxy layer                                   \u2502\n\u2502                                                             \u2502\n\u2502  Captures: source, destination, action, user, context       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          2. Classification (3-layer pipeline)               \u2502\n\u2502                                                             \u2502\n\u2502  Layer 1: Heuristics (&lt;1ms) - 90% of operations             \u2502\n\u2502  \u251c\u2500 File path patterns: /pii/*, /customer/*                 \u2502\n\u2502  \u251c\u2500 Column name patterns: email, ssn, credit_card           \u2502\n\u2502  \u2514\u2500 Known sensitive terms from config                       \u2502\n\u2502                                                             \u2502\n\u2502  Layer 2: Embeddings (&lt;10ms) - 8% of operations             \u2502\n\u2502  \u251c\u2500 Semantic similarity to known examples                   \u2502\n\u2502  \u251c\u2500 Pre-computed embedding cache                            \u2502\n\u2502  \u2514\u2500 Vector search for closest match                         \u2502\n\u2502                                                             \u2502\n\u2502  Layer 3: LLM (&lt;200ms) - 2% of operations                   \u2502\n\u2502  \u251c\u2500 Complex context-dependent reasoning                     \u2502\n\u2502  \u251c\u2500 Multi-source lineage analysis                           \u2502\n\u2502  \u2514\u2500 Ambiguous cases requiring judgment                      \u2502\n\u2502                                                             \u2502\n\u2502  Output: Classification(tier, confidence, reasoning, tags)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            3. Lineage &amp; Provenance Tracking                 \u2502\n\u2502                                                             \u2502\n\u2502  \u2022 Extract lineage: source(s) \u2192 operation \u2192 destination     \u2502\n\u2502  \u2022 Apply inheritance rules:                                 \u2502\n\u2502    - Join: max(source classifications)                      \u2502\n\u2502    - Aggregate: evaluate if PII preserved                   \u2502\n\u2502    - Filter: inherit source                                 \u2502\n\u2502  \u2022 Propagate tags: union of all source tags                 \u2502\n\u2502  \u2022 Capture provenance:                                      \u2502\n\u2502    - Who: user_id, role, session                            \u2502\n\u2502    - What: operation type, sources, destination             \u2502\n\u2502    - When: timestamp (NTP-synchronized)                     \u2502\n\u2502    - Why: business purpose (if provided)                    \u2502\n\u2502    - How: transformation code, quality checks               \u2502\n\u2502                                                             \u2502\n\u2502  Output: DataOperation(classification, lineage, provenance) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              4. Policy Evaluation (OPA)                     \u2502\n\u2502                                                             \u2502\n\u2502  Query OPA with context:                                    \u2502\n\u2502  {                                                          \u2502\n\u2502    \"action\": \"export\",                                      \u2502\n\u2502    \"source\": {                                              \u2502\n\u2502      \"classification\": \"PROPRIETARY\",                       \u2502\n\u2502      \"tags\": [\"PII\", \"GDPR\"]                                \u2502\n\u2502    },                                                       \u2502\n\u2502    \"destination\": {                                         \u2502\n\u2502      \"type\": \"file\",                                        \u2502\n\u2502      \"path\": \"~/Downloads/export.csv\",                      \u2502\n\u2502      \"encrypted\": false                                     \u2502\n\u2502    },                                                       \u2502\n\u2502    \"user\": {                                                \u2502\n\u2502      \"id\": \"analyst_alice\",                                 \u2502\n\u2502      \"role\": \"data_analyst\",                                \u2502\n\u2502      \"clearance\": \"INTERNAL\"                                \u2502\n\u2502    },                                                       \u2502\n\u2502    \"lineage\": [\"customers.csv\", \"sales.csv\"]                \u2502\n\u2502  }                                                          \u2502\n\u2502                                                             \u2502\n\u2502  OPA returns:                                               \u2502\n\u2502  {                                                          \u2502\n\u2502    \"allow\": false,                                          \u2502\n\u2502    \"policy_id\": \"P-2024-001\",                               \u2502\n\u2502    \"reasoning\": \"Cannot export PROPRIETARY data...\",        \u2502\n\u2502    \"alternatives\": [...]                                    \u2502\n\u2502  }                                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              5. User Feedback &amp; Execution                   \u2502\n\u2502                                                             \u2502\n\u2502  If ALLOW:                                                  \u2502\n\u2502  \u251c\u2500 Execute operation                                       \u2502\n\u2502  \u251c\u2500 Log to audit trail                                      \u2502\n\u2502  \u2514\u2500 Update lineage graph                                    \u2502\n\u2502                                                             \u2502\n\u2502  If DENY:                                                   \u2502\n\u2502  \u251c\u2500 Block operation                                         \u2502\n\u2502  \u251c\u2500 Show detailed error with alternatives                   \u2502\n\u2502  \u251c\u2500 Log denial to audit trail                               \u2502\n\u2502  \u2514\u2500 Track for policy improvement                            \u2502\n\u2502                                                             \u2502\n\u2502  User can:                                                  \u2502\n\u2502  \u251c\u2500 Follow suggested alternative                            \u2502\n\u2502  \u251c\u2500 Request exception with justification                    \u2502\n\u2502  \u2514\u2500 Provide feedback on policy                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"DATA_GOVERNANCE/#policy-management","title":"Policy Management","text":""},{"location":"DATA_GOVERNANCE/#centralized-policy-definition","title":"Centralized Policy Definition","text":"<p>Policies are defined by governance team but distributed execution:</p> <pre><code># policies/data_export.rego\npackage governance.export\n\nimport future.keywords.if\nimport future.keywords.in\n\n# Policy metadata\nmetadata := {\n    \"id\": \"P-2024-001\",\n    \"title\": \"PII Export Restrictions\",\n    \"owner\": \"data-governance@example.com\",\n    \"compliance\": [\"GDPR\", \"CCPA\"],\n    \"version\": \"1.2.0\",\n    \"last_updated\": \"2025-01-15\"\n}\n\n# Helper: Check if data contains PII\ncontains_pii if {\n    \"PII\" in input.source.tags\n}\n\n# Helper: Check if destination is approved\napproved_destination if {\n    input.destination.type == \"governed_storage\"\n    input.destination.encrypted == true\n}\n\napproved_destination if {\n    input.destination.type == \"database\"\n    input.destination.classification_support == true\n}\n\n# Main policy: Allow export\ndefault allow := false\n\nallow if {\n    # Public data can go anywhere\n    input.source.classification == \"PUBLIC\"\n}\n\nallow if {\n    # Internal data to internal systems\n    input.source.classification == \"INTERNAL\"\n    input.destination.scope == \"internal\"\n}\n\nallow if {\n    # Proprietary data only to approved destinations\n    input.source.classification == \"PROPRIETARY\"\n    approved_destination\n}\n\nallow if {\n    # Exception granted by data steward\n    input.exception_approved == true\n    input.exception_approver_role == \"data_steward\"\n}\n\n# Provide helpful alternatives when denied\nalternatives[msg] {\n    not allow\n    contains_pii\n    msg := \"Anonymize PII: lacuna.anonymize(data, pii_columns=['email', 'phone', 'address'])\"\n}\n\nalternatives[msg] {\n    not allow\n    input.destination.type == \"file\"\n    msg := sprintf(\"Save to governed storage: %v\", [approved_paths[0]])\n}\n\nalternatives[msg] {\n    not allow\n    msg := \"Request exception: lacuna.request_exception(purpose='...', approver='data-steward@example.com')\"\n}\n\n# List of approved export paths\napproved_paths := [\n    \"/governed/workspace/\",\n    \"/governed/reports/\",\n    \"s3://company-governed-data/\"\n]\n</code></pre>"},{"location":"DATA_GOVERNANCE/#federated-policy-ownership","title":"Federated Policy Ownership","text":"<p>Domain teams can define domain-specific policies:</p> <pre><code># policies/marketing_domain.rego\npackage governance.domains.marketing\n\n# Marketing team owns policies for marketing data\nmetadata := {\n    \"domain\": \"marketing\",\n    \"owner\": \"marketing-data-lead@example.com\",\n    \"inherits\": [\"governance.export\"]  # Inherit corporate policies\n}\n\n# Domain-specific classification\nclassify_marketing_data[classification] {\n    input.source.table_name == \"campaigns\"\n    classification := {\n        \"tier\": \"INTERNAL\",\n        \"tags\": [\"MARKETING\", \"CAMPAIGN_DATA\"],\n        \"steward\": \"marketing-data-lead@example.com\"\n    }\n}\n\nclassify_marketing_data[classification] {\n    input.source.table_name == \"customer_segments\"\n    classification := {\n        \"tier\": \"PROPRIETARY\",  # Contains customer intelligence\n        \"tags\": [\"MARKETING\", \"PROPRIETARY\", \"CUSTOMER_INTELLIGENCE\"],\n        \"steward\": \"marketing-data-lead@example.com\"\n    }\n}\n\n# Marketing-specific export rules\nallow_marketing_export {\n    input.source.tags[_] == \"MARKETING\"\n    input.user.department == \"marketing\"\n    input.destination.type == \"marketing_automation_platform\"\n}\n</code></pre> <p>Benefits of federated ownership: - Central governance team defines meta-policies (e.g., \"PII requires approval\") - Domain teams define domain-specific rules (e.g., \"marketing can export to HubSpot\") - Scales policy management as organization grows - Domain expertise embedded in policies</p>"},{"location":"DATA_GOVERNANCE/#exception-management","title":"Exception Management","text":"<p>Sometimes users need to violate policies for legitimate reasons:</p> <pre><code>from lacuna import request_exception\n\n# User's code\ncustomers_df = pd.read_csv(\"customers.csv\")  # PROPRIETARY, PII\n\n# Attempt export (will be denied)\ncustomers_df.to_csv(\"~/Downloads/board_report.csv\")\n# \u274c Policy violation\n\n# Request exception with business justification\nexception = request_exception(\n    operation={\n        \"action\": \"export\",\n        \"source\": \"customers.csv\",\n        \"destination\": \"~/Downloads/board_report.csv\"\n    },\n    purpose=\"Board of Directors Q4 customer metrics presentation\",\n    business_justification=\"\"\"\n    Board requested customer growth metrics with specific examples.\n    Report will be presented in secure board room, then destroyed.\n    Duration: 2 hours (2025-01-20 14:00-16:00).\n    \"\"\",\n    approver=\"data-steward@example.com\",\n    duration_hours=2,\n    conditions=[\n        \"File will be encrypted\",\n        \"File will be deleted after presentation\",\n        \"No electronic copies will be made\"\n    ]\n)\n\n# Approval workflow\n# 1. Data steward receives notification\n# 2. Reviews justification and conditions\n# 3. Approves or denies with comments\n\n# If approved, user receives:\n\u2713 Exception Approved\n\nException ID: EXC-2025-001\nApproved by: jane.smith@example.com (Data Steward)\nValid: 2025-01-20 14:00 - 16:00 UTC\nConditions:\n  \u2022 File must be encrypted (AES-256)\n  \u2022 File must be deleted after use\n  \u2022 No electronic distribution\n\nTo proceed:\ncustomers_df.to_csv(\n    \"~/Downloads/board_report.csv\",\n    exception_id=\"EXC-2025-001\",\n    encrypt=True\n)\n\nReminder: Exception expires at 16:00 UTC. \nFile will be automatically deleted.\n</code></pre> <p>Exception audit trail: - All exceptions logged with full justification - Approver accountability - Automatic expiration - Compliance reports include exceptions</p>"},{"location":"DATA_GOVERNANCE/#measuring-success","title":"Measuring Success","text":""},{"location":"DATA_GOVERNANCE/#governance-metrics","title":"Governance Metrics","text":"<p>Policy Effectiveness: <pre><code>from lacuna.metrics import GovernanceMetrics\n\nmetrics = GovernanceMetrics(period=\"last_30_days\")\n\nprint(f\"Policy violation rate: {metrics.violation_rate}%\")\n# Target: &lt;2% (users mostly comply voluntarily)\n\nprint(f\"False positive rate: {metrics.false_positive_rate}%\")\n# Target: &lt;5% (policies aren't too restrictive)\n\nprint(f\"Average resolution time: {metrics.avg_resolution_time_minutes} min\")\n# Target: &lt;10min (users find compliant paths quickly)\n\nprint(f\"Exception request rate: {metrics.exception_rate}%\")\n# Target: &lt;1% (policies are practical)\n</code></pre></p> <p>User Satisfaction: <pre><code>print(f\"User satisfaction: {metrics.user_satisfaction}/5\")\n# Survey question: \"Governance tools help me work efficiently\"\n# Target: &gt;4.0/5\n\nprint(f\"Workaround attempts: {metrics.workaround_attempts}\")\n# Detection: Operations that match workaround patterns\n# Target: Trending downward\n</code></pre></p> <p>Compliance Coverage: <pre><code>print(f\"Data coverage: {metrics.data_coverage_percent}%\")\n# % of data assets under policy management\n# Target: &gt;80%\n\nprint(f\"Lineage completeness: {metrics.lineage_completeness_percent}%\")\n# % of data flows with complete lineage\n# Target: &gt;90% for critical data\n\nprint(f\"Audit completeness: {metrics.audit_completeness}%\")\n# % of operations captured in audit log\n# Target: 100% for regulated data\n</code></pre></p>"},{"location":"DATA_GOVERNANCE/#common-patterns","title":"Common Patterns","text":""},{"location":"DATA_GOVERNANCE/#pattern-1-development-vs-production","title":"Pattern 1: Development vs Production","text":"<p>Different policies for different environments:</p> <pre><code>package governance.environment_aware\n\nallow_looser_in_dev {\n    input.environment == \"development\"\n    input.source.classification == \"PROPRIETARY\"\n    input.destination.type == \"local_file\"\n    input.destination.path_prefix == \"/tmp/\"\n}\n\n# Stricter in production\nallow_strict_in_prod {\n    input.environment == \"production\"\n    input.source.classification == \"PROPRIETARY\"\n    input.destination.type == \"governed_storage\"\n    input.destination.encrypted == true\n}\n</code></pre>"},{"location":"DATA_GOVERNANCE/#pattern-2-time-based-access","title":"Pattern 2: Time-Based Access","text":"<p>Data available for limited time after collection:</p> <pre><code>package governance.time_based\n\nimport time\n\n# Customer data older than 90 days requires special access\nrequires_retention_approval {\n    input.source.tags[_] == \"CUSTOMER_DATA\"\n    data_age_days := time.diff_days(time.now_ns(), input.source.created_at)\n    data_age_days &gt; 90\n    not input.user.role == \"compliance_officer\"\n}\n</code></pre>"},{"location":"DATA_GOVERNANCE/#pattern-3-purpose-based-access","title":"Pattern 3: Purpose-Based Access","text":"<p>Same data, different rules based on purpose:</p> <pre><code>package governance.purpose_based\n\nallow_for_analytics {\n    input.purpose == \"analytics\"\n    input.source.tags[_] == \"CUSTOMER_DATA\"\n    input.destination.type == \"analytics_warehouse\"\n}\n\ndeny_for_marketing {\n    input.purpose == \"marketing\"\n    input.source.tags[_] == \"CUSTOMER_DATA\"\n    not input.user.consent_management_certified == true\n}\n</code></pre>"},{"location":"DATA_GOVERNANCE/#best-practices","title":"Best Practices","text":""},{"location":"DATA_GOVERNANCE/#1-start-small-scale-gradually","title":"1. Start Small, Scale Gradually","text":"<p>Phase 1: Single team, 5 policies, critical data only Phase 2: Multiple teams, 20 policies, most data covered Phase 3: Enterprise-wide, 50+ policies, all data governed</p> <p>Don't try to govern everything on day 1.</p>"},{"location":"DATA_GOVERNANCE/#2-make-compliant-paths-easier","title":"2. Make Compliant Paths Easier","text":"<p>Bad: Block everything, force exception requests Good: Provide pre-approved alternatives that are easier than non-compliant paths</p> <p>Example: <pre><code># Don't just block\n\u274c Cannot export PII\n\n# Provide easy alternative\n\u274c Cannot export raw PII\n\u2713 Use pre-anonymized version:\n  df_anon = lacuna.datasets.get(\"customers_anonymized\")\n  df_anon.to_csv(\"output.csv\")  # This just works\n</code></pre></p>"},{"location":"DATA_GOVERNANCE/#3-educate-through-errors","title":"3. Educate Through Errors","text":"<p>Every policy violation is a learning opportunity:</p> <pre><code># Bad error message\n\"Access denied: Policy P-123\"\n\n# Good error message\n\"\"\"\n\u274c Cannot export customer emails to external service\n\nWhy: Customer emails are PII protected under GDPR\nWhat: You're trying to send emails to api.external-service.com\nWho: This requires customer consent + data processing agreement\n\nLearn more: https://governance.example.com/gdpr/email-export\nQuestions: Ask #data-governance on Slack\n\"\"\"\n</code></pre>"},{"location":"DATA_GOVERNANCE/#4-measure-and-improve","title":"4. Measure and Improve","text":"<p>Track metrics, iterate on policies:</p> <ul> <li>High violation rate: Policies too strict or unclear</li> <li>High false positive rate: Classification needs tuning</li> <li>High exception rate: Policies don't match business needs</li> <li>Low user satisfaction: Friction too high</li> </ul> <p>Review quarterly, adjust based on data.</p>"},{"location":"DATA_GOVERNANCE/#5-balance-control-and-autonomy","title":"5. Balance Control and Autonomy","text":"<pre><code>Too much control \u2192 Shadow IT, workarounds, slow innovation\nToo much freedom \u2192 Compliance violations, data leaks, audit failures\n\nSweet spot \u2192 Clear guardrails, self-service within bounds\n</code></pre> <p>Lacuna aims for the sweet spot: governance that enables rather than blocks.</p>"},{"location":"DATA_GOVERNANCE/#integration-patterns","title":"Integration Patterns","text":""},{"location":"DATA_GOVERNANCE/#with-dbt","title":"With dbt","text":"<pre><code># dbt_project.yml\non-run-start:\n  - \"{{ lacuna.register_run() }}\"\n\non-run-end:\n  - \"{{ lacuna.verify_compliance() }}\"\n\nmodels:\n  my_project:\n    customer_analytics:\n      +post-hook: \"{{ lacuna.track_lineage() }}\"\n      +meta:\n        classification: PROPRIETARY\n        tags: [PII, CUSTOMER_DATA]\n</code></pre>"},{"location":"DATA_GOVERNANCE/#with-databricks","title":"With Databricks","text":"<pre><code># Databricks notebook\nspark.conf.set(\"spark.databricks.lacuna.enabled\", \"true\")\nspark.conf.set(\"spark.databricks.lacuna.policy_server\", \"http://lacuna:8181\")\n\n# All DataFrame operations automatically governed\ndf = spark.read.table(\"customers\")  # Classification: PROPRIETARY\ndf.write.saveAsTable(\"analytics.customer_summary\")  # Policy check\n</code></pre>"},{"location":"DATA_GOVERNANCE/#with-jupyter","title":"With Jupyter","text":"<pre><code># Cell 1: Load extension\n%load_ext lacuna\n\n# Cell 2: Configure\n%lacuna config --policy-server http://lacuna:8181\n\n# All subsequent cells are governed\ndf = pd.read_csv(\"customers.csv\")  # Auto-classified\ndf.to_csv(\"output.csv\")  # Policy-checked\n</code></pre>"},{"location":"DATA_GOVERNANCE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DATA_GOVERNANCE/#classification-takes-too-long","title":"\"Classification takes too long\"","text":"<p>Symptom: Operations delay 1-2 seconds</p> <p>Solution: Check cache hit rate <pre><code>from lacuna.metrics import CacheMetrics\nprint(CacheMetrics.hit_rate())  # Should be &gt;80%\n</code></pre></p> <p>If low, increase cache size or pre-warm cache: <pre><code>lacuna cache warmup --config config.yaml\n</code></pre></p>"},{"location":"DATA_GOVERNANCE/#false-positives-blocking-legitimate-work","title":"\"False positives blocking legitimate work\"","text":"<p>Symptom: Users complain about unnecessary blocks</p> <p>Solution: Review false positive reports <pre><code>from lacuna.admin import FalsePositiveReview\nFalsePositiveReview.generate_report(days=7)\n</code></pre></p> <p>Adjust policies or classification thresholds based on patterns.</p>"},{"location":"DATA_GOVERNANCE/#lineage-gaps","title":"\"Lineage gaps\"","text":"<p>Symptom: Downstream impact analysis incomplete</p> <p>Solution: Add manual lineage registration for custom code <pre><code>from lacuna import register_lineage\n\n# For operations Lacuna can't auto-detect\nregister_lineage(\n    source=[\"raw_data.csv\"],\n    destination=\"processed_data.csv\",\n    operation=\"custom_transformation\",\n    code=open(\"transform.py\").read()\n)\n</code></pre></p>"},{"location":"DATA_GOVERNANCE/#summary","title":"Summary","text":"<p>Lacuna's governance model achieves:</p> <p>\u2713 Self-service: Users work autonomously within guardrails \u2713 Compliance: Policies enforce automatically with audit trails \u2713 Transparency: Users see exactly what/why/how of decisions \u2713 Learning: System improves through user feedback \u2713 Scalability: Federated policy ownership as org grows</p> <p>Key insight: Governance isn't about saying \"no\"\u2014it's about making \"yes\" safe, traceable, and compliant.</p>"},{"location":"DEPLOYMENT/","title":"Production Deployment Guide","text":"<p>Lacuna - The protected space where your knowledge stays yours</p> <p>Deploy Lacuna in production with Docker, Kubernetes, and Helm for enterprise-scale privacy-aware RAG.</p> <p>For local development, see DEVELOPMENT.md for the lightweight dev mode that requires no external dependencies.</p>"},{"location":"DEPLOYMENT/#production-ready-configurations","title":"Production-Ready Configurations","text":"<p>The <code>deploy/</code> directory contains production-ready configurations:</p> <pre><code>deploy/\n\u251c\u2500\u2500 README.md                      # Deployment overview\n\u251c\u2500\u2500 docker/\n\u2502   \u251c\u2500\u2500 docker-compose.prod.yaml   # Production multi-replica setup\n\u2502   \u251c\u2500\u2500 docker-compose.ha.yaml     # High-availability (PostgreSQL replication, Redis Sentinel)\n\u2502   \u251c\u2500\u2500 nginx.conf                 # Load balancer with rate limiting\n\u2502   \u251c\u2500\u2500 .env.example               # Environment template\n\u2502   \u2514\u2500\u2500 init-db.sql                # Database initialization\n\u2502\n\u2514\u2500\u2500 helm/lacuna/\n    \u251c\u2500\u2500 Chart.yaml                 # Helm chart definition\n    \u251c\u2500\u2500 values.yaml                # Default values\n    \u251c\u2500\u2500 values-production.yaml     # Production values\n    \u2514\u2500\u2500 templates/                 # Kubernetes manifests\n</code></pre>"},{"location":"DEPLOYMENT/#quick-start-production-docker","title":"Quick Start (Production Docker)","text":"<pre><code># Copy and configure environment\ncp deploy/docker/.env.example deploy/docker/.env\n# Edit deploy/docker/.env with production values\n\n# Start production stack (2 API replicas, Nginx load balancer)\ndocker compose -f deploy/docker/docker-compose.prod.yaml up -d\n\n# Run database migrations\ndocker compose -f deploy/docker/docker-compose.prod.yaml --profile migrate up migrate\n\n# Scale API replicas\ndocker compose -f deploy/docker/docker-compose.prod.yaml up -d --scale lacuna-api=5\n</code></pre>"},{"location":"DEPLOYMENT/#quick-start-high-availability","title":"Quick Start (High Availability)","text":"<pre><code># HA setup includes:\n# - 3 API replicas\n# - PostgreSQL primary + 2 replicas with PgPool\n# - Redis master + 2 replicas with Sentinel\ndocker compose -f deploy/docker/docker-compose.ha.yaml up -d\n</code></pre>"},{"location":"DEPLOYMENT/#quick-start-kuberneteshelm","title":"Quick Start (Kubernetes/Helm)","text":"<pre><code># Add Bitnami repo for PostgreSQL/Redis dependencies\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm dependency update ./deploy/helm/lacuna\n\n# Install with production values\nhelm install lacuna ./deploy/helm/lacuna \\\n  -f deploy/helm/lacuna/values-production.yaml \\\n  --set secrets.databasePassword=YOUR_PASSWORD \\\n  --set secrets.redisPassword=YOUR_PASSWORD \\\n  --set ingress.hosts[0].host=lacuna.yourdomain.com\n</code></pre>"},{"location":"DEPLOYMENT/#deployment-options","title":"Deployment Options","text":"Method Best For Complexity Scale pip install Development, single machine Low 1 node Docker Testing, simple production Low 1-3 containers Docker Compose Multi-service development Medium 1 node Kubernetes Production, enterprise High Multi-node Helm Chart Production, GitOps Medium Multi-node"},{"location":"DEPLOYMENT/#quick-start","title":"Quick Start","text":""},{"location":"DEPLOYMENT/#pip-installation","title":"pip Installation","text":"<pre><code># Install Lacuna\npip install lacuna\n\n# With optional dependencies\npip install lacuna[all]  # Everything\npip install lacuna[plugins-enterprise]  # Enterprise plugins\npip install lacuna[llamaindex,langchain]  # Framework integrations\n\n# Verify installation\nlacuna --version\nlacuna config validate\n</code></pre>"},{"location":"DEPLOYMENT/#docker","title":"Docker","text":"<pre><code># Pull from GitHub Container Registry\ndocker pull ghcr.io/witlox/lacuna:latest\n\n# Run with config volume\ndocker run -d \\\n  --name lacuna \\\n  -p 8000:8000 \\\n  -v $(pwd)/config:/app/config \\\n  -v $(pwd)/data:/app/data \\\n  -e LACUNA_CONFIG_PATH=/app/config \\\n  ghcr.io/witlox/lacuna:latest\n\n# Check health\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"DEPLOYMENT/#docker-compose","title":"Docker Compose","text":"<pre><code># Clone repository\ngit clone https://github.com/witlox/lacuna.git\ncd lacuna\n\n# Start stack\ndocker-compose up -d\n\n# Verify services\ndocker-compose ps\n</code></pre>"},{"location":"DEPLOYMENT/#docker-deployment","title":"Docker Deployment","text":""},{"location":"DEPLOYMENT/#official-images","title":"Official Images","text":"<pre><code># Available tags\nghcr.io/witlox/lacuna:latest           # Latest stable\nghcr.io/witlox/lacuna:0.1.0            # Specific version\nghcr.io/witlox/lacuna:0.1.0-slim       # Minimal (no GPU)\nghcr.io/witlox/lacuna:0.1.0-gpu        # With CUDA support\n</code></pre>"},{"location":"DEPLOYMENT/#dockerfile","title":"Dockerfile","text":"<pre><code># Base image with Python 3.11\nFROM python:3.11-slim as base\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    build-essential \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy requirements\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application\nCOPY lacuna/ ./lacuna/\nCOPY config/ ./config/\n\n# Create non-root user\nRUN useradd -m -u 1000 lacuna &amp;&amp; \\\n    chown -R lacuna:lacuna /app\n\nUSER lacuna\n\n# Expose API port\nEXPOSE 8000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n\n# Run classifier service\nCMD [\"python\", \"-m\", \"lacuna.server\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"DEPLOYMENT/#gpu-enabled-dockerfile","title":"GPU-Enabled Dockerfile","text":"<pre><code>FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04 as base\n\n# Install Python\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    python3.11 \\\n    python3-pip \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\n# Install PyTorch with CUDA support\nRUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n\n# Copy and install requirements\nCOPY requirements.txt .\nRUN pip3 install --no-cache-dir -r requirements.txt\n\n# Copy application\nCOPY lacuna/ ./lacuna/\nCOPY config/ ./config/\n\n# Expose port\nEXPOSE 8000\n\n# Run with GPU\nCMD [\"python3\", \"-m\", \"lacuna.server\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--device\", \"cuda\"]\n</code></pre>"},{"location":"DEPLOYMENT/#environment-variables","title":"Environment Variables","text":"<pre><code># Core configuration\nLACUNA_CONFIG_PATH=/app/config\nLACUNA_LOG_LEVEL=INFO\nLACUNA_LOG_FORMAT=json\n\n# Database\nLACUNA_POSTGRES_URL=postgresql://user:pass@postgres:5432/lacuna\nLACUNA_POSTGRES_POOL_SIZE=20\n\n# LLM backend\nLACUNA_LLM_BACKEND=vllm\nLACUNA_LLM_ENDPOINT=http://vllm:8000\nLACUNA_LLM_MODEL=meta-llama/Llama-3.1-70B-Instruct\n\n# Embeddings\nLACUNA_EMBEDDING_MODEL=BAAI/bge-large-en-v1.5\nLACUNA_EMBEDDING_DEVICE=cuda\n\n# Cache\nLACUNA_REDIS_URL=redis://redis:6379\nLACUNA_CACHE_TTL=3600\n\n# Metrics\nLACUNA_PROMETHEUS_PORT=9090\nLACUNA_LOKI_URL=http://loki:3100\n\n# Security\nLACUNA_API_KEY=${LACUNA_API_KEY}\nLACUNA_VAULT_URL=http://vault:8200\nLACUNA_VAULT_TOKEN=${VAULT_TOKEN}\n</code></pre>"},{"location":"DEPLOYMENT/#docker-compose-stack","title":"Docker Compose Stack","text":"<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  # Lacuna classifier service\n  lacuna:\n    image: ghcr.io/witlox/lacuna:latest\n    container_name: lacuna\n    ports:\n      - \"8000:8000\"  # API\n      - \"9090:9090\"  # Prometheus metrics\n    volumes:\n      - ./config:/app/config:ro\n      - ./data:/app/data\n    environment:\n      - LACUNA_CONFIG_PATH=/app/config\n      - LACUNA_LOG_LEVEL=INFO\n      - LACUNA_POSTGRES_URL=postgresql://lacuna:${POSTGRES_PASSWORD}@postgres:5432/lacuna\n      - LACUNA_REDIS_URL=redis://redis:6379\n      - LACUNA_LLM_ENDPOINT=http://vllm:8000\n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_started\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # PostgreSQL for lineage/audit\n  postgres:\n    image: postgres:16-alpine\n    container_name: lacuna-postgres\n    environment:\n      - POSTGRES_DB=lacuna\n      - POSTGRES_USER=lacuna\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./migrations:/docker-entrypoint-initdb.d:ro\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U lacuna\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # Redis for caching\n  redis:\n    image: redis:7-alpine\n    container_name: lacuna-redis\n    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru\n    volumes:\n      - redis-data:/data\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # Qdrant vector database\n  qdrant:\n    image: qdrant/qdrant:latest\n    container_name: lacuna-qdrant\n    ports:\n      - \"6333:6333\"\n    volumes:\n      - qdrant-data:/qdrant/storage\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # vLLM for LLM backend (requires GPU)\n  vllm:\n    image: vllm/vllm-openai:latest\n    container_name: lacuna-vllm\n    ports:\n      - \"8001:8000\"\n    environment:\n      - CUDA_VISIBLE_DEVICES=0,1,2,3  # 4 GPUs\n    command: &gt;\n      --model meta-llama/Llama-3.1-70B-Instruct\n      --tensor-parallel-size 4\n      --max-model-len 32768\n      --gpu-memory-utilization 0.95\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 4\n              capabilities: [gpu]\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # OPA for policy-as-code\n  opa:\n    image: openpolicyagent/opa:latest\n    container_name: lacuna-opa\n    ports:\n      - \"8181:8181\"\n    command: run --server --addr :8181 /policies\n    volumes:\n      - ./policies:/policies:ro\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # Prometheus for metrics\n  prometheus:\n    image: prom/prometheus:latest\n    container_name: lacuna-prometheus\n    ports:\n      - \"9091:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro\n      - prometheus-data:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # Loki for logs\n  loki:\n    image: grafana/loki:latest\n    container_name: lacuna-loki\n    ports:\n      - \"3100:3100\"\n    volumes:\n      - ./loki-config.yml:/etc/loki/local-config.yaml:ro\n      - loki-data:/loki\n    command: -config.file=/etc/loki/local-config.yaml\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # Grafana for visualization\n  grafana:\n    image: grafana/grafana:latest\n    container_name: lacuna-grafana\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}\n    volumes:\n      - grafana-data:/var/lib/grafana\n      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro\n      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\n  # Vault for secrets\n  vault:\n    image: hashicorp/vault:latest\n    container_name: lacuna-vault\n    ports:\n      - \"8200:8200\"\n    environment:\n      - VAULT_DEV_ROOT_TOKEN_ID=${VAULT_TOKEN}\n      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200\n    cap_add:\n      - IPC_LOCK\n    restart: unless-stopped\n    networks:\n      - lacuna-net\n\nvolumes:\n  postgres-data:\n  redis-data:\n  qdrant-data:\n  prometheus-data:\n  loki-data:\n  grafana-data:\n\nnetworks:\n  lacuna-net:\n    driver: bridge\n</code></pre>"},{"location":"DEPLOYMENT/#starting-the-stack","title":"Starting the Stack","text":"<pre><code># Create .env file\ncat &gt; .env &lt;&lt;EOF\nPOSTGRES_PASSWORD=your_secure_password\nGRAFANA_PASSWORD=your_grafana_password\nVAULT_TOKEN=your_vault_token\nLACUNA_API_KEY=your_api_key\nEOF\n\n# Start all services\ndocker-compose up -d\n\n# Check status\ndocker-compose ps\n\n# View logs\ndocker-compose logs -f lacuna\n\n# Stop services\ndocker-compose down\n\n# Stop and remove volumes\ndocker-compose down -v\n</code></pre>"},{"location":"DEPLOYMENT/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"DEPLOYMENT/#prerequisites","title":"Prerequisites","text":"<pre><code># Kubernetes 1.25+\nkubectl version\n\n# Helm 3.10+\nhelm version\n\n# Storage class for persistent volumes\nkubectl get storageclass\n</code></pre>"},{"location":"DEPLOYMENT/#namespace-setup","title":"Namespace Setup","text":"<pre><code># namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: lacuna\n  labels:\n    name: lacuna\n    monitoring: enabled\n</code></pre> <pre><code>kubectl apply -f namespace.yaml\n</code></pre>"},{"location":"DEPLOYMENT/#configmaps","title":"ConfigMaps","text":"<pre><code># configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: lacuna-config\n  namespace: lacuna\ndata:\n  config.yaml: |\n    classification:\n      strategy: conservative\n      layers:\n        heuristic:\n          enabled: true\n          priority: 1\n        embedding:\n          enabled: true\n          priority: 2\n          model: BAAI/bge-large-en-v1.5\n        llm:\n          enabled: true\n          priority: 3\n          endpoint: http://vllm:8000\n\n    routing:\n      PROPRIETARY:\n        local_rag: true\n        web_search: false\n      INTERNAL:\n        local_rag: true\n        web_search: false\n      PUBLIC:\n        local_rag: true\n        web_search: true\n\n    lineage:\n      enabled: true\n      postgres_url: postgresql://lacuna:password@postgres:5432/lacuna\n      sampling_rate: 1.0\n\n    cache:\n      enabled: true\n      redis_url: redis://redis:6379\n      ttl: 3600\n\n    metrics:\n      enabled: true\n      prometheus_port: 9090\n\n    logging:\n      level: INFO\n      format: json\n      loki_url: http://loki:3100\n\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: lacuna-proprietary-terms\n  namespace: lacuna\ndata:\n  proprietary_terms.yaml: |\n    projects:\n      - project_apollo\n      - project_artemis\n      - skunkworks\n\n    customers:\n      - customer_alpha\n      - customer_beta\n      - vip_client\n\n    internal_terms:\n      - confidential\n      - internal only\n      - do not distribute\n</code></pre>"},{"location":"DEPLOYMENT/#secrets","title":"Secrets","text":"<pre><code># Create secrets from files\nkubectl create secret generic lacuna-secrets \\\n  --from-literal=postgres-password=your_secure_password \\\n  --from-literal=api-key=your_api_key \\\n  --from-literal=kagi-api-key=your_kagi_key \\\n  --namespace=lacuna\n\n# Or from YAML\nkubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: lacuna-secrets\n  namespace: lacuna\ntype: Opaque\nstringData:\n  postgres-password: your_secure_password\n  api-key: your_api_key\n  kagi-api-key: your_kagi_key\nEOF\n</code></pre>"},{"location":"DEPLOYMENT/#deployments","title":"Deployments","text":"<pre><code># deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lacuna-classifier\n  namespace: lacuna\n  labels:\n    app: lacuna\n    component: classifier\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: lacuna\n      component: classifier\n  template:\n    metadata:\n      labels:\n        app: lacuna\n        component: classifier\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"9090\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1000\n        fsGroup: 1000\n\n      containers:\n      - name: lacuna\n        image: ghcr.io/witlox/lacuna:0.1.0\n        imagePullPolicy: IfNotPresent\n\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n        - name: metrics\n          containerPort: 9090\n          protocol: TCP\n\n        env:\n        - name: LACUNA_CONFIG_PATH\n          value: /app/config\n        - name: LACUNA_LOG_LEVEL\n          value: INFO\n        - name: LACUNA_POSTGRES_URL\n          value: postgresql://lacuna:$(POSTGRES_PASSWORD)@postgres:5432/lacuna\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: lacuna-secrets\n              key: postgres-password\n        - name: LACUNA_REDIS_URL\n          value: redis://redis:6379\n        - name: LACUNA_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: lacuna-secrets\n              key: api-key\n\n        volumeMounts:\n        - name: config\n          mountPath: /app/config\n          readOnly: true\n        - name: proprietary-terms\n          mountPath: /app/config/proprietary_terms.yaml\n          subPath: proprietary_terms.yaml\n          readOnly: true\n\n        resources:\n          requests:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n          limits:\n            memory: \"8Gi\"\n            cpu: \"4000m\"\n\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: http\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: http\n          initialDelaySeconds: 10\n          periodSeconds: 5\n          timeoutSeconds: 3\n          failureThreshold: 3\n\n      volumes:\n      - name: config\n        configMap:\n          name: lacuna-config\n      - name: proprietary-terms\n        configMap:\n          name: lacuna-proprietary-terms\n\n---\n# vLLM deployment (requires GPU nodes)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vllm\n  namespace: lacuna\n  labels:\n    app: lacuna\n    component: llm\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lacuna\n      component: llm\n  template:\n    metadata:\n      labels:\n        app: lacuna\n        component: llm\n    spec:\n      nodeSelector:\n        nvidia.com/gpu: \"true\"  # Schedule on GPU nodes\n\n      containers:\n      - name: vllm\n        image: vllm/vllm-openai:latest\n\n        ports:\n        - name: http\n          containerPort: 8000\n          protocol: TCP\n\n        env:\n        - name: CUDA_VISIBLE_DEVICES\n          value: \"0,1,2,3\"\n\n        command:\n        - python\n        - -m\n        - vllm.entrypoints.openai.api_server\n        - --model\n        - meta-llama/Llama-3.1-70B-Instruct\n        - --tensor-parallel-size\n        - \"4\"\n        - --max-model-len\n        - \"32768\"\n        - --gpu-memory-utilization\n        - \"0.95\"\n\n        resources:\n          requests:\n            nvidia.com/gpu: 4\n            memory: \"200Gi\"\n            cpu: \"16\"\n          limits:\n            nvidia.com/gpu: 4\n            memory: \"256Gi\"\n            cpu: \"32\"\n\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          timeoutSeconds: 10\n</code></pre>"},{"location":"DEPLOYMENT/#services","title":"Services","text":"<pre><code># service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: lacuna\n  namespace: lacuna\n  labels:\n    app: lacuna\n    component: classifier\nspec:\n  type: ClusterIP\n  selector:\n    app: lacuna\n    component: classifier\n  ports:\n  - name: http\n    port: 8000\n    targetPort: http\n    protocol: TCP\n  - name: metrics\n    port: 9090\n    targetPort: metrics\n    protocol: TCP\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: vllm\n  namespace: lacuna\n  labels:\n    app: lacuna\n    component: llm\nspec:\n  type: ClusterIP\n  selector:\n    app: lacuna\n    component: llm\n  ports:\n  - name: http\n    port: 8000\n    targetPort: http\n    protocol: TCP\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgres\n  namespace: lacuna\nspec:\n  type: ClusterIP\n  selector:\n    app: postgres\n  ports:\n  - port: 5432\n    targetPort: 5432\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis\n  namespace: lacuna\nspec:\n  type: ClusterIP\n  selector:\n    app: redis\n  ports:\n  - port: 6379\n    targetPort: 6379\n</code></pre>"},{"location":"DEPLOYMENT/#ingress","title":"Ingress","text":"<pre><code># ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: lacuna\n  namespace: lacuna\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/rate-limit: \"100\"\n    nginx.ingress.kubernetes.io/auth-type: basic\n    nginx.ingress.kubernetes.io/auth-secret: lacuna-basic-auth\nspec:\n  tls:\n  - hosts:\n    - lacuna.example.com\n    secretName: lacuna-tls\n  rules:\n  - host: lacuna.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: lacuna\n            port:\n              number: 8000\n</code></pre>"},{"location":"DEPLOYMENT/#apply-kubernetes-manifests","title":"Apply Kubernetes Manifests","text":"<pre><code># Apply all manifests\nkubectl apply -f namespace.yaml\nkubectl apply -f configmap.yaml\nkubectl apply -f secrets.yaml\nkubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\nkubectl apply -f ingress.yaml\n\n# Check deployment\nkubectl get pods -n lacuna\nkubectl logs -f deployment/lacuna-classifier -n lacuna\n\n# Check services\nkubectl get svc -n lacuna\n\n# Test service\nkubectl port-forward svc/lacuna 8000:8000 -n lacuna\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"DEPLOYMENT/#helm-deployment","title":"Helm Deployment","text":""},{"location":"DEPLOYMENT/#install-helm-chart","title":"Install Helm Chart","text":"<pre><code># Add Lacuna Helm repository\nhelm repo add lacuna https://witlox.github.io/lacuna-helm\nhelm repo update\n\n# Install with default values\nhelm install lacuna lacuna/lacuna --namespace lacuna --create-namespace\n\n# Install with custom values\nhelm install lacuna lacuna/lacuna \\\n  --namespace lacuna \\\n  --create-namespace \\\n  --values values.yaml\n\n# Upgrade\nhelm upgrade lacuna lacuna/lacuna \\\n  --namespace lacuna \\\n  --values values.yaml\n\n# Uninstall\nhelm uninstall lacuna --namespace lacuna\n</code></pre>"},{"location":"DEPLOYMENT/#custom-values","title":"Custom Values","text":"<pre><code># values.yaml\n\n# Image configuration\nimage:\n  repository: ghcr.io/witlox/lacuna\n  tag: \"0.1.0\"\n  pullPolicy: IfNotPresent\n\n# Replicas\nreplicaCount: 3\n\n# Resources\nresources:\n  requests:\n    memory: \"4Gi\"\n    cpu: \"2\"\n  limits:\n    memory: \"8Gi\"\n    cpu: \"4\"\n\n# Autoscaling\nautoscaling:\n  enabled: true\n  minReplicas: 3\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 70\n  targetMemoryUtilizationPercentage: 80\n\n# Configuration\nconfig:\n  classification:\n    strategy: conservative\n\n  routing:\n    proprietary:\n      local_rag: true\n      web_search: false\n    public:\n      local_rag: true\n      web_search: true\n\n# Proprietary terms\nproprietaryTerms:\n  projects:\n    - project_apollo\n    - project_artemis\n  customers:\n    - customer_alpha\n\n# PostgreSQL (for lineage)\npostgresql:\n  enabled: true\n  auth:\n    username: lacuna\n    password: changeme\n    database: lacuna\n  primary:\n    persistence:\n      enabled: true\n      size: 20Gi\n  resources:\n    requests:\n      memory: \"2Gi\"\n      cpu: \"1\"\n    limits:\n      memory: \"4Gi\"\n      cpu: \"2\"\n\n# Redis (for caching)\nredis:\n  enabled: true\n  auth:\n    enabled: false\n  master:\n    persistence:\n      enabled: true\n      size: 8Gi\n  resources:\n    requests:\n      memory: \"2Gi\"\n      cpu: \"500m\"\n    limits:\n      memory: \"4Gi\"\n      cpu: \"1\"\n\n# Qdrant (vector database)\nqdrant:\n  enabled: true\n  persistence:\n    enabled: true\n    size: 50Gi\n  resources:\n    requests:\n      memory: \"8Gi\"\n      cpu: \"2\"\n    limits:\n      memory: \"16Gi\"\n      cpu: \"4\"\n\n# vLLM (LLM backend)\nvllm:\n  enabled: true\n  model: \"meta-llama/Llama-3.1-70B-Instruct\"\n  tensorParallelSize: 4\n  maxModelLen: 32768\n  gpuMemoryUtilization: 0.95\n\n  nodeSelector:\n    nvidia.com/gpu: \"true\"\n\n  resources:\n    requests:\n      nvidia.com/gpu: 4\n      memory: \"200Gi\"\n      cpu: \"16\"\n    limits:\n      nvidia.com/gpu: 4\n      memory: \"256Gi\"\n      cpu: \"32\"\n\n# OPA (policy-as-code)\nopa:\n  enabled: true\n  policies:\n    base: |\n      package lacuna.classification\n      # Policy content here\n\n# Monitoring\nmonitoring:\n  enabled: true\n  prometheus:\n    enabled: true\n  grafana:\n    enabled: true\n    adminPassword: changeme\n  loki:\n    enabled: true\n\n# Ingress\ningress:\n  enabled: true\n  className: nginx\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n  hosts:\n    - host: lacuna.example.com\n      paths:\n        - path: /\n          pathType: Prefix\n  tls:\n    - secretName: lacuna-tls\n      hosts:\n        - lacuna.example.com\n\n# Security\nsecurity:\n  apiKey:\n    enabled: true\n    existingSecret: lacuna-secrets\n    key: api-key\n\n  vault:\n    enabled: true\n    address: http://vault:8200\n    token: changeme\n\n# Service\nservice:\n  type: ClusterIP\n  port: 8000\n  metricsPort: 9090\n</code></pre>"},{"location":"DEPLOYMENT/#deploy-with-helm","title":"Deploy with Helm","text":"<pre><code># Create values file\ncat &gt; my-values.yaml &lt;&lt;EOF\nreplicaCount: 5\n\npostgresql:\n  auth:\n    password: $(openssl rand -base64 32)\n\ngrafana:\n  adminPassword: $(openssl rand -base64 16)\n\ningress:\n  hosts:\n    - host: lacuna.mycompany.com\n      paths:\n        - path: /\n          pathType: Prefix\n  tls:\n    - secretName: lacuna-tls\n      hosts:\n        - lacuna.mycompany.com\nEOF\n\n# Install\nhelm install lacuna lacuna/lacuna \\\n  --namespace lacuna \\\n  --create-namespace \\\n  --values my-values.yaml\n\n# Check status\nhelm status lacuna -n lacuna\nkubectl get pods -n lacuna\n</code></pre>"},{"location":"DEPLOYMENT/#production-checklist","title":"Production Checklist","text":""},{"location":"DEPLOYMENT/#security","title":"Security","text":"<ul> <li> Change all default passwords</li> <li> Enable TLS/SSL for all services</li> <li> Configure network policies</li> <li> Enable pod security policies</li> <li> Set up RBAC</li> <li> Use secrets management (Vault)</li> <li> Enable API authentication</li> <li> Configure rate limiting</li> <li> Set up audit logging</li> </ul>"},{"location":"DEPLOYMENT/#high-availability","title":"High Availability","text":"<ul> <li> Deploy multiple replicas (\u22653)</li> <li> Configure pod anti-affinity</li> <li> Set up horizontal pod autoscaling</li> <li> Configure liveness/readiness probes</li> <li> Set resource requests/limits</li> <li> Enable persistent storage</li> <li> Configure backup/restore</li> </ul>"},{"location":"DEPLOYMENT/#monitoring","title":"Monitoring","text":"<ul> <li> Deploy Prometheus</li> <li> Deploy Grafana with dashboards</li> <li> Configure alerting rules</li> <li> Set up Loki for logs</li> <li> Enable distributed tracing</li> <li> Configure health checks</li> <li> Set up uptime monitoring</li> </ul>"},{"location":"DEPLOYMENT/#performance","title":"Performance","text":"<ul> <li> Enable Redis caching</li> <li> Configure connection pooling</li> <li> Optimize resource allocation</li> <li> Set up CDN (if applicable)</li> <li> Enable compression</li> <li> Configure query timeouts</li> <li> Tune PostgreSQL</li> </ul>"},{"location":"DEPLOYMENT/#compliance","title":"Compliance","text":"<ul> <li> Enable audit logging</li> <li> Configure data retention</li> <li> Set up lineage tracking</li> <li> Document privacy policies</li> <li> Enable encryption at rest</li> <li> Configure access controls</li> <li> Set up compliance dashboards</li> </ul>"},{"location":"DEPLOYMENT/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"DEPLOYMENT/#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code># prometheus-rules.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-rules\n  namespace: lacuna\ndata:\n  lacuna.rules: |\n    groups:\n    - name: lacuna\n      interval: 30s\n      rules:\n\n      # High error rate\n      - alert: HighErrorRate\n        expr: rate(lacuna_classification_errors_total[5m]) &gt; 0.01\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High classification error rate\"\n          description: \"Error rate is {{ $value }} errors/sec\"\n\n      # High latency\n      - alert: HighLatency\n        expr: histogram_quantile(0.95, lacuna_classification_latency_seconds_bucket) &gt; 1.0\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High classification latency\"\n          description: \"P95 latency is {{ $value }} seconds\"\n\n      # Low cache hit rate\n      - alert: LowCacheHitRate\n        expr: rate(lacuna_cache_hits_total[5m]) / (rate(lacuna_cache_hits_total[5m]) + rate(lacuna_cache_misses_total[5m])) &lt; 0.7\n        for: 10m\n        labels:\n          severity: info\n        annotations:\n          summary: \"Low cache hit rate\"\n          description: \"Cache hit rate is {{ $value }}%\"\n</code></pre>"},{"location":"DEPLOYMENT/#grafana-dashboards","title":"Grafana Dashboards","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Lacuna Production\",\n    \"panels\": [\n      {\n        \"title\": \"Requests/sec\",\n        \"targets\": [{\n          \"expr\": \"rate(lacuna_requests_total[5m])\"\n        }]\n      },\n      {\n        \"title\": \"P95 Latency\",\n        \"targets\": [{\n          \"expr\": \"histogram_quantile(0.95, lacuna_classification_latency_seconds_bucket)\"\n        }]\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"targets\": [{\n          \"expr\": \"rate(lacuna_classification_errors_total[5m])\"\n        }]\n      },\n      {\n        \"title\": \"Tier Distribution\",\n        \"targets\": [{\n          \"expr\": \"sum by (tier) (rate(lacuna_classification_tier_total[5m]))\"\n        }]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"DEPLOYMENT/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DEPLOYMENT/#pod-crashes","title":"Pod Crashes","text":"<pre><code># Check pod status\nkubectl get pods -n lacuna\n\n# View logs\nkubectl logs -f deployment/lacuna-classifier -n lacuna\n\n# Describe pod\nkubectl describe pod lacuna-classifier-xxx -n lacuna\n\n# Check events\nkubectl get events -n lacuna --sort-by='.lastTimestamp'\n</code></pre>"},{"location":"DEPLOYMENT/#database-issues","title":"Database Issues","text":"<pre><code># Check PostgreSQL connectivity\nkubectl exec -it deployment/lacuna-classifier -n lacuna -- \\\n  psql postgresql://lacuna:password@postgres:5432/lacuna -c \"SELECT 1;\"\n\n# Check database size\nkubectl exec -it postgres-0 -n lacuna -- \\\n  psql -U lacuna -c \"SELECT pg_size_pretty(pg_database_size('lacuna'));\"\n</code></pre>"},{"location":"DEPLOYMENT/#performance-issues","title":"Performance Issues","text":"<pre><code># Check resource usage\nkubectl top pods -n lacuna\n\n# Check HPA status\nkubectl get hpa -n lacuna\n\n# View metrics\nkubectl port-forward svc/lacuna 9090:9090 -n lacuna\ncurl http://localhost:9090/metrics\n</code></pre>"},{"location":"DEPLOYMENT/#authentication","title":"Authentication","text":"<p>Lacuna supports two authentication methods, designed for enterprise deployment behind a reverse proxy or API gateway.</p>"},{"location":"DEPLOYMENT/#authentication-methods","title":"Authentication Methods","text":"Method Use Case Header/Mechanism Reverse Proxy Headers Human users via OIDC/SSO X-User, X-Email, X-Groups API Keys Service accounts, automation Authorization: Bearer lac_xxx"},{"location":"DEPLOYMENT/#reverse-proxy-authentication-oidcsso","title":"Reverse Proxy Authentication (OIDC/SSO)","text":"<p>In production, Lacuna runs behind a reverse proxy (oauth2-proxy, Traefik, nginx-oidc, etc.) that handles authentication and forwards user identity via headers:</p> <pre><code># Environment variables (config)\nLACUNA_AUTH_USER_HEADER=X-User         # User ID header\nLACUNA_AUTH_EMAIL_HEADER=X-Email       # Email header\nLACUNA_AUTH_GROUPS_HEADER=X-Groups     # Comma-separated groups\nLACUNA_AUTH_NAME_HEADER=X-Name         # Display name header\nLACUNA_AUTH_ADMIN_GROUP=lacuna-admins  # Group for admin access\n</code></pre> <p>Example nginx configuration with oauth2-proxy:</p> <pre><code>location / {\n    auth_request /oauth2/auth;\n    auth_request_set $user   $upstream_http_x_auth_request_user;\n    auth_request_set $email  $upstream_http_x_auth_request_email;\n    auth_request_set $groups $upstream_http_x_auth_request_groups;\n\n    proxy_set_header X-User $user;\n    proxy_set_header X-Email $email;\n    proxy_set_header X-Groups $groups;\n\n    proxy_pass http://lacuna:8000;\n}\n</code></pre>"},{"location":"DEPLOYMENT/#api-key-authentication-service-accounts","title":"API Key Authentication (Service Accounts)","text":"<p>For service accounts (dbt, CI/CD pipelines, Databricks), use API keys:</p> <ol> <li>Create via Admin UI: Navigate to Admin &gt; API Keys</li> <li> <p>Create via CLI:    <pre><code>lacuna admin apikey create \\\n  --name \"dbt-production\" \\\n  --service-account \"svc-dbt\" \\\n  --groups \"data-engineers\"\n</code></pre></p> </li> <li> <p>Use in requests:    <pre><code>curl -H \"Authorization: Bearer lac_your_key_here\" \\\n     https://lacuna.example.com/api/v1/classify\n</code></pre></p> </li> </ol> <p>API key format: <code>lac_</code> prefix followed by 32+ secure random characters.</p>"},{"location":"DEPLOYMENT/#role-based-access-control","title":"Role-Based Access Control","text":"Role Access Determined By Admin Full access, API key management, config Member of <code>lacuna-admins</code> group User Query, classify, view own audit logs Any authenticated user"},{"location":"DEPLOYMENT/#dev-mode-authentication","title":"Dev Mode Authentication","text":"<p>In dev mode (<code>lacuna dev</code>), authentication is bypassed and a default admin user is used:</p> <pre><code># Automatic dev user\nuser_id: \"dev-user\"\nemail: \"dev@localhost\"\ngroups: [\"lacuna-admins\", \"developers\"]\nis_admin: True\n</code></pre> <p>Warning: Never use dev mode in production.</p>"},{"location":"DEPLOYMENT/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Always use TLS - API keys are sensitive credentials</li> <li>Rotate API keys regularly - Set expiration dates</li> <li>Use service-specific keys - One key per service for auditability</li> <li>Trust only internal proxies - Verify X-Forwarded-For headers</li> <li>Monitor API key usage - Check last_used_at in admin UI</li> </ol>"},{"location":"DEPLOYMENT/#related-documentation","title":"Related Documentation","text":"<ul> <li>ARCHITECTURE.md - System design</li> <li>LINEAGE.md - Audit and compliance</li> <li>POLICY_AS_CODE.md - OPA configuration</li> </ul> <p>Deploy Lacuna confidently in production with enterprise-grade reliability and observability.</p>"},{"location":"DEVELOPMENT/","title":"Development Guide","text":"<p>Lacuna - Local development setup and dev mode</p>"},{"location":"DEVELOPMENT/#quick-start","title":"Quick Start","text":"<pre><code># Clone repository\ngit clone https://github.com/witlox/lacuna.git\ncd lacuna\n\n# Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # Linux/macOS\n# .venv\\Scripts\\activate   # Windows\n\n# Install in development mode\npip install -e \".[dev]\"\n\n# Start in dev mode\nlacuna dev\n</code></pre> <p>That's it! Lacuna is now running at http://127.0.0.1:8000 with: - API Documentation: http://127.0.0.1:8000/docs - User Dashboard: http://127.0.0.1:8000/user/dashboard - Admin Dashboard: http://127.0.0.1:8000/admin/</p>"},{"location":"DEVELOPMENT/#development-mode","title":"Development Mode","text":"<p>Dev mode (<code>lacuna dev</code>) uses lightweight backends so you can run Lacuna locally without external dependencies:</p> Service Production Dev Mode Database PostgreSQL SQLite (<code>data/lacuna_dev.db</code>) Cache Redis In-memory (disabled) Policy Engine OPA Disabled Embedding Models GPU/CPU intensive Disabled LLM Classification OpenAI/local LLM Disabled Monitoring Prometheus/Loki Disabled"},{"location":"DEVELOPMENT/#dev-mode-command","title":"Dev Mode Command","text":"<pre><code># Start with defaults\nlacuna dev\n\n# Custom port\nlacuna dev --port 8080\n\n# Disable auto-reload\nlacuna dev --no-reload\n</code></pre>"},{"location":"DEVELOPMENT/#environment-variables","title":"Environment Variables","text":"<p>Dev mode automatically sets these environment variables:</p> <pre><code>LACUNA_ENVIRONMENT=development\nLACUNA_DEBUG=true\nLACUNA_DATABASE__URL=sqlite:///data/lacuna_dev.db\nLACUNA_REDIS__ENABLED=false\nLACUNA_CLASSIFICATION__EMBEDDING_ENABLED=false\nLACUNA_CLASSIFICATION__LLM_ENABLED=false\nLACUNA_POLICY__ENABLED=false\nLACUNA_MONITORING__ENABLED=false\nLACUNA_LOG_FORMAT=text\nLACUNA_LOG_LEVEL=DEBUG\n</code></pre>"},{"location":"DEVELOPMENT/#envdev-template","title":".env.dev Template","text":"<p>Copy <code>.env.dev</code> to <code>.env</code> for custom configuration:</p> <pre><code>cp .env.dev .env\n# Edit .env with your settings\n</code></pre>"},{"location":"DEVELOPMENT/#project-structure","title":"Project Structure","text":"<pre><code>lacuna/\n\u251c\u2500\u2500 lacuna/                 # Main package\n\u2502   \u251c\u2500\u2500 api/                # FastAPI application\n\u2502   \u2502   \u2514\u2500\u2500 app.py          # Main app with routes\n\u2502   \u251c\u2500\u2500 audit/              # ISO 27001 audit logging\n\u2502   \u2502   \u251c\u2500\u2500 backend.py      # PostgreSQL backend\n\u2502   \u2502   \u251c\u2500\u2500 memory_backend.py  # In-memory (dev mode)\n\u2502   \u2502   \u2514\u2500\u2500 logger.py       # Audit logger\n\u2502   \u251c\u2500\u2500 classifier/         # Three-layer classification\n\u2502   \u2502   \u251c\u2500\u2500 heuristic.py    # Fast regex patterns\n\u2502   \u2502   \u251c\u2500\u2500 embedding.py    # Semantic similarity\n\u2502   \u2502   \u251c\u2500\u2500 llm.py          # LLM reasoning\n\u2502   \u2502   \u2514\u2500\u2500 pipeline.py     # Classification orchestrator\n\u2502   \u251c\u2500\u2500 cli/                # Command-line interface\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py     # Main CLI commands\n\u2502   \u2502   \u2514\u2500\u2500 admin.py        # Admin CLI commands\n\u2502   \u251c\u2500\u2500 config/             # Configuration management\n\u2502   \u2502   \u251c\u2500\u2500 loader.py       # YAML config loader\n\u2502   \u2502   \u2514\u2500\u2500 settings.py     # Pydantic settings\n\u2502   \u251c\u2500\u2500 db/                 # Database layer\n\u2502   \u2502   \u251c\u2500\u2500 base.py         # SQLAlchemy setup\n\u2502   \u2502   \u2514\u2500\u2500 models.py       # ORM models\n\u2502   \u251c\u2500\u2500 engine/             # Governance engine\n\u2502   \u2502   \u2514\u2500\u2500 governance.py   # Main engine\n\u2502   \u251c\u2500\u2500 lineage/            # Data lineage tracking\n\u2502   \u2502   \u251c\u2500\u2500 backend.py      # PostgreSQL backend\n\u2502   \u2502   \u251c\u2500\u2500 memory_backend.py  # In-memory (dev mode)\n\u2502   \u2502   \u2514\u2500\u2500 tracker.py      # Lineage tracker\n\u2502   \u251c\u2500\u2500 models/             # Pydantic models\n\u2502   \u2502   \u251c\u2500\u2500 audit.py        # Audit records\n\u2502   \u2502   \u251c\u2500\u2500 classification.py  # Classification types\n\u2502   \u2502   \u251c\u2500\u2500 data_operation.py  # Operations\n\u2502   \u2502   \u251c\u2500\u2500 lineage.py      # Lineage graph\n\u2502   \u2502   \u2514\u2500\u2500 policy.py       # Policy decisions\n\u2502   \u251c\u2500\u2500 policy/             # Policy engine\n\u2502   \u2502   \u251c\u2500\u2500 client.py       # OPA client\n\u2502   \u2502   \u2514\u2500\u2500 engine.py       # Policy evaluation\n\u2502   \u2514\u2500\u2500 web/                # Web UI\n\u2502       \u251c\u2500\u2500 routes/         # FastAPI routes\n\u2502       \u2502   \u251c\u2500\u2500 admin.py    # Admin dashboard\n\u2502       \u2502   \u2514\u2500\u2500 user.py     # User dashboard\n\u2502       \u2514\u2500\u2500 templates/      # Jinja2 templates\n\u2502           \u251c\u2500\u2500 admin/      # Admin pages\n\u2502           \u2514\u2500\u2500 user/       # User pages\n\u251c\u2500\u2500 config/                 # Configuration files\n\u2502   \u251c\u2500\u2500 default.yaml        # Default settings\n\u2502   \u2514\u2500\u2500 dev.yaml            # Dev mode settings\n\u251c\u2500\u2500 tests/                  # Test suite\n\u2502   \u251c\u2500\u2500 unit/               # Unit tests\n\u2502   \u2514\u2500\u2500 integration/        # Integration tests\n\u251c\u2500\u2500 docs/                   # Documentation\n\u251c\u2500\u2500 examples/               # Usage examples\n\u251c\u2500\u2500 migrations/             # Alembic migrations\n\u2514\u2500\u2500 policies/               # OPA policy files\n</code></pre>"},{"location":"DEVELOPMENT/#running-tests","title":"Running Tests","text":"<pre><code># All tests\nmake test\n\n# Unit tests only\npytest tests/unit/ -v\n\n# With coverage\npytest --cov=lacuna --cov-report=html\n\n# Integration tests (requires services)\nLACUNA_RUN_INTEGRATION_TESTS=true pytest tests/integration/\n</code></pre>"},{"location":"DEVELOPMENT/#examples","title":"Examples","text":"<p>The <code>examples/</code> directory contains runnable scripts demonstrating Lacuna features:</p> <pre><code># Start dev server in background\nlacuna dev &amp;\n\n# Run classification example\npython examples/basic_classification.py\n\n# Run full governance workflow\npython examples/governance_workflow.py\n</code></pre> Example Description <code>basic_classification.py</code> Classify data sensitivity <code>policy_evaluation.py</code> Evaluate operations against policies <code>lineage_tracking.py</code> Track data lineage <code>audit_logging.py</code> Query audit logs <code>api_client.py</code> REST API HTTP client <code>batch_classification.py</code> Batch classification <code>custom_classifier.py</code> Custom classifiers <code>governance_workflow.py</code> End-to-end workflow"},{"location":"DEVELOPMENT/#code-quality","title":"Code Quality","text":"<pre><code># Format code\nmake format\n\n# Lint\nmake lint\n\n# Type check\nmake mypy\n\n# Security scan\nmake security\n\n# All checks\nmake validate\n</code></pre> <p>Individual tools:</p> <pre><code># Ruff (linting + formatting)\nruff check lacuna/ --fix\nruff format lacuna/\n\n# MyPy (type checking)\nmypy lacuna/\n\n# Bandit (security)\nbandit -r lacuna/\n</code></pre>"},{"location":"DEVELOPMENT/#building","title":"Building","text":"<pre><code># Build package\nmake build\n\n# Build Docker image\nmake docker-build\n</code></pre>"},{"location":"DEVELOPMENT/#cli-commands","title":"CLI Commands","text":""},{"location":"DEVELOPMENT/#core-commands","title":"Core Commands","text":"<pre><code>lacuna dev              # Start in development mode\nlacuna serve            # Start in production mode\nlacuna migrate          # Run database migrations\nlacuna config validate  # Validate configuration\nlacuna version          # Show version\n</code></pre>"},{"location":"DEVELOPMENT/#admin-commands","title":"Admin Commands","text":"<pre><code>lacuna admin config show           # Show configuration\nlacuna admin config set KEY VALUE  # Set config value\nlacuna admin users list            # List users\nlacuna admin users create          # Create user\nlacuna admin policy reload         # Reload policies\nlacuna admin terms add PROJECT     # Add proprietary term\n</code></pre>"},{"location":"DEVELOPMENT/#api-endpoints","title":"API Endpoints","text":"<p>When running (<code>lacuna dev</code> or <code>lacuna serve</code>):</p> Endpoint Description <code>GET /</code> Health check <code>GET /health</code> Detailed health status <code>GET /docs</code> OpenAPI documentation (Swagger) <code>GET /redoc</code> Alternative API docs (ReDoc) <code>POST /classify</code> Classify a data operation <code>GET /lineage/{id}</code> Get lineage for artifact <code>GET /audit/records</code> Query audit records"},{"location":"DEVELOPMENT/#web-dashboards","title":"Web Dashboards","text":"URL Description <code>/user/dashboard</code> User dashboard <code>/user/history</code> Operation history <code>/user/violations</code> Policy violations <code>/user/recommendations</code> Improvement suggestions <code>/admin/</code> Admin dashboard <code>/admin/users</code> User management <code>/admin/audit</code> Audit log viewer <code>/admin/policies</code> Policy management <code>/admin/config</code> System configuration <code>/admin/alerts</code> Alert management"},{"location":"DEVELOPMENT/#configuration","title":"Configuration","text":""},{"location":"DEVELOPMENT/#configuration-files","title":"Configuration Files","text":"<p>Lacuna loads configuration in order (later overrides earlier):</p> <ol> <li><code>config/default.yaml</code> - Default settings</li> <li><code>config/{environment}.yaml</code> - Environment-specific (e.g., <code>dev.yaml</code>)</li> <li>Environment variables (<code>LACUNA_*</code>)</li> <li><code>.env</code> file (if present)</li> </ol>"},{"location":"DEVELOPMENT/#key-settings","title":"Key Settings","text":"<pre><code># config/dev.yaml\nenvironment: development\ndebug: true\n\ndatabase:\n  url: \"sqlite:///data/lacuna_dev.db\"\n\nredis:\n  enabled: false\n\nclassification:\n  embedding:\n    enabled: false\n  llm:\n    enabled: false\n\npolicy:\n  enabled: false\n\nmonitoring:\n  enabled: false\n\nlogging:\n  level: DEBUG\n  format: text\n</code></pre>"},{"location":"DEVELOPMENT/#environment-variable-mapping","title":"Environment Variable Mapping","text":"<p>Environment variables use <code>__</code> for nested keys:</p> <pre><code>LACUNA_DATABASE__URL=postgresql://...\nLACUNA_REDIS__ENABLED=true\nLACUNA_CLASSIFICATION__LLM__MODEL=gpt-4\n</code></pre>"},{"location":"DEVELOPMENT/#database-migrations","title":"Database Migrations","text":"<pre><code># Generate migration after model changes\nlacuna migrate --generate --message \"Add new field\"\n\n# Run pending migrations\nlacuna migrate\n\n# Rollback one revision\nlacuna migrate --revision -1\n</code></pre>"},{"location":"DEVELOPMENT/#debugging","title":"Debugging","text":""},{"location":"DEVELOPMENT/#enable-debug-mode","title":"Enable Debug Mode","text":"<pre><code>export LACUNA_DEBUG=true\nexport LACUNA_LOG_LEVEL=DEBUG\nlacuna dev\n</code></pre>"},{"location":"DEVELOPMENT/#view-logs","title":"View Logs","text":"<p>Dev mode uses human-readable text logs. For JSON logs:</p> <pre><code>export LACUNA_LOG_FORMAT=json\n</code></pre>"},{"location":"DEVELOPMENT/#database-inspection","title":"Database Inspection","text":"<pre><code># SQLite (dev mode)\nsqlite3 data/lacuna_dev.db \".tables\"\nsqlite3 data/lacuna_dev.db \"SELECT * FROM audit_records LIMIT 5;\"\n\n# PostgreSQL (production)\npsql $LACUNA_DATABASE__URL -c \"SELECT * FROM audit_records LIMIT 5;\"\n</code></pre>"},{"location":"DEVELOPMENT/#extending-lacuna","title":"Extending Lacuna","text":""},{"location":"DEVELOPMENT/#custom-classifier","title":"Custom Classifier","text":"<pre><code>from lacuna.classifier.base import BaseClassifier\nfrom lacuna.models.classification import Classification\n\nclass MyClassifier(BaseClassifier):\n    def classify(self, content: str, context: dict) -&gt; Classification:\n        # Your classification logic\n        return Classification(tier=\"INTERNAL\", confidence=0.9)\n</code></pre>"},{"location":"DEVELOPMENT/#custom-policy","title":"Custom Policy","text":"<p>Create a Rego policy in <code>policies/</code>:</p> <pre><code># policies/custom.rego\npackage lacuna.custom\n\ndeny[msg] {\n    input.operation.type == \"export\"\n    input.classification.tier == \"PROPRIETARY\"\n    not input.user.roles[_] == \"data_steward\"\n    msg := \"Only data stewards can export proprietary data\"\n}\n</code></pre>"},{"location":"DEVELOPMENT/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DEVELOPMENT/#port-already-in-use","title":"Port Already in Use","text":"<pre><code># Find process using port\nlsof -i :8000\n\n# Use different port\nlacuna dev --port 8080\n</code></pre>"},{"location":"DEVELOPMENT/#database-locked-sqlite","title":"Database Locked (SQLite)","text":"<p>SQLite can only handle one writer at a time. If you see \"database is locked\":</p> <pre><code># Remove dev database\nrm data/lacuna_dev.db\n\n# Restart\nlacuna dev\n</code></pre>"},{"location":"DEVELOPMENT/#import-errors","title":"Import Errors","text":"<pre><code># Reinstall in development mode\npip install -e \".[dev]\"\n</code></pre>"},{"location":"DEVELOPMENT/#missing-dependencies","title":"Missing Dependencies","text":"<pre><code># Install all optional dependencies\npip install -e \".[all]\"\n</code></pre>"},{"location":"DEVELOPMENT/#ide-setup","title":"IDE Setup","text":""},{"location":"DEVELOPMENT/#vs-code","title":"VS Code","text":"<p>Recommended extensions: - Python (ms-python.python) - Pylance (ms-python.vscode-pylance) - Ruff (charliermarsh.ruff)</p> <p><code>.vscode/settings.json</code>:</p> <pre><code>{\n    \"python.defaultInterpreterPath\": \".venv/bin/python\",\n    \"python.formatting.provider\": \"none\",\n    \"editor.formatOnSave\": true,\n    \"[python]\": {\n        \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n    },\n    \"python.linting.enabled\": true,\n    \"python.linting.mypyEnabled\": true\n}\n</code></pre>"},{"location":"DEVELOPMENT/#pycharm","title":"PyCharm","text":"<ol> <li>Set Python interpreter to <code>.venv/bin/python</code></li> <li>Enable Ruff plugin</li> <li>Enable MyPy plugin</li> <li>Mark <code>lacuna/</code> as Sources Root</li> </ol>"},{"location":"DEVELOPMENT/#contributing","title":"Contributing","text":"<p>See CONTRIBUTING.md for: - Code style guidelines - Pull request process - Testing requirements - Documentation standards</p> <p>Happy hacking! \ud83d\ude80</p>"},{"location":"INTEGRATIONS/","title":"Framework Integrations","text":"<p>Lacuna - The protected space where your knowledge stays yours</p> <p>Integrate Lacuna's privacy-aware routing with popular RAG frameworks and vector databases.</p>"},{"location":"INTEGRATIONS/#overview","title":"Overview","text":"<p>Lacuna integrates with existing RAG frameworks as a privacy layer, adding sensitivity-aware routing without replacing your current stack.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Your RAG Application                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                         \u2502\n\u2502  LlamaIndex / LangChain \u2192 Lacuna Router \u2192 Sources       \u2502\n\u2502         \u2193                       \u2193              \u2193        \u2502\n\u2502    Query Engine          Classification   Local/Web     \u2502\n\u2502                               \u2193                         \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502                    \u2502  Lacuna Classifier   \u2502             \u2502\n\u2502                    \u2502  - Heuristics        \u2502             \u2502\n\u2502                    \u2502  - Embeddings        \u2502             \u2502\n\u2502                    \u2502  - LLM               \u2502             \u2502\n\u2502                    \u2502  - Plugins (OPA)     \u2502             \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502                               \u2193                         \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502              \u2193                                 \u2193        \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502    \u2502   Local Sources  \u2502              \u2502 Web Sources  \u2502   \u2502\n\u2502    \u2502  - Qdrant        \u2502              \u2502  - Kagi API  \u2502   \u2502\n\u2502    \u2502  - ChromaDB      \u2502              \u2502  - Brave API \u2502   \u2502\n\u2502    \u2502  - Weaviate      \u2502              \u2502              \u2502   \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"INTEGRATIONS/#llamaindex-integration","title":"LlamaIndex Integration","text":""},{"location":"INTEGRATIONS/#installation","title":"Installation","text":"<pre><code># Install Lacuna with LlamaIndex support\npip install lacuna[llamaindex]\n\n# Or separately\npip install lacuna llama-index\n</code></pre>"},{"location":"INTEGRATIONS/#basic-integration","title":"Basic Integration","text":"<pre><code>from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.core.query_engine import RouterQueryEngine\nfrom lacuna.integrations.llamaindex import PrivacyAwareRouter\n\n# 1. Load documents\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\n\n# 2. Create local index\nlocal_index = VectorStoreIndex.from_documents(documents)\n\n# 3. Initialize Lacuna router\nlacuna_router = PrivacyAwareRouter(\n    config_path=\"config/\",\n    local_index=local_index,\n    web_search_enabled=True,\n    web_search_provider=\"kagi\"  # or \"brave\", \"duckduckgo\"\n)\n\n# 4. Query with automatic privacy routing\nresponse = lacuna_router.query(\n    \"How do we handle authentication in project_apollo?\"\n)\n# \u2192 Classified as PROPRIETARY \u2192 Routes to local_index only\n\nresponse = lacuna_router.query(\n    \"What's the latest Python 3.12 features?\"\n)\n# \u2192 Classified as PUBLIC \u2192 Routes to local_index + web search\n</code></pre>"},{"location":"INTEGRATIONS/#advanced-custom-query-engines","title":"Advanced: Custom Query Engines","text":"<pre><code>from llama_index.core import VectorStoreIndex\nfrom llama_index.core.query_engine import SubQuestionQueryEngine\nfrom lacuna.integrations.llamaindex import PrivacyAwareQueryEngine\n\n# Multiple local indices\nproprietary_index = VectorStoreIndex.from_documents(proprietary_docs)\ninternal_index = VectorStoreIndex.from_documents(internal_docs)\n\n# Wrap with Lacuna privacy routing\nquery_engine = PrivacyAwareQueryEngine(\n    proprietary_engine=proprietary_index.as_query_engine(),\n    internal_engine=internal_index.as_query_engine(),\n    public_engine=None,  # Use web search for public\n    classifier_config=\"config/\",\n    routing_strategy=\"conservative\"\n)\n\n# Automatic routing based on classification\nresponse = query_engine.query(\"User query here\")\n</code></pre>"},{"location":"INTEGRATIONS/#sub-question-decomposition-with-privacy","title":"Sub-Question Decomposition with Privacy","text":"<pre><code>from llama_index.core.tools import QueryEngineTool\nfrom llama_index.core.query_engine import SubQuestionQueryEngine\nfrom lacuna.integrations.llamaindex import PrivacyAwareSubQuestionEngine\n\n# Define tools (each with privacy tier)\nproprietary_tool = QueryEngineTool.from_defaults(\n    query_engine=proprietary_index.as_query_engine(),\n    name=\"proprietary_docs\",\n    description=\"Company proprietary documentation\",\n    privacy_tier=\"PROPRIETARY\"  # Lacuna extension\n)\n\npublic_tool = QueryEngineTool.from_defaults(\n    query_engine=web_search_engine,\n    name=\"web_search\",\n    description=\"Public web search\",\n    privacy_tier=\"PUBLIC\"\n)\n\n# Privacy-aware sub-question engine\nsub_question_engine = PrivacyAwareSubQuestionEngine.from_tools(\n    [proprietary_tool, public_tool],\n    classifier_config=\"config/\"\n)\n\n# Complex query decomposed with privacy awareness\nresponse = sub_question_engine.query(\n    \"Compare our ML pipeline to industry best practices\"\n)\n# \u2192 Sub-question 1: \"Our ML pipeline\" \u2192 PROPRIETARY \u2192 proprietary_docs\n# \u2192 Sub-question 2: \"Industry best practices\" \u2192 PUBLIC \u2192 web_search\n</code></pre>"},{"location":"INTEGRATIONS/#streaming-responses","title":"Streaming Responses","text":"<pre><code>from lacuna.integrations.llamaindex import PrivacyAwareStreamingEngine\n\nstreaming_engine = PrivacyAwareStreamingEngine(\n    local_index=local_index,\n    web_search_enabled=True\n)\n\n# Stream response with privacy check upfront\nfor chunk in streaming_engine.stream_query(\"Your query\"):\n    print(chunk, end=\"\", flush=True)\n</code></pre>"},{"location":"INTEGRATIONS/#langchain-integration","title":"LangChain Integration","text":""},{"location":"INTEGRATIONS/#installation_1","title":"Installation","text":"<pre><code># Install Lacuna with LangChain support\npip install lacuna[langchain]\n\n# Or separately\npip install lacuna langchain langchain-community\n</code></pre>"},{"location":"INTEGRATIONS/#basic-integration_1","title":"Basic Integration","text":"<pre><code>from langchain.chains import RetrievalQA\nfrom langchain_community.vectorstores import Qdrant\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom lacuna.integrations.langchain import PrivacyAwareRetriever\n\n# 1. Create local vector store\nembeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\nlocal_vectorstore = Qdrant.from_documents(\n    documents,\n    embeddings,\n    location=\":memory:\"\n)\n\n# 2. Wrap with Lacuna privacy-aware retriever\nlacuna_retriever = PrivacyAwareRetriever(\n    local_retriever=local_vectorstore.as_retriever(),\n    web_search_enabled=True,\n    config_path=\"config/\"\n)\n\n# 3. Create QA chain\nqa_chain = RetrievalQA.from_chain_type(\n    llm=local_llm,\n    retriever=lacuna_retriever,\n    return_source_documents=True\n)\n\n# 4. Query with automatic privacy routing\nresult = qa_chain({\"query\": \"How do we deploy to production?\"})\n</code></pre>"},{"location":"INTEGRATIONS/#multi-retriever-with-privacy-tiers","title":"Multi-Retriever with Privacy Tiers","text":"<pre><code>from langchain.retrievers import EnsembleRetriever\nfrom lacuna.integrations.langchain import TieredRetriever\n\n# Different retrievers for different tiers\nproprietary_retriever = qdrant_proprietary.as_retriever()\ninternal_retriever = qdrant_internal.as_retriever()\nweb_retriever = web_search_tool.as_retriever()\n\n# Lacuna routes to appropriate retriever(s)\ntiered_retriever = TieredRetriever(\n    retrievers={\n        \"PROPRIETARY\": proprietary_retriever,\n        \"INTERNAL\": internal_retriever,\n        \"PUBLIC\": web_retriever\n    },\n    classifier_config=\"config/\"\n)\n\n# Automatic tier-based routing\ndocs = tiered_retriever.get_relevant_documents(\n    \"What's our customer retention strategy?\"\n)\n# \u2192 PROPRIETARY \u2192 Uses only proprietary_retriever\n</code></pre>"},{"location":"INTEGRATIONS/#conversational-rag-with-memory","title":"Conversational RAG with Memory","text":"<pre><code>from langchain.chains import ConversationalRetrievalChain\nfrom langchain.memory import ConversationBufferMemory\nfrom lacuna.integrations.langchain import PrivacyAwareConversationalChain\n\n# Memory for conversation history\nmemory = ConversationBufferMemory(\n    memory_key=\"chat_history\",\n    return_messages=True,\n    output_key=\"answer\"\n)\n\n# Privacy-aware conversational chain\nconv_chain = PrivacyAwareConversationalChain.from_llm(\n    llm=local_llm,\n    retriever=lacuna_retriever,\n    memory=memory,\n    classifier_config=\"config/\"\n)\n\n# Context-aware classification (considers conversation history)\nresponse = conv_chain({\"question\": \"Tell me more about that\"})\n# \u2192 Classification considers previous messages for context\n</code></pre>"},{"location":"INTEGRATIONS/#langgraph-agent-with-privacy","title":"LangGraph Agent with Privacy","text":"<pre><code>from langgraph.prebuilt import create_react_agent\nfrom lacuna.integrations.langchain import privacy_aware_tools\n\n# Tools with privacy annotations\ntools = privacy_aware_tools([\n    {\n        \"name\": \"search_proprietary\",\n        \"func\": lambda q: search_qdrant(q),\n        \"description\": \"Search proprietary documents\",\n        \"privacy_tier\": \"PROPRIETARY\"\n    },\n    {\n        \"name\": \"search_web\",\n        \"func\": lambda q: search_kagi(q),\n        \"description\": \"Search public web\",\n        \"privacy_tier\": \"PUBLIC\"\n    }\n])\n\n# Agent with Lacuna privacy checks\nagent = create_react_agent(\n    model=local_llm,\n    tools=tools,\n    checkpointer=memory_checkpointer\n)\n\n# Lacuna validates tool selection matches query sensitivity\nfor chunk in agent.stream(\n    {\"messages\": [(\"user\", \"How do we optimize ML pipeline?\")]}\n):\n    print(chunk)\n# \u2192 Lacuna ensures agent only uses proprietary_search tool\n</code></pre>"},{"location":"INTEGRATIONS/#vector-database-integrations","title":"Vector Database Integrations","text":""},{"location":"INTEGRATIONS/#qdrant","title":"Qdrant","text":"<pre><code>from qdrant_client import QdrantClient\nfrom qdrant_client.models import Distance, VectorParams\nfrom lacuna.integrations.vectordb import PrivacyAwareQdrant\n\n# Initialize Qdrant client\nclient = QdrantClient(url=\"http://localhost:6333\")\n\n# Create collections with privacy tiers\nclient.create_collection(\n    collection_name=\"proprietary\",\n    vectors_config=VectorParams(size=768, distance=Distance.COSINE)\n)\nclient.create_collection(\n    collection_name=\"public\",\n    vectors_config=VectorParams(size=768, distance=Distance.COSINE)\n)\n\n# Wrap with Lacuna\nlacuna_qdrant = PrivacyAwareQdrant(\n    client=client,\n    collections={\n        \"PROPRIETARY\": \"proprietary\",\n        \"INTERNAL\": \"internal\",\n        \"PUBLIC\": \"public\"\n    },\n    classifier_config=\"config/\"\n)\n\n# Query with automatic collection routing\nresults = lacuna_qdrant.search(\n    query=\"How do we handle customer data?\",\n    top_k=5\n)\n# \u2192 PROPRIETARY \u2192 Searches only \"proprietary\" collection\n</code></pre>"},{"location":"INTEGRATIONS/#chromadb","title":"ChromaDB","text":"<pre><code>import chromadb\nfrom lacuna.integrations.vectordb import PrivacyAwareChroma\n\n# Initialize ChromaDB\nchroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n\n# Create collections\nproprietary_collection = chroma_client.create_collection(\"proprietary\")\npublic_collection = chroma_client.create_collection(\"public\")\n\n# Wrap with Lacuna\nlacuna_chroma = PrivacyAwareChroma(\n    client=chroma_client,\n    collections={\n        \"PROPRIETARY\": proprietary_collection,\n        \"PUBLIC\": public_collection\n    },\n    classifier_config=\"config/\"\n)\n\n# Automatic routing\nresults = lacuna_chroma.query(\n    query_texts=[\"Customer retention strategies\"],\n    n_results=10\n)\n</code></pre>"},{"location":"INTEGRATIONS/#weaviate","title":"Weaviate","text":"<pre><code>import weaviate\nfrom lacuna.integrations.vectordb import PrivacyAwareWeaviate\n\n# Initialize Weaviate client\nweaviate_client = weaviate.Client(\"http://localhost:8080\")\n\n# Create schemas with privacy metadata\nweaviate_client.schema.create_class({\n    \"class\": \"ProprietaryDocs\",\n    \"properties\": [\n        {\"name\": \"content\", \"dataType\": [\"text\"]},\n        {\"name\": \"privacy_tier\", \"dataType\": [\"string\"]}\n    ]\n})\n\n# Wrap with Lacuna\nlacuna_weaviate = PrivacyAwareWeaviate(\n    client=weaviate_client,\n    classes={\n        \"PROPRIETARY\": \"ProprietaryDocs\",\n        \"PUBLIC\": \"PublicDocs\"\n    },\n    classifier_config=\"config/\"\n)\n\n# Query with privacy routing\nresults = lacuna_weaviate.search(\n    query=\"Latest product roadmap\",\n    top_k=5\n)\n</code></pre>"},{"location":"INTEGRATIONS/#web-search-integrations","title":"Web Search Integrations","text":""},{"location":"INTEGRATIONS/#kagi-search-api","title":"Kagi Search API","text":"<pre><code>from lacuna.integrations.search import KagiSearch\n\n# Initialize Kagi search\nkagi = KagiSearch(\n    api_key=\"your-kagi-api-key\",\n    region=\"us\",  # or \"eu\"\n    safe_search=True\n)\n\n# Search with privacy classification\nresults = kagi.search(\n    query=\"Latest Python features\",\n    max_results=10,\n    # Lacuna automatically adds context about query sensitivity\n    sensitivity_tier=\"PUBLIC\"\n)\n\n# Kagi features\nresults = kagi.search(\n    query=\"Machine learning best practices\",\n    summary=True,  # FastGPT summary\n    custom_params={\n        \"freshness\": \"week\"  # Recent results only\n    }\n)\n</code></pre>"},{"location":"INTEGRATIONS/#brave-search-api","title":"Brave Search API","text":"<pre><code>from lacuna.integrations.search import BraveSearch\n\nbrave = BraveSearch(\n    api_key=\"your-brave-api-key\",\n    safe_search=\"strict\"\n)\n\nresults = brave.search(\n    query=\"Rust async programming\",\n    count=10,\n    freshness=\"pw\"  # Past week\n)\n</code></pre>"},{"location":"INTEGRATIONS/#duckduckgo-no-api-key","title":"DuckDuckGo (No API Key)","text":"<pre><code>from lacuna.integrations.search import DuckDuckGoSearch\n\nddg = DuckDuckGoSearch()\n\n# No API key required\nresults = ddg.search(\n    query=\"PostgreSQL performance tuning\",\n    max_results=10,\n    region=\"us-en\"\n)\n</code></pre>"},{"location":"INTEGRATIONS/#searxng-self-hosted","title":"SearXNG (Self-Hosted)","text":"<pre><code>from lacuna.integrations.search import SearXNGSearch\n\nsearxng = SearXNGSearch(\n    instance_url=\"https://your-searxng.example.com\",\n    engines=[\"google\", \"bing\", \"duckduckgo\"]\n)\n\nresults = searxng.search(\n    query=\"Kubernetes best practices\",\n    categories=[\"general\", \"it\"]\n)\n</code></pre>"},{"location":"INTEGRATIONS/#llm-backend-integrations","title":"LLM Backend Integrations","text":""},{"location":"INTEGRATIONS/#vllm-local","title":"vLLM (Local)","text":"<pre><code>from lacuna.integrations.llm import VLLMBackend\n\n# Local vLLM server for classification\nvllm_backend = VLLMBackend(\n    model=\"meta-llama/Llama-2-70b-chat-hf\",\n    api_base=\"http://localhost:8000\",\n    temperature=0.1  # Low temp for classification\n)\n\n# Use in Lacuna classifier\nfrom lacuna.classifier import LLMClassifier\n\nllm_classifier = LLMClassifier(\n    backend=vllm_backend,\n    system_prompt=\"You are a privacy classifier...\"\n)\n</code></pre>"},{"location":"INTEGRATIONS/#text-generation-inference-tgi","title":"text-generation-inference (TGI)","text":"<pre><code>from lacuna.integrations.llm import TGIBackend\n\ntgi_backend = TGIBackend(\n    endpoint=\"http://localhost:8080\",\n    model=\"mistralai/Mistral-7B-Instruct-v0.2\"\n)\n</code></pre>"},{"location":"INTEGRATIONS/#ollama-local","title":"Ollama (Local)","text":"<pre><code>from lacuna.integrations.llm import OllamaBackend\n\nollama_backend = OllamaBackend(\n    model=\"llama2:70b\",\n    base_url=\"http://localhost:11434\"\n)\n</code></pre>"},{"location":"INTEGRATIONS/#openai-compatible-apis","title":"OpenAI-Compatible APIs","text":"<pre><code>from lacuna.integrations.llm import OpenAICompatibleBackend\n\n# Works with OpenRouter, Together, Replicate, etc.\nbackend = OpenAICompatibleBackend(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=\"your-api-key\",\n    model=\"meta-llama/Llama-2-70b-chat-hf\"\n)\n</code></pre>"},{"location":"INTEGRATIONS/#embedding-model-integrations","title":"Embedding Model Integrations","text":""},{"location":"INTEGRATIONS/#sentence-transformers-local","title":"Sentence Transformers (Local)","text":"<pre><code>from lacuna.integrations.embeddings import SentenceTransformerEmbeddings\n\nembeddings = SentenceTransformerEmbeddings(\n    model_name=\"BAAI/bge-large-en-v1.5\",\n    device=\"cuda\"  # or \"cpu\"\n)\n\n# Use in classifier\nfrom lacuna.classifier import EmbeddingClassifier\n\nclassifier = EmbeddingClassifier(\n    embeddings=embeddings,\n    examples_path=\"config/classification_examples.yaml\"\n)\n</code></pre>"},{"location":"INTEGRATIONS/#nomic-embed-local","title":"Nomic Embed (Local)","text":"<pre><code>from lacuna.integrations.embeddings import NomicEmbeddings\n\nembeddings = NomicEmbeddings(\n    model=\"nomic-embed-text-v1.5\",\n    task_type=\"search_query\"\n)\n</code></pre>"},{"location":"INTEGRATIONS/#openai-embeddings-api","title":"OpenAI Embeddings (API)","text":"<pre><code>from lacuna.integrations.embeddings import OpenAIEmbeddings\n\n# Note: Using external API for embeddings\n# Consider privacy implications\nembeddings = OpenAIEmbeddings(\n    api_key=\"your-api-key\",\n    model=\"text-embedding-3-large\",\n    # Only use for PUBLIC tier queries\n    allowed_tiers=[\"PUBLIC\"]\n)\n</code></pre>"},{"location":"INTEGRATIONS/#complete-example-multi-framework-stack","title":"Complete Example: Multi-Framework Stack","text":"<pre><code>\"\"\"\nComplete Lacuna integration with LlamaIndex, LangChain, \nQdrant, Kagi, and local LLM.\n\"\"\"\nfrom lacuna import PrivacyAwareRAG\nfrom lacuna.config import load_config\n\n# Vector databases\nfrom qdrant_client import QdrantClient\n\n# LLM\nfrom lacuna.integrations.llm import VLLMBackend\n\n# Embeddings\nfrom sentence_transformers import SentenceTransformer\n\n# Search\nfrom lacuna.integrations.search import KagiSearch\n\n# 1. Initialize components\nconfig = load_config(\"config/\")\n\n# Local vector DB\nqdrant = QdrantClient(url=\"http://localhost:6333\")\n\n# Local LLM for classification\nllm = VLLMBackend(\n    model=\"meta-llama/Llama-2-70b-chat-hf\",\n    api_base=\"http://localhost:8000\"\n)\n\n# Local embeddings\nembeddings = SentenceTransformer(\"BAAI/bge-large-en-v1.5\")\n\n# Web search (for PUBLIC queries only)\nkagi = KagiSearch(api_key=config.kagi_api_key)\n\n# 2. Initialize Lacuna\nrag = PrivacyAwareRAG(\n    config=config,\n    local_vectordb=qdrant,\n    llm_backend=llm,\n    embeddings=embeddings,\n    web_search=kagi,\n    strategy=\"conservative\"\n)\n\n# 3. Use with any framework\n\n# LlamaIndex\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\n\nvector_store = QdrantVectorStore(client=qdrant, collection_name=\"docs\")\nindex = VectorStoreIndex.from_vector_store(vector_store)\n\n# Wrap index with Lacuna\nfrom lacuna.integrations.llamaindex import wrap_index\nprivacy_aware_index = wrap_index(index, rag.classifier)\n\n# LangChain\nfrom langchain_community.vectorstores import Qdrant as LangChainQdrant\n\nlc_vectorstore = LangChainQdrant(\n    client=qdrant,\n    collection_name=\"docs\",\n    embeddings=embeddings\n)\n\n# Wrap retriever with Lacuna\nfrom lacuna.integrations.langchain import wrap_retriever\nprivacy_aware_retriever = wrap_retriever(\n    lc_vectorstore.as_retriever(),\n    rag.classifier\n)\n\n# 4. Query - works with both frameworks\nresponse = rag.query(\"How do we handle authentication?\")\n# \u2192 Automatic classification and routing\n</code></pre>"},{"location":"INTEGRATIONS/#middleware-pattern","title":"Middleware Pattern","text":"<p>For custom frameworks or direct integration:</p> <pre><code>from lacuna.middleware import ClassificationMiddleware\n\n# Your custom RAG pipeline\nclass CustomRAGPipeline:\n    def __init__(self, local_db, web_search):\n        self.local_db = local_db\n        self.web_search = web_search\n\n    def query(self, text: str) -&gt; str:\n        # Your custom logic\n        pass\n\n# Wrap with Lacuna middleware\npipeline = CustomRAGPipeline(local_db, web_search)\nprivacy_aware_pipeline = ClassificationMiddleware(\n    pipeline=pipeline,\n    classifier_config=\"config/\",\n    routing_strategy=\"balanced\"\n)\n\n# Middleware intercepts queries for classification\nresponse = privacy_aware_pipeline.query(\"Your query\")\n</code></pre>"},{"location":"INTEGRATIONS/#configuration-examples","title":"Configuration Examples","text":""},{"location":"INTEGRATIONS/#multi-source-configuration","title":"Multi-Source Configuration","text":"<pre><code># config/sources.yaml\nsources:\n  local:\n    - name: \"proprietary_qdrant\"\n      type: \"qdrant\"\n      url: \"http://localhost:6333\"\n      collection: \"proprietary\"\n      tier: \"PROPRIETARY\"\n\n    - name: \"internal_chromadb\"\n      type: \"chromadb\"\n      path: \"./chroma_internal\"\n      collection: \"internal\"\n      tier: \"INTERNAL\"\n\n  web:\n    - name: \"kagi\"\n      type: \"kagi\"\n      api_key: \"${KAGI_API_KEY}\"\n      tier: \"PUBLIC\"\n      rate_limit: 300  # requests/hour\n\n    - name: \"searxng\"\n      type: \"searxng\"\n      url: \"https://searxng.local\"\n      tier: \"PUBLIC\"\n      fallback: true  # Use if Kagi fails\n\nrouting:\n  PROPRIETARY:\n    sources: [\"proprietary_qdrant\"]\n    web_search: false\n\n  INTERNAL:\n    sources: [\"proprietary_qdrant\", \"internal_chromadb\"]\n    web_search: false\n\n  PUBLIC:\n    sources: [\"proprietary_qdrant\", \"internal_chromadb\"]\n    web_search: true\n    web_sources: [\"kagi\", \"searxng\"]\n</code></pre>"},{"location":"INTEGRATIONS/#framework-specific-config","title":"Framework-Specific Config","text":"<pre><code># config/integrations.yaml\nintegrations:\n  llamaindex:\n    enabled: true\n    response_mode: \"tree_summarize\"\n    similarity_top_k: 5\n    streaming: true\n\n  langchain:\n    enabled: true\n    chain_type: \"stuff\"\n    return_source_documents: true\n    max_tokens_limit: 3000\n\n  embeddings:\n    provider: \"sentence_transformers\"\n    model: \"BAAI/bge-large-en-v1.5\"\n    device: \"cuda\"\n    normalize: true\n\n  llm:\n    provider: \"vllm\"\n    endpoint: \"http://localhost:8000\"\n    model: \"meta-llama/Llama-2-70b-chat-hf\"\n    temperature: 0.1\n    max_tokens: 500\n</code></pre>"},{"location":"INTEGRATIONS/#best-practices","title":"Best Practices","text":""},{"location":"INTEGRATIONS/#1-always-initialize-lacuna-first","title":"1. Always Initialize Lacuna First","text":"<pre><code># \u2705 Good: Lacuna wraps framework components\nconfig = load_config(\"config/\")\nrag = PrivacyAwareRAG(config=config)\nindex = wrap_index(llamaindex_index, rag.classifier)\n\n# \u274c Bad: Framework initialized without privacy layer\nindex = VectorStoreIndex.from_documents(docs)\n# No privacy classification!\n</code></pre>"},{"location":"INTEGRATIONS/#2-use-appropriate-privacy-tiers","title":"2. Use Appropriate Privacy Tiers","text":"<pre><code># \u2705 Good: Separate collections by sensitivity\nproprietary_index = create_index(proprietary_docs)\npublic_index = create_index(public_docs)\n\n# \u274c Bad: Mixing tiers in same index\nmixed_index = create_index(proprietary_docs + public_docs)\n</code></pre>"},{"location":"INTEGRATIONS/#3-test-integration-thoroughly","title":"3. Test Integration Thoroughly","text":"<pre><code># Test privacy routing\ndef test_proprietary_stays_local():\n    \"\"\"Ensure PROPRIETARY queries don't hit web search.\"\"\"\n    response = rag.query(\"Our customer retention strategy\")\n\n    assert response.classification.tier == \"PROPRIETARY\"\n    assert not response.used_web_search\n    assert len(response.local_sources) &gt; 0\n\ndef test_public_uses_web():\n    \"\"\"Ensure PUBLIC queries leverage web search.\"\"\"\n    response = rag.query(\"Latest Python version\")\n\n    assert response.classification.tier == \"PUBLIC\"\n    assert response.used_web_search or len(response.local_sources) &gt; 0\n</code></pre>"},{"location":"INTEGRATIONS/#4-monitor-integration-performance","title":"4. Monitor Integration Performance","text":"<pre><code>from lacuna.monitoring import IntegrationMetrics\n\nmetrics = IntegrationMetrics()\n\n# Track framework usage\nmetrics.track_query(\n    framework=\"llamaindex\",\n    tier=\"PROPRIETARY\",\n    latency_ms=150.5,\n    sources_used=[\"qdrant\"]\n)\n\n# Export to Prometheus\nmetrics.export_prometheus()\n</code></pre>"},{"location":"INTEGRATIONS/#troubleshooting","title":"Troubleshooting","text":""},{"location":"INTEGRATIONS/#issue-classification-too-slow","title":"Issue: Classification Too Slow","text":"<p>Symptom: Integration adds &gt;500ms latency</p> <p>Solution: <pre><code># Enable async classification\nrag = PrivacyAwareRAG(\n    config=config,\n    async_classification=True,\n    cache_enabled=True,\n    cache_size=10000\n)\n</code></pre></p>"},{"location":"INTEGRATIONS/#issue-wrong-sources-selected","title":"Issue: Wrong Sources Selected","text":"<p>Symptom: PUBLIC queries hitting proprietary DB</p> <p>Solution: <pre><code># Verify routing configuration\nfrom lacuna.debug import verify_routing\n\nverify_routing(\n    query=\"Test query\",\n    expected_tier=\"PUBLIC\",\n    expected_sources=[\"web_search\"]\n)\n</code></pre></p>"},{"location":"INTEGRATIONS/#issue-framework-conflict","title":"Issue: Framework Conflict","text":"<p>Symptom: LlamaIndex and LangChain interfering</p> <p>Solution: <pre><code># Use separate environments or explicit isolation\nllamaindex_rag = PrivacyAwareRAG(\n    config=config,\n    framework=\"llamaindex\"\n)\n\nlangchain_rag = PrivacyAwareRAG(\n    config=config,\n    framework=\"langchain\"\n)\n</code></pre></p>"},{"location":"INTEGRATIONS/#related-documentation","title":"Related Documentation","text":"<ul> <li>ARCHITECTURE.md - System design</li> <li>PLUGINS.md - Plugin development</li> <li>DEPLOYMENT.md - Production deployment</li> <li>examples/ - Integration code examples</li> </ul> <p>Lacuna integrates seamlessly with your existing RAG stack, adding privacy-awareness without disruption.</p>"},{"location":"LINEAGE/","title":"Query Lineage &amp; Provenance Tracking","text":"<p>Lacuna - The protected space where your knowledge stays yours</p> <p>Complete tracking of query classification decisions, routing paths, and data sources for compliance and debugging.</p>"},{"location":"LINEAGE/#overview","title":"Overview","text":"<p>Lacuna tracks the complete lineage of every query through the system:</p> <pre><code>Query \u2192 Classification \u2192 Routing \u2192 Retrieval \u2192 Generation \u2192 Response\n  \u2193         \u2193              \u2193           \u2193           \u2193           \u2193\nLogs   Audit Trail    Metrics    Sources    Attribution  User\n</code></pre> <p>Purpose: - Compliance: Demonstrate privacy policy enforcement (GDPR, HIPAA, ITAR) - Debugging: Understand why queries were classified/routed as they were - Optimization: Identify classification bottlenecks and accuracy issues - Attribution: Track which sources influenced responses</p> <p>Design principle: Low-overhead tracking that doesn't significantly impact query latency.</p>"},{"location":"LINEAGE/#architecture","title":"Architecture","text":""},{"location":"LINEAGE/#components","title":"Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Lacuna Query Pipeline                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                             \u2502\n\u2502  Query Input \u2192 Lineage Start                                \u2502\n\u2502       \u2193                                                     \u2502\n\u2502  Classification Layers \u2192 Lineage Record                     \u2502\n\u2502       \u2193                                                     \u2502\n\u2502  Routing Decision \u2192 Lineage Record                          \u2502\n\u2502       \u2193                                                     \u2502\n\u2502  Source Retrieval \u2192 Lineage Record                          \u2502\n\u2502       \u2193                                                     \u2502\n\u2502  Generation \u2192 Lineage Record                                \u2502\n\u2502       \u2193                                                     \u2502\n\u2502  Response \u2192 Lineage Complete                                \u2502\n\u2502                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2193               \u2193              \u2193\n    PostgreSQL     Prometheus      Loki Logs\n   (Audit Trail)    (Metrics)    (Debug Logs)\n</code></pre>"},{"location":"LINEAGE/#storage-backends","title":"Storage Backends","text":"<p>1. PostgreSQL (Primary audit trail) - Query metadata and classification decisions - Routing paths and timing - Source attribution - User context and overrides</p> <p>2. Prometheus (Metrics) - Classification latency by layer - Tier distribution (PROPRIETARY/INTERNAL/PUBLIC) - Cache hit rates - Error rates</p> <p>3. Loki (Structured logs) - Detailed debug information - Classification reasoning - Error traces - Performance profiling</p>"},{"location":"LINEAGE/#data-model","title":"Data Model","text":""},{"location":"LINEAGE/#postgresql-schema","title":"PostgreSQL Schema","text":"<pre><code>-- Core lineage tracking\nCREATE TABLE query_lineage (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n\n    -- Query metadata\n    query_hash VARCHAR(64) NOT NULL,  -- SHA-256 of query text (for privacy)\n    query_length INTEGER NOT NULL,\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    session_id UUID,\n    user_id VARCHAR(255),\n\n    -- Classification\n    classification_tier VARCHAR(20) NOT NULL,  -- PROPRIETARY/INTERNAL/PUBLIC\n    classification_confidence FLOAT NOT NULL,\n    classification_layer VARCHAR(20) NOT NULL,  -- heuristic/embedding/llm/plugin\n    classification_latency_ms FLOAT NOT NULL,\n    classification_reasoning TEXT,\n\n    -- Routing\n    routing_decision JSONB NOT NULL,  -- {local_rag: true, web_search: false}\n    routing_strategy VARCHAR(50),  -- conservative/balanced/aggressive\n\n    -- Context\n    conversation_context JSONB,  -- Previous messages\n    file_context JSONB,  -- Open files\n    project_context VARCHAR(255),  -- Project name\n\n    -- User interaction\n    user_override BOOLEAN DEFAULT FALSE,\n    user_override_tier VARCHAR(20),\n    user_feedback TEXT,\n\n    -- Performance\n    total_latency_ms FLOAT,\n\n    -- Indexes for efficient querying\n    INDEX idx_timestamp (timestamp),\n    INDEX idx_tier (classification_tier),\n    INDEX idx_session (session_id),\n    INDEX idx_user (user_id)\n);\n\n-- Source attribution\nCREATE TABLE source_attribution (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    lineage_id UUID REFERENCES query_lineage(id) ON DELETE CASCADE,\n\n    -- Source metadata\n    source_type VARCHAR(50) NOT NULL,  -- local_rag/web_search/plugin\n    source_name VARCHAR(255),  -- Vector DB name, search provider, etc.\n    document_id VARCHAR(255),\n    chunk_id VARCHAR(255),\n\n    -- Retrieval details\n    relevance_score FLOAT,\n    retrieval_latency_ms FLOAT,\n\n    -- Usage\n    used_in_generation BOOLEAN DEFAULT TRUE,\n\n    INDEX idx_lineage (lineage_id),\n    INDEX idx_source_type (source_type)\n);\n\n-- Plugin execution tracking\nCREATE TABLE plugin_execution (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    lineage_id UUID REFERENCES query_lineage(id) ON DELETE CASCADE,\n\n    plugin_name VARCHAR(255) NOT NULL,\n    plugin_version VARCHAR(50),\n    priority INTEGER,\n\n    -- Execution\n    executed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    latency_ms FLOAT NOT NULL,\n    result JSONB,  -- Classification result if any\n    error TEXT,\n\n    INDEX idx_lineage (lineage_id),\n    INDEX idx_plugin (plugin_name)\n);\n\n-- Classification cache tracking (for analysis)\nCREATE TABLE classification_cache_stats (\n    query_hash VARCHAR(64) PRIMARY KEY,\n\n    first_seen TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    last_seen TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    hit_count INTEGER DEFAULT 1,\n\n    cached_tier VARCHAR(20) NOT NULL,\n    cached_confidence FLOAT NOT NULL,\n\n    INDEX idx_last_seen (last_seen)\n);\n</code></pre>"},{"location":"LINEAGE/#query-hash-for-privacy","title":"Query Hash for Privacy","text":"<p>Why hash queries? - Compliance: Don't store sensitive query text in audit logs - Privacy: Query content may contain PII/proprietary info - Verification: Can verify query was processed without revealing content</p> <p>Hashing strategy: <pre><code>import hashlib\n\ndef hash_query(query: str, salt: str = \"\") -&gt; str:\n    \"\"\"\n    Hash query for privacy-preserving lineage tracking.\n\n    Args:\n        query: Original query text\n        salt: Optional salt for additional security\n\n    Returns:\n        SHA-256 hash (hex string)\n    \"\"\"\n    content = f\"{query}{salt}\".encode('utf-8')\n    return hashlib.sha256(content).hexdigest()\n</code></pre></p> <p>Verification: <pre><code># User can verify their query was processed\nstored_hash = \"a3f5b8c2...\"\nuser_query = \"How do we optimize our ML pipeline?\"\nassert hash_query(user_query) == stored_hash\n</code></pre></p>"},{"location":"LINEAGE/#api","title":"API","text":""},{"location":"LINEAGE/#lineage-tracking-interface","title":"Lineage Tracking Interface","text":"<pre><code>from lacuna.lineage import LineageTracker\nfrom lacuna.models import Classification, RoutingDecision\n\n# Initialize tracker\ntracker = LineageTracker(\n    postgres_url=\"postgresql://localhost/lacuna\",\n    enable_prometheus=True,\n    enable_loki=True\n)\n\n# Start tracking\nlineage_id = tracker.start(\n    query=\"How do we optimize our authentication?\",\n    session_id=\"session-123\",\n    user_id=\"user-456\",\n    context={\n        \"conversation\": [...],\n        \"files\": [\"auth.py\", \"config.yaml\"],\n        \"project\": \"project_apollo\"\n    }\n)\n\n# Record classification\ntracker.record_classification(\n    lineage_id=lineage_id,\n    tier=Classification.PROPRIETARY,\n    confidence=0.98,\n    layer=\"heuristic\",\n    latency_ms=2.3,\n    reasoning=\"Matched project name 'project_apollo'\"\n)\n\n# Record routing\ntracker.record_routing(\n    lineage_id=lineage_id,\n    decision=RoutingDecision(local_rag=True, web_search=False),\n    strategy=\"conservative\"\n)\n\n# Record source attribution\ntracker.record_source(\n    lineage_id=lineage_id,\n    source_type=\"local_rag\",\n    source_name=\"qdrant_proprietary\",\n    document_id=\"doc_123\",\n    relevance_score=0.95,\n    latency_ms=45.2\n)\n\n# Complete tracking\ntracker.complete(\n    lineage_id=lineage_id,\n    total_latency_ms=250.8\n)\n</code></pre>"},{"location":"LINEAGE/#query-api","title":"Query API","text":"<pre><code>from lacuna.lineage import LineageQuery\nfrom datetime import datetime, timedelta\n\nquery = LineageQuery(postgres_url=\"postgresql://localhost/lacuna\")\n\n# Get recent classifications\nrecent = query.get_recent(limit=100, hours=24)\n\n# Get by tier\nproprietary_queries = query.get_by_tier(\n    tier=\"PROPRIETARY\",\n    start_time=datetime.now() - timedelta(days=7)\n)\n\n# Get by user\nuser_history = query.get_by_user(\n    user_id=\"user-456\",\n    include_sources=True\n)\n\n# Get classification accuracy (with user overrides)\naccuracy = query.get_classification_accuracy(\n    start_time=datetime.now() - timedelta(days=30)\n)\n# Returns: {\n#   \"total\": 1000,\n#   \"overridden\": 50,\n#   \"accuracy\": 0.95\n# }\n\n# Analyze tier distribution\ndistribution = query.get_tier_distribution(days=7)\n# Returns: {\n#   \"PROPRIETARY\": 450,\n#   \"INTERNAL\": 300,\n#   \"PUBLIC\": 250\n# }\n</code></pre>"},{"location":"LINEAGE/#metrics-prometheus","title":"Metrics (Prometheus)","text":""},{"location":"LINEAGE/#classification-metrics","title":"Classification Metrics","text":"<pre><code># Classification latency by layer\nlacuna_classification_latency_seconds{layer=\"heuristic\"} histogram\nlacuna_classification_latency_seconds{layer=\"embedding\"} histogram\nlacuna_classification_latency_seconds{layer=\"llm\"} histogram\nlacuna_classification_latency_seconds{layer=\"plugin\"} histogram\n\n# Classification tier distribution\nlacuna_classification_tier_total{tier=\"PROPRIETARY\"} counter\nlacuna_classification_tier_total{tier=\"INTERNAL\"} counter\nlacuna_classification_tier_total{tier=\"PUBLIC\"} counter\n\n# Classification confidence\nlacuna_classification_confidence{tier=\"PROPRIETARY\"} histogram\nlacuna_classification_confidence{tier=\"INTERNAL\"} histogram\nlacuna_classification_confidence{tier=\"PUBLIC\"} histogram\n\n# Cache performance\nlacuna_classification_cache_hit_total counter\nlacuna_classification_cache_miss_total counter\n</code></pre>"},{"location":"LINEAGE/#routing-metrics","title":"Routing Metrics","text":"<pre><code># Routing decisions\nlacuna_routing_decision_total{local_rag=\"true\",web_search=\"false\"} counter\nlacuna_routing_decision_total{local_rag=\"true\",web_search=\"true\"} counter\n\n# Source usage\nlacuna_source_usage_total{source_type=\"local_rag\"} counter\nlacuna_source_usage_total{source_type=\"web_search\"} counter\n</code></pre>"},{"location":"LINEAGE/#user-interaction-metrics","title":"User Interaction Metrics","text":"<pre><code># User overrides (classification accuracy indicator)\nlacuna_user_override_total{from_tier=\"PROPRIETARY\",to_tier=\"INTERNAL\"} counter\nlacuna_user_override_total{from_tier=\"INTERNAL\",to_tier=\"PROPRIETARY\"} counter\n\n# User feedback\nlacuna_user_feedback_total{sentiment=\"positive\"} counter\nlacuna_user_feedback_total{sentiment=\"negative\"} counter\n</code></pre>"},{"location":"LINEAGE/#structured-logging-loki","title":"Structured Logging (Loki)","text":""},{"location":"LINEAGE/#log-format","title":"Log Format","text":"<pre><code>{\n  \"timestamp\": \"2026-01-19T10:30:45.123Z\",\n  \"level\": \"INFO\",\n  \"component\": \"classification\",\n  \"lineage_id\": \"uuid-here\",\n  \"query_hash\": \"a3f5b8c2...\",\n  \"message\": \"Query classified\",\n  \"details\": {\n    \"tier\": \"PROPRIETARY\",\n    \"confidence\": 0.98,\n    \"layer\": \"heuristic\",\n    \"latency_ms\": 2.3,\n    \"reasoning\": \"Matched project name 'project_apollo'\"\n  }\n}\n</code></pre>"},{"location":"LINEAGE/#log-levels","title":"Log Levels","text":"<pre><code># DEBUG: Detailed execution traces\nlogger.debug(\n    \"Classification layer executed\",\n    layer=\"heuristic\",\n    patterns_matched=[\"project_apollo\"],\n    execution_time_ms=2.3\n)\n\n# INFO: Normal operations\nlogger.info(\n    \"Query classified\",\n    tier=\"PROPRIETARY\",\n    confidence=0.98\n)\n\n# WARNING: Potential issues\nlogger.warning(\n    \"Low classification confidence\",\n    tier=\"INTERNAL\",\n    confidence=0.65,\n    fallback=\"requested_user_review\"\n)\n\n# ERROR: Failures\nlogger.error(\n    \"Plugin execution failed\",\n    plugin=\"presidio\",\n    error=\"Connection timeout\",\n    fallback=\"skipped_plugin\"\n)\n</code></pre>"},{"location":"LINEAGE/#compliance-features","title":"Compliance Features","text":""},{"location":"LINEAGE/#gdpr-right-to-explanation","title":"GDPR Right to Explanation","text":"<p>Requirement: Users can request explanation of automated decisions</p> <p>Implementation: <pre><code>from lacuna.lineage import get_classification_explanation\n\nexplanation = get_classification_explanation(\n    query_hash=\"a3f5b8c2...\",\n    user_id=\"user-456\"\n)\n\n# Returns:\n{\n    \"query_hash\": \"a3f5b8c2...\",\n    \"timestamp\": \"2026-01-19T10:30:45Z\",\n    \"classification\": {\n        \"tier\": \"PROPRIETARY\",\n        \"confidence\": 0.98,\n        \"reasoning\": \"Matched proprietary project name 'project_apollo'\",\n        \"layer\": \"heuristic\",\n        \"latency_ms\": 2.3\n    },\n    \"routing\": {\n        \"local_rag\": True,\n        \"web_search\": False,\n        \"reason\": \"PROPRIETARY tier queries never route to external APIs\"\n    },\n    \"sources\": [\n        {\n            \"type\": \"local_rag\",\n            \"name\": \"qdrant_proprietary\",\n            \"relevance\": 0.95\n        }\n    ]\n}\n</code></pre></p>"},{"location":"LINEAGE/#hipaa-audit-trail","title":"HIPAA Audit Trail","text":"<p>Requirement: Complete audit trail of PHI access</p> <p>Implementation: <pre><code>-- Query: All queries that accessed patient data\nSELECT \n    ql.timestamp,\n    ql.user_id,\n    ql.classification_tier,\n    ql.classification_reasoning,\n    sa.source_name,\n    sa.document_id\nFROM query_lineage ql\nJOIN source_attribution sa ON ql.id = sa.lineage_id\nWHERE ql.classification_reasoning LIKE '%PHI%'\n  OR sa.source_name LIKE '%patient%'\nORDER BY ql.timestamp DESC;\n</code></pre></p>"},{"location":"LINEAGE/#data-retention-policies","title":"Data Retention Policies","text":"<pre><code>from lacuna.lineage import RetentionPolicy\n\n# Configure retention by tier\nretention = RetentionPolicy(\n    proprietary_days=90,  # Keep PROPRIETARY queries for 90 days\n    internal_days=60,\n    public_days=30,\n    metrics_days=365,  # Keep aggregated metrics longer\n)\n\n# Automatic cleanup (run daily)\nretention.cleanup_expired()\n\n# Manual anonymization (for long-term analytics)\nretention.anonymize_old_queries(\n    days=90,\n    keep_aggregates=True  # Keep tier/timing stats\n)\n</code></pre>"},{"location":"LINEAGE/#performance-impact","title":"Performance Impact","text":""},{"location":"LINEAGE/#measurement","title":"Measurement","text":"<p>Target: &lt;5ms overhead for lineage tracking per query</p> <p>Actual performance (measured):</p> Operation Latency Impact Start lineage 0.5ms Minimal Record classification 1.2ms Low Record routing 0.8ms Low Record source (async) 2.5ms Low (async) Complete lineage 0.9ms Low Total overhead ~3ms \u2705 Under target"},{"location":"LINEAGE/#optimization-strategies","title":"Optimization Strategies","text":"<p>1. Async writes <pre><code># Non-blocking lineage recording\ntracker.record_classification_async(\n    lineage_id=lineage_id,\n    tier=tier,\n    confidence=confidence\n)\n# Returns immediately, writes happen in background\n</code></pre></p> <p>2. Batching <pre><code># Batch multiple lineage records\ntracker.batch_size = 100  # Write every 100 records or 5 seconds\ntracker.batch_timeout = 5.0\n</code></pre></p> <p>3. Sampling (for high-volume production) <pre><code># Sample 10% of queries for detailed lineage\ntracker = LineageTracker(\n    sampling_rate=0.1,  # 10% sampling\n    always_track_tiers=[\"PROPRIETARY\"],  # Always track sensitive\n    always_track_errors=True  # Always track errors\n)\n</code></pre></p> <p>4. Connection pooling <pre><code># PostgreSQL connection pool\ntracker = LineageTracker(\n    postgres_url=\"postgresql://localhost/lacuna\",\n    pool_size=20,\n    max_overflow=10\n)\n</code></pre></p>"},{"location":"LINEAGE/#deployment-configuration","title":"Deployment Configuration","text":""},{"location":"LINEAGE/#environment-variables","title":"Environment Variables","text":"<pre><code># PostgreSQL\nLACUNA_LINEAGE_POSTGRES_URL=\"postgresql://user:pass@localhost:5432/lacuna\"\nLACUNA_LINEAGE_POOL_SIZE=20\n\n# Metrics\nLACUNA_METRICS_ENABLED=true\nLACUNA_PROMETHEUS_PORT=9090\n\n# Logging\nLACUNA_LOKI_URL=\"http://loki:3100\"\nLACUNA_LOG_LEVEL=INFO\n\n# Performance\nLACUNA_LINEAGE_ASYNC=true\nLACUNA_LINEAGE_BATCH_SIZE=100\nLACUNA_LINEAGE_SAMPLING_RATE=1.0  # 1.0 = 100% (track all)\n\n# Privacy\nLACUNA_LINEAGE_HASH_QUERIES=true\nLACUNA_LINEAGE_HASH_SALT=\"\"  # Optional salt for hashing\n\n# Retention\nLACUNA_RETENTION_PROPRIETARY_DAYS=90\nLACUNA_RETENTION_INTERNAL_DAYS=60\nLACUNA_RETENTION_PUBLIC_DAYS=30\n</code></pre>"},{"location":"LINEAGE/#kubernetes-configmap","title":"Kubernetes ConfigMap","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: lacuna-lineage-config\n  namespace: lacuna\ndata:\n  lineage.yaml: |\n    postgres:\n      url: \"postgresql://lacuna:password@postgres:5432/lacuna\"\n      pool_size: 20\n      max_overflow: 10\n\n    metrics:\n      enabled: true\n      prometheus_port: 9090\n\n    logging:\n      loki_url: \"http://loki:3100\"\n      level: \"INFO\"\n      structured: true\n\n    performance:\n      async_writes: true\n      batch_size: 100\n      batch_timeout_seconds: 5.0\n      sampling_rate: 1.0\n\n    privacy:\n      hash_queries: true\n      hash_salt: \"\"\n\n    retention:\n      proprietary_days: 90\n      internal_days: 60\n      public_days: 30\n      metrics_days: 365\n</code></pre>"},{"location":"LINEAGE/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"LINEAGE/#classification-performance","title":"Classification Performance","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Lacuna - Classification Performance\",\n    \"panels\": [\n      {\n        \"title\": \"Classification Latency by Layer\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, lacuna_classification_latency_seconds_bucket)\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Tier Distribution\",\n        \"type\": \"piechart\",\n        \"targets\": [\n          {\n            \"expr\": \"sum by (tier) (increase(lacuna_classification_tier_total[24h]))\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Cache Hit Rate\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(lacuna_classification_cache_hit_total[5m]) / (rate(lacuna_classification_cache_hit_total[5m]) + rate(lacuna_classification_cache_miss_total[5m]))\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"LINEAGE/#compliance-dashboard","title":"Compliance Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Lacuna - Compliance &amp; Audit\",\n    \"panels\": [\n      {\n        \"title\": \"User Overrides (Accuracy Proxy)\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(lacuna_user_override_total[1h])\"\n          }\n        ]\n      },\n      {\n        \"title\": \"PROPRIETARY Query Volume\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(lacuna_classification_tier_total{tier=\\\"PROPRIETARY\\\"}[5m])\"\n          }\n        ]\n      },\n      {\n        \"title\": \"External API Exposure Risk\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"sum(lacuna_routing_decision_total{web_search=\\\"true\\\"})\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"LINEAGE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"LINEAGE/#high-lineage-latency","title":"High Lineage Latency","text":"<p>Symptom: Lineage tracking taking &gt;10ms per query</p> <p>Diagnosis: <pre><code>from lacuna.lineage import diagnose_performance\n\nreport = diagnose_performance()\n# Returns:\n# {\n#   \"postgres_connection_time_ms\": 25.3,  # Too high!\n#   \"write_latency_p95_ms\": 8.2,\n#   \"batch_efficiency\": 0.45,\n#   \"recommendation\": \"Increase connection pool size\"\n# }\n</code></pre></p> <p>Solutions: 1. Increase PostgreSQL connection pool 2. Enable async writes 3. Increase batch size 4. Add PostgreSQL read replicas for queries</p>"},{"location":"LINEAGE/#missing-lineage-records","title":"Missing Lineage Records","text":"<p>Symptom: Queries not appearing in audit trail</p> <p>Diagnosis: <pre><code># Check lineage service logs\nkubectl logs -n lacuna deployment/lacuna-classifier -f | grep lineage\n\n# Check PostgreSQL connectivity\nkubectl exec -n lacuna deployment/lacuna-classifier -- \\\n  psql postgresql://lacuna:password@postgres:5432/lacuna -c \"SELECT 1;\"\n</code></pre></p> <p>Solutions: 1. Check PostgreSQL connection string 2. Verify database permissions 3. Check for silent failures in async writes 4. Review sampling configuration</p>"},{"location":"LINEAGE/#disk-space-issues","title":"Disk Space Issues","text":"<p>Symptom: PostgreSQL disk filling up</p> <p>Diagnosis: <pre><code>-- Check table sizes\nSELECT \n    schemaname,\n    tablename,\n    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size\nFROM pg_tables\nWHERE schemaname = 'public'\nORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;\n</code></pre></p> <p>Solutions: 1. Adjust retention policies (shorter periods) 2. Enable automatic cleanup job 3. Archive old records to cold storage 4. Increase sampling rate (reduce % tracked)</p>"},{"location":"LINEAGE/#best-practices","title":"Best Practices","text":""},{"location":"LINEAGE/#1-always-hash-sensitive-queries","title":"1. Always Hash Sensitive Queries","text":"<pre><code># \u274c Bad: Storing plaintext queries\ntracker.start(query=\"Patient John Doe has diabetes\")\n\n# \u2705 Good: Hash queries\ntracker.start(\n    query=\"Patient John Doe has diabetes\",\n    hash_query=True  # Store only hash\n)\n</code></pre>"},{"location":"LINEAGE/#2-use-sampling-in-high-volume-production","title":"2. Use Sampling in High-Volume Production","text":"<pre><code># For systems processing &gt;1000 QPS\ntracker = LineageTracker(\n    sampling_rate=0.1,  # Track 10%\n    always_track_tiers=[\"PROPRIETARY\"],  # But always track sensitive\n    always_track_overrides=True  # And user corrections\n)\n</code></pre>"},{"location":"LINEAGE/#3-regular-retention-cleanup","title":"3. Regular Retention Cleanup","text":"<pre><code># Run daily via cron or K8s CronJob\n0 2 * * * /usr/local/bin/lacuna-lineage cleanup --days 90\n</code></pre>"},{"location":"LINEAGE/#4-monitor-classification-accuracy","title":"4. Monitor Classification Accuracy","text":"<pre><code># Set up alerts for high override rates\nif override_rate &gt; 0.10:  # &gt;10% override rate\n    alert(\"Classification accuracy degraded - review recent overrides\")\n</code></pre>"},{"location":"LINEAGE/#5-separate-audit-from-analytics","title":"5. Separate Audit from Analytics","text":"<pre><code># Audit: Full detail, strict retention\naudit_tracker = LineageTracker(\n    sampling_rate=1.0,\n    retention_days=90\n)\n\n# Analytics: Sampled, longer retention of aggregates\nanalytics_tracker = LineageTracker(\n    sampling_rate=0.1,\n    retention_days=30,\n    keep_aggregates=True,\n    aggregate_retention_days=365\n)\n</code></pre>"},{"location":"LINEAGE/#related-documentation","title":"Related Documentation","text":"<ul> <li>ARCHITECTURE.md - System design and components</li> <li>DEPLOYMENT.md - Production deployment guide</li> <li>POLICY_AS_CODE.md - OPA policy configuration</li> <li>INTEGRATIONS.md - Framework integration patterns</li> </ul> <p>Lineage tracking enables compliance, debugging, and continuous improvement of Lacuna's classification accuracy.</p>"},{"location":"PLUGINS/","title":"Plugin Ecosystem","text":"<p>Lacuna - The protected space where your knowledge stays yours</p> <p>Lacuna is designed with a plugin-first architecture that enables organizations to integrate existing classification systems while remaining lightweight and usable for individual users.</p>"},{"location":"PLUGINS/#philosophy-enterprise-first-individual-friendly","title":"Philosophy: Enterprise-First, Individual-Friendly","text":""},{"location":"PLUGINS/#core-design-principle","title":"Core Design Principle","text":"<p>Plugins are optional enhancements, not requirements.</p> <ul> <li>Without plugins: Three-layer classification (heuristic, embedding, LLM) works standalone</li> <li>With plugins: Enhanced accuracy, compliance integration, domain expertise</li> </ul>"},{"location":"PLUGINS/#target-audiences","title":"Target Audiences","text":"<p>Individual Users (recommended: <code>plugins-individual</code>) - Local PII detection (Presidio) - Few-shot learning (SetFit) - No enterprise dependencies - Quick setup, immediate value</p> <p>Enterprise Users (recommended: <code>plugins-enterprise</code>) - All individual plugins - Policy-as-code (OPA) - Compliance logging - Multi-user support</p> <p>Domain-Specific (healthcare, finance, legal) - Industry-specific classifiers - Regulatory compliance (HIPAA, PCI-DSS, SOX) - Domain terminology detection</p>"},{"location":"PLUGINS/#available-plugins","title":"Available Plugins","text":""},{"location":"PLUGINS/#individual-user-plugins-plugins-individual","title":"Individual User Plugins (<code>plugins-individual</code>)","text":""},{"location":"PLUGINS/#1-presidio-pii-detection","title":"1. Presidio PII Detection","text":"<p>What it does: Detects Personally Identifiable Information using ML models</p> <p>Why use it: Catches PII that simple regex misses (phone numbers in various formats, names, locations)</p> <p>Installation: <pre><code>pip install lacuna[plugins-individual]\n</code></pre></p> <p>Usage: <pre><code>from lacuna.plugins import PresidioPlugin\n\npresidio = PresidioPlugin(\n    entities=[\"PHONE_NUMBER\", \"EMAIL_ADDRESS\", \"CREDIT_CARD\", \"SSN\"],\n    priority=5\n)\npipeline.register(presidio)\n</code></pre></p> <p>Features: - 50+ built-in PII recognizers - Multi-language support (15+ languages) - Custom recognizer support - Runs entirely locally (no API calls) - 85-95% accuracy on common PII</p> <p>Performance: - Latency: 5-20ms per query - Memory: ~500MB (models loaded) - CPU-based (no GPU required)</p> <p>Example detections: <pre><code>\"Call me at 555-123-4567\" \u2192 PHONE_NUMBER detected \u2192 PROPRIETARY\n\"My email is john@example.com\" \u2192 EMAIL_ADDRESS \u2192 PROPRIETARY\n\"SSN: 123-45-6789\" \u2192 SSN detected \u2192 PROPRIETARY\n</code></pre></p> <p>Custom recognizers: <pre><code># config/plugins.yaml\npresidio:\n  custom_recognizers:\n    - name: EMPLOYEE_ID\n      pattern: \"EMP-\\\\d{6}\"\n      score: 0.9\n</code></pre></p>"},{"location":"PLUGINS/#2-setfit-few-shot-classification","title":"2. SetFit Few-Shot Classification","text":"<p>What it does: Learns your organization's classification patterns with minimal examples</p> <p>Why use it: Better than cosine similarity, improves with user corrections</p> <p>Installation: <pre><code>pip install lacuna[plugins-individual]\n</code></pre></p> <p>Usage: <pre><code>from lacuna.plugins import SetFitPlugin\n\n# Train from examples\nsetfit = SetFitPlugin(\n    examples={\n        Tier.PROPRIETARY: [\n            \"How do we optimize our auth system?\",\n            \"Debug project_apollo error\",\n            # 8-16 examples\n        ],\n        Tier.PUBLIC: [\n            \"Latest Python version?\",\n            \"How does MVCC work?\",\n            # 8-16 examples\n        ],\n    },\n    priority=20\n)\n\n# Or load pre-trained\nsetfit = SetFitPlugin.from_pretrained(\"./models/classifier\")\npipeline.register(setfit)\n</code></pre></p> <p>Features: - Few-shot learning (8-16 examples per tier) - Automatic retraining on user corrections - Fast inference (5-10ms) - 85-92% accuracy after initial training</p> <p>Training workflow: <pre><code>1. Start with 8-16 examples per tier\n2. System classifies queries\n3. User corrects misclassifications\n4. After 50 corrections, auto-retrain\n5. Accuracy improves to 90%+\n</code></pre></p> <p>Performance: - Training: ~2 minutes (one-time) - Inference: 5-10ms per query - Memory: ~200MB (model loaded) - GPU optional (CPU works fine)</p>"},{"location":"PLUGINS/#enterprise-plugins-plugins-enterprise","title":"Enterprise Plugins (<code>plugins-enterprise</code>)","text":""},{"location":"PLUGINS/#3-open-policy-agent-opa","title":"3. Open Policy Agent (OPA)","text":"<p>What it does: Policy-as-code for compliance-driven classification</p> <p>Why use it: Separates policy (compliance team) from implementation (engineering)</p> <p>Installation: <pre><code>pip install lacuna[plugins-enterprise]\n</code></pre></p> <p>Setup: <pre><code># Start OPA server\ndocker run -p 8181:8181 -v $(pwd)/policies:/policies \\\n  openpolicyagent/opa:latest run --server --addr :8181 /policies\n</code></pre></p> <p>Usage: <pre><code>from lacuna.plugins import OPAPlugin\n\nopa = OPAPlugin(\n    endpoint=\"http://localhost:8181\",\n    policy_path=\"privacy/classify\",\n    priority=10\n)\npipeline.register(opa)\n</code></pre></p> <p>Policy example (<code>policies/privacy.rego</code>): <pre><code>package privacy\n\n# Rule: Customer references are always PROPRIETARY\nclassify[{\n    \"tier\": \"PROPRIETARY\",\n    \"confidence\": 1.0,\n    \"reason\": \"Customer data reference\"\n}] {\n    contains(lower(input.query), \"customer\")\n}\n\n# Rule: Public technology questions\nclassify[{\n    \"tier\": \"PUBLIC\",\n    \"confidence\": 0.9,\n    \"reason\": \"General technical question\"\n}] {\n    startswith(lower(input.query), \"what is\")\n}\n\n# Rule: Project-specific (from context)\nclassify[{\n    \"tier\": \"PROPRIETARY\",\n    \"confidence\": 1.0,\n    \"reason\": \"Project context indicates proprietary\"\n}] {\n    input.context.project != null\n    input.context.project != \"learning\"\n}\n</code></pre></p> <p>Features: - Declarative policy language (Rego) - Version-controlled policies - Centralized policy management - Audit trail built-in - Policy testing framework</p> <p>Use cases: - SOX compliance (financial data protection) - GDPR compliance (EU data residency) - ITAR compliance (defense/export control) - Custom organizational policies</p> <p>Performance: - Latency: &lt;5ms (local OPA server) - Scales to thousands of rules - Policy evaluation cached</p>"},{"location":"PLUGINS/#4-microsoft-purview-enterprise-only","title":"4. Microsoft Purview (Enterprise Only)","text":"<p>What it does: Integrates with existing Microsoft Purview classification</p> <p>Why use it: Organizations already using Purview have trained models and defined labels</p> <p>\u26a0\ufe0f Privacy Warning: Only use with on-premises or private cloud deployment</p> <p>Installation: <pre><code>pip install lacuna[cloud-azure]\n</code></pre></p> <p>Usage: <pre><code>from lacuna.plugins import PurviewPlugin\n\n# Requires private deployment\npurview = PurviewPlugin(\n    endpoint=\"https://your-purview.purview.azure.com\",\n    credential=credential,\n    priority=15\n)\npipeline.register(purview)\n</code></pre></p> <p>Label mapping: <pre><code># Map Purview labels to our tiers\nlabel_mapping:\n  \"Highly Confidential\": PROPRIETARY\n  \"Confidential\": PROPRIETARY\n  \"Internal Use Only\": INTERNAL\n  \"Public\": PUBLIC\n</code></pre></p> <p>Requirements: - Purview deployed on-premises or private cloud - Do NOT send to public Azure (defeats privacy goal) - Enterprise licensing required</p>"},{"location":"PLUGINS/#5-google-cloud-dlp-enterprise-only","title":"5. Google Cloud DLP (Enterprise Only)","text":"<p>What it does: Advanced PII and sensitive data detection</p> <p>Why use it: 120+ built-in detectors, custom info types</p> <p>\u26a0\ufe0f Privacy Warning: Only use with on-premises deployment</p> <p>Installation: <pre><code>pip install lacuna[cloud-gcp]\n</code></pre></p> <p>Usage: <pre><code>from lacuna.plugins import GoogleDLPPlugin\n\n# Requires on-prem or private GCP\ndlp = GoogleDLPPlugin(\n    project_id=\"your-project\",\n    location=\"us\",  # or on-prem location\n    priority=15\n)\npipeline.register(dlp)\n</code></pre></p> <p>Features: - 120+ built-in info types - Custom info type detection - Risk scoring - De-identification capabilities</p> <p>Requirements: - Sensitive Data Protection on-prem - Do NOT send to public GCP APIs - Enterprise licensing</p>"},{"location":"PLUGINS/#domain-specific-plugins","title":"Domain-Specific Plugins","text":""},{"location":"PLUGINS/#6-healthcare-plugin-plugins-healthcare","title":"6. Healthcare Plugin (<code>plugins-healthcare</code>)","text":"<p>What it does: Medical NER and PHI detection for HIPAA compliance</p> <p>Why use it: Healthcare organizations need PHI protection</p> <p>Installation: <pre><code>pip install lacuna[plugins-healthcare]\n\n# Download medical NER model\npython -m spacy download en_core_sci_md\n</code></pre></p> <p>Usage: <pre><code>from lacuna.plugins import HealthcarePlugin\n\nhealthcare = HealthcarePlugin(\n    models=[\"en_core_sci_md\"],\n    detect_phi=True,\n    priority=5\n)\npipeline.register(healthcare)\n</code></pre></p> <p>Detects: - Medical conditions (diabetes, hypertension) - Symptoms (fever, pain) - Medications (aspirin, metformin) - Procedures (surgery, biopsy) - Lab values (blood pressure, glucose) - PHI (patient identifiers)</p> <p>HIPAA compliance: - Detects 18 HIPAA identifiers - Labels PHI as PROPRIETARY - Prevents external queries with PHI</p> <p>Example: <pre><code>\"Patient's blood pressure is 140/90\" \n\u2192 Medical entities detected \n\u2192 PROPRIETARY \n\u2192 Local RAG only\n</code></pre></p>"},{"location":"PLUGINS/#7-finance-plugin-plugins-finance","title":"7. Finance Plugin (<code>plugins-finance</code>)","text":"<p>What it does: Financial data and PCI-DSS compliance</p> <p>Installation: <pre><code>pip install lacuna[plugins-finance]\n</code></pre></p> <p>Usage: <pre><code>from lacuna.plugins import FinancePlugin\n\nfinance = FinancePlugin(\n    detect_pci=True,\n    detect_securities=True,\n    priority=5\n)\npipeline.register(finance)\n</code></pre></p> <p>Detects: - Credit card numbers (PCI-DSS) - Bank account numbers - Routing numbers - Securities (stock symbols, CUSIP, ISIN) - Financial identifiers</p> <p>Compliance: - PCI-DSS Level 1 compliant - SOX compliance support - Audit logging</p>"},{"location":"PLUGINS/#plugin-configuration","title":"Plugin Configuration","text":""},{"location":"PLUGINS/#configuration-file","title":"Configuration File","text":"<pre><code># config/plugins.yaml\n\nplugins:\n  # Enable/disable and configure each plugin\n  presidio:\n    enabled: true\n    priority: 5\n    entities: [PHONE_NUMBER, EMAIL_ADDRESS, CREDIT_CARD]\n\n  setfit:\n    enabled: true\n    priority: 20\n    model_path: ./models/setfit-classifier\n    auto_train: true\n\n  opa:\n    enabled: false  # Enterprise only\n    priority: 10\n    endpoint: http://localhost:8181\n\n# Pipeline behavior\nbehavior:\n  short_circuit: true  # Stop at first high-confidence result\n  confidence_threshold: 0.90\n  fail_safe: true  # Continue on plugin errors\n</code></pre>"},{"location":"PLUGINS/#loading-plugins","title":"Loading Plugins","text":"<pre><code>from lacuna.config import load_plugin_config\n\n# Load configuration\nconfig = load_plugin_config(\"config/plugins.yaml\")\n\n# Auto-register enabled plugins\npipeline.register_from_config(config)\n</code></pre>"},{"location":"PLUGINS/#creating-custom-plugins","title":"Creating Custom Plugins","text":""},{"location":"PLUGINS/#plugin-interface","title":"Plugin Interface","text":"<pre><code>from lacuna.classifier import ClassifierPlugin\nfrom lacuna.models import Classification, Tier\nfrom typing import Optional\n\nclass MyCustomPlugin(ClassifierPlugin):\n    \"\"\"Custom plugin for organization-specific rules.\"\"\"\n\n    # Priority (1-100, lower = earlier)\n    priority = 10\n\n    def __init__(self, custom_config: dict):\n        \"\"\"Initialize with custom configuration.\"\"\"\n        self.config = custom_config\n\n    def classify(\n        self, \n        query: str, \n        context: dict\n    ) -&gt; Optional[Classification]:\n        \"\"\"\n        Classify query or return None.\n\n        Args:\n            query: User's query text\n            context: Conversation history, files, project\n\n        Returns:\n            Classification if applicable, None otherwise\n        \"\"\"\n        # Your classification logic\n        if self.is_sensitive(query):\n            return Classification(\n                tier=Tier.PROPRIETARY,\n                confidence=0.95,\n                reasoning=\"Custom rule: sensitive term detected\",\n                metadata={\"plugin\": self.name, \"rule\": \"custom_001\"}\n            )\n\n        # Not applicable, pass to next plugin\n        return None\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Plugin name for logging.\"\"\"\n        return \"MyCustomPlugin\"\n</code></pre>"},{"location":"PLUGINS/#plugin-best-practices","title":"Plugin Best Practices","text":"<ol> <li>Return None when uncertain: Let other plugins handle it</li> <li>High confidence for clear matches: 0.90+ when you're sure</li> <li>Include reasoning: Explain why classification was chosen</li> <li>Handle errors gracefully: Don't crash the pipeline</li> <li>Document priority: Explain when plugin should run</li> <li>Add comprehensive tests: Test edge cases</li> </ol>"},{"location":"PLUGINS/#plugin-testing","title":"Plugin Testing","text":"<pre><code>import pytest\nfrom lacuna.plugins import MyCustomPlugin\n\nclass TestMyCustomPlugin:\n    @pytest.fixture\n    def plugin(self):\n        return MyCustomPlugin(config={})\n\n    def test_detects_sensitive_term(self, plugin):\n        \"\"\"Should detect proprietary term.\"\"\"\n        query = \"How do we handle acme_corp data?\"\n        result = plugin.classify(query, context={})\n\n        assert result is not None\n        assert result.tier == Tier.PROPRIETARY\n        assert result.confidence &gt; 0.90\n\n    def test_ignores_public_query(self, plugin):\n        \"\"\"Should return None for public queries.\"\"\"\n        query = \"What's the latest Python version?\"\n        result = plugin.classify(query, context={})\n\n        assert result is None  # Pass to next plugin\n</code></pre>"},{"location":"PLUGINS/#plugin-execution-flow","title":"Plugin Execution Flow","text":"<pre><code>User Query\n    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 PluggableClassificationPipeline     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Run plugins in priority order       \u2502\n\u2502 (1 \u2192 100)                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193\nFor each plugin:\n    \u251c\u2500 Call plugin.classify(query, context)\n    \u251c\u2500 If result and confidence &gt;= 0.90:\n    \u2502   \u2514\u2500 Return result (short-circuit)\n    \u2514\u2500 If result but confidence &lt; 0.90:\n        \u2514\u2500 Add to results list\n    \u2193\nIf no short-circuit:\n    \u251c\u2500 Aggregate results\n    \u2514\u2500 Return highest confidence\n    \u2193\nIf no plugins returned results:\n    \u2514\u2500 Use default pipeline (heuristic \u2192 embedding \u2192 LLM)\n</code></pre>"},{"location":"PLUGINS/#plugin-priority-guidelines","title":"Plugin Priority Guidelines","text":"<pre><code>Priority 1-10: Critical Security/Compliance\n\u251c\u2500 5: PII detection (Presidio, Healthcare, Finance)\n\u251c\u2500 8: Policy enforcement (OPA)\n\u2514\u2500 10: Enterprise classification (Purview, DLP)\n\nPriority 11-50: ML-Based Classification\n\u251c\u2500 15: Cloud services (if on-prem)\n\u251c\u2500 20: SetFit (few-shot learning)\n\u2514\u2500 30: Zero-shot classifiers\n\nPriority 51-100: Core Pipeline (Fallback)\n\u251c\u2500 60: Heuristic rules\n\u251c\u2500 70: Embedding similarity\n\u2514\u2500 80: LLM classification\n</code></pre>"},{"location":"PLUGINS/#performance-impact","title":"Performance Impact","text":""},{"location":"PLUGINS/#with-no-plugins-baseline","title":"With No Plugins (Baseline)","text":"<pre><code>Query \u2192 Heuristic (1ms) \u2192 Embedding (10ms) \u2192 LLM (200ms)\nAverage: 15ms (90% heuristic, 8% embedding, 2% LLM)\n</code></pre>"},{"location":"PLUGINS/#with-individual-plugins","title":"With Individual Plugins","text":"<pre><code>Query \u2192 Presidio (15ms) \u2192 SetFit (8ms) \u2192 Heuristic (1ms)\nAverage: 18ms (3ms overhead for enhanced accuracy)\n</code></pre>"},{"location":"PLUGINS/#with-enterprise-plugins","title":"With Enterprise Plugins","text":"<pre><code>Query \u2192 OPA (3ms) \u2192 Presidio (15ms) \u2192 SetFit (8ms) \u2192 Heuristic (1ms)\nAverage: 21ms (6ms overhead for policy + PII + ML)\n</code></pre> <p>Recommendation: Plugin overhead is negligible (&lt;10ms) for the accuracy improvement.</p>"},{"location":"PLUGINS/#plugin-ecosystem-roadmap","title":"Plugin Ecosystem Roadmap","text":""},{"location":"PLUGINS/#current-state-v01","title":"Current State (v0.1)","text":"<ul> <li> Plugin architecture defined</li> <li> Presidio integration (PII detection)</li> <li> SetFit integration (few-shot learning)</li> <li> OPA integration (policy-as-code)</li> <li> Healthcare plugin</li> <li> Finance plugin</li> </ul>"},{"location":"PLUGINS/#near-term-v02-03","title":"Near-term (v0.2-0.3)","text":"<ul> <li> Plugin marketplace/registry</li> <li> Community-contributed plugins</li> <li> Plugin templates and generator</li> <li> Plugin performance benchmarks</li> <li> Plugin compatibility matrix</li> </ul>"},{"location":"PLUGINS/#long-term-v10","title":"Long-term (v1.0+)","text":"<ul> <li> Federated learning plugins</li> <li> Cross-organization plugin sharing</li> <li> Plugin versioning and dependencies</li> <li> Plugin sandboxing/isolation</li> <li> Plugin hot-reload</li> </ul>"},{"location":"PLUGINS/#getting-help","title":"Getting Help","text":"<ul> <li>Plugin issues: GitHub Issues with <code>[Plugin]</code> tag</li> <li>Custom plugin development: See <code>CONTRIBUTING.md</code></li> <li>Enterprise setup: Email enterprise@lacuna.dev</li> <li>Plugin requests: GitHub Discussions</li> </ul>"},{"location":"PLUGINS/#contributing-plugins","title":"Contributing Plugins","text":"<p>We welcome community-contributed plugins! See: - <code>CONTRIBUTING.md</code> for general guidelines - <code>docs/PLUGIN_DEVELOPMENT.md</code> for detailed plugin creation guide - <code>examples/custom_plugin/</code> for working examples</p> <p>Popular plugin categories we're looking for: - Legal (contract analysis, regulatory compliance) - Scientific (research data protection) - Government (classified information handling) - Education (FERPA compliance)</p>"},{"location":"POLICY_AS_CODE/","title":"Policy as Code with Open Policy Agent","text":"<p>Lacuna - The protected space where your knowledge stays yours</p> <p>Define classification rules as code using Open Policy Agent (OPA) for governance-driven query routing.</p>"},{"location":"POLICY_AS_CODE/#overview","title":"Overview","text":"<p>Policy-as-Code separates classification rules (owned by compliance/security) from implementation (owned by engineering).</p>"},{"location":"POLICY_AS_CODE/#why-policy-as-code","title":"Why Policy-as-Code?","text":"<p>Traditional approach (hardcoded rules): <pre><code># Engineering owns both policy AND implementation\nif \"patient\" in query or \"PHI\" in query:\n    return Classification.PROPRIETARY\n</code></pre></p> <p>Problems: - Compliance team can't modify rules without engineering - No audit trail of policy changes - Rules scattered across codebase - Can't test policies independently</p> <p>Policy-as-Code approach: <pre><code># Compliance team owns policy (security.rego)\npackage lacuna.classification\n\nproprietary[reason] {\n    contains(lower(input.query), \"patient\")\n    reason := \"Query contains PHI indicator\"\n}\n</code></pre></p> <p>Benefits: - \u2705 Compliance team controls rules - \u2705 Version-controlled policies (Git) - \u2705 Policy testing framework - \u2705 Audit trail via Git history - \u2705 Centralized governance</p>"},{"location":"POLICY_AS_CODE/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Lacuna Classifier                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                          \u2502\n\u2502  Query \u2192 Heuristics \u2192 Embeddings \u2192 OPA \u2192 LLM \u2192 Result    \u2502\n\u2502              \u2193            \u2193         \u2193     \u2193              \u2502\n\u2502          Fast path    Semantic   Policy  Fallback        \u2502\n\u2502           (1ms)       (10ms)    (5ms)   (200ms)          \u2502\n\u2502                                   \u2193                      \u2502\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502                         \u2502   OPA Server    \u2502              \u2502\n\u2502                         \u2502  (Port 8181)    \u2502              \u2502\n\u2502                         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\n\u2502                         \u2502 policies/       \u2502              \u2502\n\u2502                         \u2502  \u251c\u2500 base.rego   \u2502              \u2502\n\u2502                         \u2502  \u251c\u2500 healthcare  \u2502              \u2502\n\u2502                         \u2502  \u251c\u2500 finance     \u2502              \u2502\n\u2502                         \u2502  \u2514\u2500 custom      \u2502              \u2502\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"POLICY_AS_CODE/#getting-started","title":"Getting Started","text":""},{"location":"POLICY_AS_CODE/#installation","title":"Installation","text":"<p>1. Install OPA</p> <pre><code># Using Docker (recommended)\ndocker run -p 8181:8181 \\\n  -v $(pwd)/policies:/policies \\\n  openpolicyagent/opa:latest \\\n  run --server --addr :8181 /policies\n\n# Or install binary\ncurl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64\nchmod +x opa\n./opa run --server --addr :8181 policies/\n</code></pre> <p>2. Configure Lacuna</p> <pre><code># config/plugins.yaml\nplugins:\n  opa:\n    enabled: true\n    priority: 10  # High priority (policy enforcement)\n    endpoint: \"http://localhost:8181\"\n    policy_path: \"lacuna/classification\"\n    timeout: 1.0  # seconds\n    fallback_on_error: true\n</code></pre> <p>3. Write first policy</p> <pre><code># policies/base.rego\npackage lacuna.classification\n\nimport future.keywords.if\nimport future.keywords.in\n\n# Classification result structure\nclassification[result] {\n    result := {\n        \"tier\": tier,\n        \"confidence\": confidence,\n        \"reasoning\": reasoning\n    }\n    tier := proprietary_tier\n    confidence := 1.0\n    reasoning := proprietary_reason\n}\n\nclassification[result] {\n    result := {\n        \"tier\": tier,\n        \"confidence\": confidence,\n        \"reasoning\": reasoning\n    }\n    tier := \"INTERNAL\"\n    confidence := 0.9\n    reasoning := internal_reason\n}\n\nclassification[result] {\n    result := {\n        \"tier\": \"PUBLIC\",\n        \"confidence\": 0.8,\n        \"reasoning\": \"No sensitive patterns detected\"\n    }\n    not proprietary_tier\n    not internal_reason\n}\n\n# Proprietary rules\nproprietary_tier := \"PROPRIETARY\"\nproprietary_reason := reason {\n    # Check for project names\n    project := input.context.project\n    project != \"learning\"\n    reason := sprintf(\"Project context indicates proprietary: %s\", [project])\n}\n\nproprietary_reason := reason {\n    # Check for customer references\n    contains(lower(input.query), \"customer\")\n    reason := \"Query references customers\"\n}\n\n# Internal rules  \ninternal_reason := \"Query about internal processes\" {\n    process_terms := [\"deployment\", \"infrastructure\", \"monitoring\"]\n    some term in process_terms\n    contains(lower(input.query), term)\n}\n\n# Helper functions\nlower(s) := lower {\n    lower := lower(s)\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#testing-policies","title":"Testing Policies","text":"<pre><code># Test policy locally\nopa test policies/ -v\n\n# Test specific scenario\necho '{\n  \"query\": \"How do we deploy to customer_acme?\",\n  \"context\": {\n    \"project\": \"production\"\n  }\n}' | opa eval --data policies/ \\\n  --input - \\\n  'data.lacuna.classification.classification'\n</code></pre>"},{"location":"POLICY_AS_CODE/#policy-structure","title":"Policy Structure","text":""},{"location":"POLICY_AS_CODE/#input-schema","title":"Input Schema","text":"<p>OPA receives query context from Lacuna:</p> <pre><code>{\n  \"query\": \"How do we optimize authentication?\",\n  \"context\": {\n    \"project\": \"project_apollo\",\n    \"conversation\": [\n      {\"role\": \"user\", \"content\": \"Tell me about our auth\"},\n      {\"role\": \"assistant\", \"content\": \"Our auth uses...\"}\n    ],\n    \"files\": [\"auth.py\", \"config.yaml\"],\n    \"user_id\": \"user-123\",\n    \"session_id\": \"session-456\",\n    \"timestamp\": \"2026-01-19T10:30:00Z\"\n  }\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#output-schema","title":"Output Schema","text":"<p>OPA returns classification decision:</p> <pre><code>{\n  \"tier\": \"PROPRIETARY\",\n  \"confidence\": 0.95,\n  \"reasoning\": \"Matched project name 'project_apollo'\",\n  \"metadata\": {\n    \"matched_rules\": [\"project_context\", \"proprietary_term\"],\n    \"policy_version\": \"1.2.0\"\n  }\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#policy-examples","title":"Policy Examples","text":""},{"location":"POLICY_AS_CODE/#healthcare-hipaa","title":"Healthcare (HIPAA)","text":"<pre><code># policies/healthcare.rego\npackage lacuna.classification\n\nimport future.keywords.if\n\n# PHI indicators\nphi_terms := [\n    \"patient\",\n    \"diagnosis\",\n    \"treatment\",\n    \"medical record\",\n    \"health information\",\n    \"prescription\",\n    \"ssn\",\n    \"date of birth\"\n]\n\n# PROPRIETARY: Contains PHI\nproprietary_tier := \"PROPRIETARY\" {\n    some term in phi_terms\n    contains(lower(input.query), term)\n}\n\nproprietary_reason := reason {\n    matched_terms := [term | \n        some term in phi_terms\n        contains(lower(input.query), term)\n    ]\n    count(matched_terms) &gt; 0\n    reason := sprintf(\"Query contains PHI indicators: %v\", [matched_terms])\n}\n\n# PROPRIETARY: Patient ID patterns\nproprietary_tier := \"PROPRIETARY\" {\n    regex.match(`\\bMRN[-\\s]?\\d{6,}`, input.query)\n}\n\nproprietary_reason := \"Query contains medical record number pattern\" {\n    regex.match(`\\bMRN[-\\s]?\\d{6,}`, input.query)\n}\n\n# INTERNAL: Clinical workflows (no patient data)\ninternal_tier := \"INTERNAL\" {\n    workflow_terms := [\"protocol\", \"procedure\", \"guideline\", \"workflow\"]\n    some term in workflow_terms\n    contains(lower(input.query), term)\n    not proprietary_tier\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#finance-pci-dss-sox","title":"Finance (PCI-DSS, SOX)","text":"<pre><code># policies/finance.rego\npackage lacuna.classification\n\nimport future.keywords.if\n\n# PCI-DSS: Payment card data\nproprietary_tier := \"PROPRIETARY\" {\n    pci_terms := [\n        \"credit card\",\n        \"card number\",\n        \"cvv\",\n        \"cardholder\",\n        \"payment\",\n        \"transaction\"\n    ]\n    some term in pci_terms\n    contains(lower(input.query), term)\n}\n\n# Credit card number pattern\nproprietary_tier := \"PROPRIETARY\" {\n    regex.match(`\\b\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}[-\\s]?\\d{4}\\b`, input.query)\n}\n\n# SOX: Financial reporting\nproprietary_tier := \"PROPRIETARY\" {\n    sox_terms := [\n        \"earnings\",\n        \"revenue\",\n        \"quarterly results\",\n        \"financial statement\",\n        \"audit\"\n    ]\n    some term in sox_terms\n    contains(lower(input.query), term)\n    # Additional context check\n    input.context.project in [\"finance\", \"accounting\"]\n}\n\nproprietary_reason := reason {\n    matched := [term | \n        term := [\"earnings\", \"revenue\", \"quarterly results\"][_]\n        contains(lower(input.query), term)\n    ]\n    count(matched) &gt; 0\n    reason := sprintf(\"Query contains SOX-sensitive terms: %v\", [matched])\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#defense-itarcui","title":"Defense (ITAR/CUI)","text":"<pre><code># policies/defense.rego\npackage lacuna.classification\n\nimport future.keywords.if\n\n# ITAR controlled information\nproprietary_tier := \"PROPRIETARY\" {\n    itar_terms := [\n        \"export control\",\n        \"itar\",\n        \"munitions\",\n        \"defense article\",\n        \"technical data\",\n        \"classified\"\n    ]\n    some term in itar_terms\n    contains(lower(input.query), term)\n}\n\n# CUI (Controlled Unclassified Information)\nproprietary_tier := \"PROPRIETARY\" {\n    cui_markers := [\n        \"cui\",\n        \"controlled unclassified\",\n        \"fouo\",  # For Official Use Only\n        \"noforn\"  # No Foreign Nationals\n    ]\n    some marker in cui_markers\n    contains(lower(input.query), marker)\n}\n\n# Security classification levels\nproprietary_tier := \"PROPRIETARY\" {\n    classification_levels := [\n        \"confidential\",\n        \"secret\",\n        \"top secret\"\n    ]\n    some level in classification_levels\n    contains(lower(input.query), level)\n}\n\nproprietary_reason := \"Query contains ITAR/CUI indicators\" {\n    proprietary_tier == \"PROPRIETARY\"\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#custom-organization-rules","title":"Custom Organization Rules","text":"<pre><code># policies/custom/acme_corp.rego\npackage lacuna.classification\n\nimport future.keywords.if\n\n# Company-specific projects\nproprietary_projects := [\n    \"project_apollo\",\n    \"project_artemis\",\n    \"skunkworks\"\n]\n\nproprietary_tier := \"PROPRIETARY\" {\n    input.context.project in proprietary_projects\n}\n\n# Company-specific customers\nproprietary_customers := [\n    \"customer_alpha\",\n    \"customer_beta\",\n    \"vip_client\"\n]\n\nproprietary_tier := \"PROPRIETARY\" {\n    some customer in proprietary_customers\n    contains(lower(input.query), customer)\n}\n\n# Competitive intelligence protection\nproprietary_tier := \"PROPRIETARY\" {\n    competitive_terms := [\n        \"market share\",\n        \"pricing strategy\",\n        \"product roadmap\",\n        \"acquisition target\"\n    ]\n    some term in competitive_terms\n    contains(lower(input.query), term)\n}\n\nproprietary_reason := reason {\n    proprietary_tier == \"PROPRIETARY\"\n    reason := \"Matched company-specific sensitivity rules\"\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"POLICY_AS_CODE/#time-based-rules","title":"Time-Based Rules","text":"<pre><code># Embargo: Sensitive until announcement\nproprietary_tier := \"PROPRIETARY\" {\n    contains(lower(input.query), \"new product launch\")\n\n    # Parse current time\n    time.now_ns() &lt; time.parse_rfc3339_ns(\"2026-03-01T00:00:00Z\")\n}\n\nproprietary_reason := \"Product information under embargo until March 2026\" {\n    contains(lower(input.query), \"new product launch\")\n    time.now_ns() &lt; time.parse_rfc3339_ns(\"2026-03-01T00:00:00Z\")\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#context-aware-rules","title":"Context-Aware Rules","text":"<pre><code># More permissive for specific users\ninternal_tier := \"INTERNAL\" {\n    # Would normally be PROPRIETARY\n    contains(lower(input.query), \"internal infrastructure\")\n\n    # But user has elevated permissions\n    input.context.user_id in data.elevated_users\n}\n\n# More restrictive in certain projects\nproprietary_tier := \"PROPRIETARY\" {\n    # Normally PUBLIC query\n    contains(lower(input.query), \"python tutorial\")\n\n    # But within sensitive project context\n    input.context.project == \"classified_research\"\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#multi-factor-rules","title":"Multi-Factor Rules","text":"<pre><code># Require multiple conditions\nproprietary_tier := \"PROPRIETARY\" {\n    # Condition 1: Contains sensitive term\n    contains(lower(input.query), \"customer\")\n\n    # Condition 2: In production environment\n    input.context.environment == \"production\"\n\n    # Condition 3: During business hours (higher risk)\n    hour := time.clock([time.now_ns()])[0]\n    hour &gt;= 9\n    hour &lt;= 17\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#confidence-scoring","title":"Confidence Scoring","text":"<pre><code># Variable confidence based on matches\nclassification[result] {\n    matched_terms := [term | \n        term := proprietary_terms[_]\n        contains(lower(input.query), term)\n    ]\n\n    count(matched_terms) &gt; 0\n\n    # More matches = higher confidence\n    confidence := min([1.0, count(matched_terms) * 0.3])\n\n    result := {\n        \"tier\": \"PROPRIETARY\",\n        \"confidence\": confidence,\n        \"reasoning\": sprintf(\"Matched %d proprietary terms\", [count(matched_terms)])\n    }\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#testing-framework","title":"Testing Framework","text":""},{"location":"POLICY_AS_CODE/#unit-tests","title":"Unit Tests","text":"<pre><code># policies/base_test.rego\npackage lacuna.classification\n\nimport future.keywords.if\n\ntest_proprietary_project_detection if {\n    result := classification with input as {\n        \"query\": \"How do we deploy?\",\n        \"context\": {\"project\": \"project_apollo\"}\n    }\n    result.tier == \"PROPRIETARY\"\n}\n\ntest_customer_reference_detection if {\n    result := classification with input as {\n        \"query\": \"What did customer_alpha request?\"\n    }\n    result.tier == \"PROPRIETARY\"\n}\n\ntest_public_query if {\n    result := classification with input as {\n        \"query\": \"What's the latest Python version?\"\n    }\n    result.tier == \"PUBLIC\"\n}\n\ntest_internal_process if {\n    result := classification with input as {\n        \"query\": \"How do we deploy to staging?\"\n    }\n    result.tier == \"INTERNAL\"\n}\n</code></pre> <p>Run tests: <pre><code># All tests\nopa test policies/ -v\n\n# Specific policy\nopa test policies/healthcare_test.rego -v\n\n# With coverage\nopa test policies/ --coverage --format=json\n</code></pre></p>"},{"location":"POLICY_AS_CODE/#integration-testing","title":"Integration Testing","text":"<pre><code># tests/test_opa_integration.py\nimport pytest\nfrom lacuna.plugins import OPAPlugin\n\n@pytest.fixture\ndef opa_plugin():\n    return OPAPlugin(\n        endpoint=\"http://localhost:8181\",\n        policy_path=\"lacuna/classification\"\n    )\n\ndef test_proprietary_classification(opa_plugin):\n    \"\"\"Test OPA correctly classifies proprietary queries.\"\"\"\n    result = opa_plugin.classify(\n        query=\"How do we handle customer_alpha data?\",\n        context={\"project\": \"production\"}\n    )\n\n    assert result.tier == \"PROPRIETARY\"\n    assert result.confidence &gt;= 0.9\n    assert \"customer\" in result.reasoning.lower()\n\ndef test_public_classification(opa_plugin):\n    \"\"\"Test OPA correctly classifies public queries.\"\"\"\n    result = opa_plugin.classify(\n        query=\"What's the latest Rust version?\",\n        context={}\n    )\n\n    assert result.tier == \"PUBLIC\"\n\ndef test_policy_timeout_handling(opa_plugin):\n    \"\"\"Test graceful handling of OPA timeouts.\"\"\"\n    opa_plugin.timeout = 0.001  # Very short timeout\n\n    result = opa_plugin.classify(\n        query=\"Test query\",\n        context={}\n    )\n\n    # Should fallback gracefully\n    assert result is None or result.tier == \"PROPRIETARY\"\n</code></pre>"},{"location":"POLICY_AS_CODE/#policy-deployment","title":"Policy Deployment","text":""},{"location":"POLICY_AS_CODE/#gitops-workflow","title":"GitOps Workflow","text":"<pre><code>Developer writes policy \u2192 PR \u2192 Review \u2192 Merge \u2192 CI/CD \u2192 Deploy\n     (Rego file)                           \u2193\n                                     OPA Test Suite\n                                           \u2193\n                                     Policy Validation\n                                           \u2193\n                                    Deploy to OPA Server\n</code></pre> <p>GitHub Actions example:</p> <pre><code># .github/workflows/policy-ci.yml\nname: OPA Policy CI\n\non:\n  pull_request:\n    paths:\n      - 'policies/**'\n  push:\n    branches: [main]\n    paths:\n      - 'policies/**'\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup OPA\n        run: |\n          curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64\n          chmod +x opa\n          sudo mv opa /usr/local/bin/\n\n      - name: Run OPA Tests\n        run: opa test policies/ -v\n\n      - name: Check Coverage\n        run: |\n          opa test policies/ --coverage --format=json &gt; coverage.json\n          COVERAGE=$(jq '.coverage' coverage.json)\n          if (( $(echo \"$COVERAGE &lt; 80\" | bc -l) )); then\n            echo \"Coverage too low: $COVERAGE%\"\n            exit 1\n          fi\n\n      - name: Validate Policy Syntax\n        run: opa check policies/\n\n  deploy:\n    needs: test\n    if: github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Deploy to OPA ConfigMap\n        run: |\n          kubectl create configmap opa-policies \\\n            --from-file=policies/ \\\n            --dry-run=client -o yaml | \\\n            kubectl apply -f -\n\n          # Reload OPA\n          kubectl rollout restart deployment/opa -n lacuna\n</code></pre>"},{"location":"POLICY_AS_CODE/#versioning-policies","title":"Versioning Policies","text":"<pre><code># Include version metadata\npackage lacuna.classification\n\nmetadata := {\n    \"version\": \"1.2.0\",\n    \"last_updated\": \"2026-01-19\",\n    \"author\": \"compliance-team\",\n    \"description\": \"HIPAA-compliant classification rules\"\n}\n\n# Return version in results\nclassification[result] {\n    # ... classification logic ...\n    result := {\n        \"tier\": tier,\n        \"confidence\": confidence,\n        \"reasoning\": reasoning,\n        \"metadata\": {\n            \"policy_version\": metadata.version\n        }\n    }\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#monitoring-debugging","title":"Monitoring &amp; Debugging","text":""},{"location":"POLICY_AS_CODE/#opa-metrics","title":"OPA Metrics","text":"<pre><code># Policy evaluation latency\nopa_http_request_duration_seconds_bucket{path=\"/v1/data/lacuna/classification\"}\n\n# Policy evaluation count\nopa_http_request_total{path=\"/v1/data/lacuna/classification\"}\n\n# Policy errors\nopa_http_request_error_total\n</code></pre>"},{"location":"POLICY_AS_CODE/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable OPA decision logging\ndocker run -p 8181:8181 \\\n  -v $(pwd)/policies:/policies \\\n  openpolicyagent/opa:latest \\\n  run --server --addr :8181 \\\n  --log-level debug \\\n  --log-format json \\\n  /policies\n</code></pre> <p>Query decision log: <pre><code>curl http://localhost:8181/logs\n</code></pre></p>"},{"location":"POLICY_AS_CODE/#policy-explanation","title":"Policy Explanation","text":"<pre><code># Explain why a decision was made\ncurl -X POST http://localhost:8181/v1/data/lacuna/classification/classification \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"query\": \"How do we handle patient data?\",\n    \"context\": {\"project\": \"healthcare\"}\n  }' \\\n  --explain notes\n</code></pre>"},{"location":"POLICY_AS_CODE/#best-practices","title":"Best Practices","text":""},{"location":"POLICY_AS_CODE/#1-start-simple-add-complexity-gradually","title":"1. Start Simple, Add Complexity Gradually","text":"<pre><code># \u2705 Good: Clear, simple rules\nproprietary_tier := \"PROPRIETARY\" {\n    input.context.project in [\"apollo\", \"artemis\"]\n}\n\n# \u274c Bad: Overly complex on day 1\nproprietary_tier := \"PROPRIETARY\" {\n    projects := [p | p := data.projects[_]; p.sensitivity == \"high\"]\n    contexts := [c | c := input.context.tags[_]; c.level &gt; 5]\n    count(projects) &gt; 0\n    count(contexts) &gt; 0\n    time.now_ns() &gt; time.parse_rfc3339_ns(data.embargo_dates[input.context.project])\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#2-use-descriptive-rule-names","title":"2. Use Descriptive Rule Names","text":"<pre><code># \u2705 Good: Self-documenting\nproprietary_tier := \"PROPRIETARY\" {\n    contains_phi_indicators\n}\n\ncontains_phi_indicators {\n    phi_terms := [\"patient\", \"diagnosis\", \"medical record\"]\n    some term in phi_terms\n    contains(lower(input.query), term)\n}\n\n# \u274c Bad: Unclear\nproprietary_tier := \"PROPRIETARY\" {\n    check1\n}\n\ncheck1 {\n    data.terms[_] == \"patient\"\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#3-always-provide-reasoning","title":"3. Always Provide Reasoning","text":"<pre><code># \u2705 Good: Explains decision\nproprietary_reason := reason {\n    matched := [term | \n        term := phi_terms[_]\n        contains(lower(input.query), term)\n    ]\n    reason := sprintf(\"Matched PHI terms: %v\", [matched])\n}\n\n# \u274c Bad: No explanation\nproprietary_reason := \"Proprietary\" {\n    proprietary_tier == \"PROPRIETARY\"\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#4-test-edge-cases","title":"4. Test Edge Cases","text":"<pre><code>test_case_sensitivity if {\n    # Should match regardless of case\n    result1 := classification with input as {\"query\": \"PATIENT data\"}\n    result2 := classification with input as {\"query\": \"patient data\"}\n    result1.tier == result2.tier\n}\n\ntest_partial_matches if {\n    # \"patients\" should match \"patient\" rule\n    result := classification with input as {\"query\": \"How many patients?\"}\n    result.tier == \"PROPRIETARY\"\n}\n\ntest_empty_context if {\n    # Should not crash on missing context\n    result := classification with input as {\"query\": \"test\"}\n    result.tier in [\"PROPRIETARY\", \"INTERNAL\", \"PUBLIC\"]\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#5-version-and-document-policies","title":"5. Version and Document Policies","text":"<pre><code>package lacuna.classification\n\n# Policy metadata (required)\nmetadata := {\n    \"version\": \"2.1.0\",\n    \"effective_date\": \"2026-01-19\",\n    \"author\": \"security-team@company.com\",\n    \"description\": \"Classification rules for healthcare data (HIPAA compliant)\",\n    \"changelog\": [\n        \"2.1.0: Added MRN pattern detection\",\n        \"2.0.0: Reorganized for clarity\",\n        \"1.0.0: Initial version\"\n    ]\n}\n</code></pre>"},{"location":"POLICY_AS_CODE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"POLICY_AS_CODE/#policy-not-applied","title":"Policy Not Applied","text":"<p>Symptom: OPA policy not affecting classifications</p> <p>Diagnosis: <pre><code># Check OPA is running\ncurl http://localhost:8181/health\n\n# Check policy is loaded\ncurl http://localhost:8181/v1/policies\n\n# Test policy directly\ncurl -X POST http://localhost:8181/v1/data/lacuna/classification/classification \\\n  -d '{\"input\": {\"query\": \"test\", \"context\": {}}}'\n</code></pre></p> <p>Solutions: 1. Verify OPA endpoint in Lacuna config 2. Check policy package name matches config 3. Verify policy syntax: <code>opa check policies/</code> 4. Check plugin priority (OPA should be high priority)</p>"},{"location":"POLICY_AS_CODE/#high-latency","title":"High Latency","text":"<p>Symptom: OPA policy evaluation &gt;50ms</p> <p>Diagnosis: <pre><code># Add timing annotations\npackage lacuna.classification\n\nclassification[result] {\n    start := time.now_ns()\n    # ... policy logic ...\n    end := time.now_ns()\n    duration_ms := (end - start) / 1000000\n\n    trace(sprintf(\"Policy evaluation took %d ms\", [duration_ms]))\n    # ... return result ...\n}\n</code></pre></p> <p>Solutions: 1. Simplify complex rules 2. Use OPA's built-in functions (faster than custom) 3. Cache expensive operations 4. Consider pre-computing data lookups</p>"},{"location":"POLICY_AS_CODE/#conflicting-rules","title":"Conflicting Rules","text":"<p>Symptom: Multiple tiers returned</p> <p>Diagnosis: <pre><code># Check for multiple matching rules\nopa eval --data policies/ \\\n  --input input.json \\\n  'data.lacuna.classification.classification' \\\n  --explain full\n</code></pre></p> <p>Solutions: 1. Use rule prioritization 2. Add explicit exclusions: <code>not internal_tier</code> 3. Consolidate overlapping rules 4. Use else statements for fallbacks</p>"},{"location":"POLICY_AS_CODE/#related-documentation","title":"Related Documentation","text":"<ul> <li>ARCHITECTURE.md - Classification pipeline design</li> <li>PLUGINS.md - Plugin ecosystem and OPA integration</li> <li>DEPLOYMENT.md - OPA deployment in production</li> <li>LINEAGE.md - Policy decision audit trail</li> </ul> <p>Policy-as-Code enables compliance teams to control classification rules without engineering bottlenecks.</p>"},{"location":"SECURITY/","title":"Security Policy","text":""},{"location":"SECURITY/#supported-versions","title":"Supported Versions","text":"Version Supported 2026.x &lt; 2026"},{"location":"SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>We take security seriously. If you discover a security vulnerability in Lacuna, please report it responsibly.</p>"},{"location":"SECURITY/#how-to-report","title":"How to Report","text":"<ol> <li>Do not open a public GitHub issue for security vulnerabilities</li> <li>Use GitHub's private vulnerability reporting</li> <li>Include as much detail as possible:</li> <li>Description of the vulnerability</li> <li>Steps to reproduce</li> <li>Potential impact</li> <li>Suggested fix (if any)</li> </ol>"},{"location":"SECURITY/#what-to-expect","title":"What to Expect","text":"<ul> <li>Acknowledgment: We aim to acknowledge receipt within 7 days</li> <li>Initial Assessment: Within 30 days, we will provide an initial assessment</li> <li>Resolution Timeline: We aim to resolve critical vulnerabilities within 90 days</li> <li>Disclosure: We will coordinate with you on public disclosure timing</li> </ul>"},{"location":"SECURITY/#security-measures","title":"Security Measures","text":"<p>This project implements the following security practices:</p> <ul> <li>Dependency Scanning: Dependabot monitors for vulnerable dependencies</li> <li>License Compliance: FOSSA scans for license policy violations</li> <li>Static Analysis: Bandit scans for common security issues in Python code</li> <li>Code Quality: Ruff, mypy, and other linters catch potential issues</li> </ul>"},{"location":"SECURITY/#security-best-practices-for-users","title":"Security Best Practices for Users","text":"<p>When deploying Lacuna:</p> <ol> <li>Keep dependencies up to date</li> <li>Use environment variables for sensitive configuration</li> <li>Run with least-privilege permissions</li> <li>Enable audit logging in production</li> <li>Review and customize policies for your environment</li> </ol>"},{"location":"USER_GUIDE/","title":"User Guide","text":"<p>Lacuna provides both a web interface and command-line interface for data governance operations.</p>"},{"location":"USER_GUIDE/#web-interface","title":"Web Interface","text":""},{"location":"USER_GUIDE/#user-dashboard","title":"User Dashboard","text":"<p>Access at: <code>http://localhost:8000/user/dashboard</code></p> <p>The user dashboard provides a personal view of your data governance activity:</p>"},{"location":"USER_GUIDE/#dashboard-overview","title":"Dashboard Overview","text":"<ul> <li>Recent Activity: Your latest classifications and policy evaluations</li> <li>Violation Summary: Count of policy violations in the last 30 days</li> <li>Quick Stats: Total queries, approval rate, common data tiers</li> </ul>"},{"location":"USER_GUIDE/#history-userhistory","title":"History (<code>/user/history</code>)","text":"<p>View your complete activity history with filters: - Date Range: Filter by time period - Action Type: Classification, evaluation, export - Result: Allowed, denied, blocked</p> <p>Example use cases: - Review what data you accessed last week - Find a specific query you ran previously - Export your activity for compliance reporting</p>"},{"location":"USER_GUIDE/#violations-userviolations","title":"Violations (<code>/user/violations</code>)","text":"<p>Review policy violations and understand what went wrong: - Violation Details: What rule was triggered - Context: The data and operation involved - Recommendations: How to avoid similar violations</p>"},{"location":"USER_GUIDE/#recommendations-userrecommendations","title":"Recommendations (<code>/user/recommendations</code>)","text":"<p>Personalized suggestions based on your activity patterns: - Common mistakes and how to fix them - Best practices for data handling - Training resources for specific data types</p>"},{"location":"USER_GUIDE/#admin-dashboard","title":"Admin Dashboard","text":"<p>Access at: <code>http://localhost:8000/admin/</code> (requires admin privileges)</p>"},{"location":"USER_GUIDE/#dashboard-admin","title":"Dashboard (<code>/admin/</code>)","text":"<p>System-wide overview: - Total Events: Classification and evaluation counts - Violations Today: Policy denials requiring attention - System Health: Backend service status - Top Violators: Users with most policy violations</p>"},{"location":"USER_GUIDE/#users-adminusers","title":"Users (<code>/admin/users</code>)","text":"<p>User management and activity monitoring: - View all users who have interacted with the system - See per-user violation counts - Filter by activity level or department</p>"},{"location":"USER_GUIDE/#audit-adminaudit","title":"Audit (<code>/admin/audit</code>)","text":"<p>Complete audit log with advanced filtering: - User ID: Filter by specific user - Resource: Filter by data asset - Event Type: Classification, evaluation, export, etc. - Result: Allowed, denied, blocked - Date Range: Custom time windows</p> <p>Export audit logs for compliance reporting.</p>"},{"location":"USER_GUIDE/#policies-adminpolicies","title":"Policies (<code>/admin/policies</code>)","text":"<p>Policy management: - View active policies - See policy evaluation statistics - Check policy version history</p>"},{"location":"USER_GUIDE/#config-adminconfig","title":"Config (<code>/admin/config</code>)","text":"<p>System configuration: - Proprietary Terms: Keywords that trigger PROPRIETARY classification - Project Mappings: Project-to-classification mappings - Customer Terms: Customer-specific sensitive terms - System Settings: Classification thresholds, cache TTL, etc.</p>"},{"location":"USER_GUIDE/#api-keys-adminapi-keys","title":"API Keys (<code>/admin/api-keys</code>)","text":"<p>Service account management: - Create Keys: Generate API keys for automation (dbt, CI/CD, etc.) - View Keys: See all keys with usage statistics - Revoke/Delete: Disable compromised or unused keys</p> <p>Creating an API key: 1. Click \"Generate API Key\" 2. Enter a name (e.g., \"dbt-production\") 3. Set the service account ID (username for audit logs) 4. Optionally add groups and expiration 5. Copy the key immediately - it won't be shown again!</p>"},{"location":"USER_GUIDE/#alerts-adminalerts","title":"Alerts (<code>/admin/alerts</code>)","text":"<p>Alert configuration and history: - View triggered alerts - Configure alert thresholds - Set up notification channels</p>"},{"location":"USER_GUIDE/#command-line-interface","title":"Command-Line Interface","text":""},{"location":"USER_GUIDE/#getting-started","title":"Getting Started","text":"<pre><code># Install Lacuna\npip install lacuna\n\n# Verify installation\nlacuna --version\n\n# Get help\nlacuna --help\n</code></pre>"},{"location":"USER_GUIDE/#development-mode","title":"Development Mode","text":"<pre><code># Start dev server (no external dependencies needed)\nlacuna dev\n\n# Custom port\nlacuna dev --port 8080\n\n# Disable auto-reload\nlacuna dev --no-reload\n</code></pre> <p>Dev mode uses: - SQLite instead of PostgreSQL - In-memory cache instead of Redis - Heuristic classifier only (no LLM/embeddings) - Authentication bypassed (admin user)</p>"},{"location":"USER_GUIDE/#classification","title":"Classification","text":"<pre><code># Classify a query\nlacuna classify \"SELECT * FROM customers WHERE email LIKE '%@gmail.com'\"\n\n# Classify with context\nlacuna classify \"SELECT revenue FROM sales\" --project finance --user analyst@company.com\n\n# Batch classification from file\nlacuna classify --file queries.txt --output results.json\n\n# Output formats\nlacuna classify \"query\" --format json\nlacuna classify \"query\" --format table\nlacuna classify \"query\" --format yaml\n</code></pre>"},{"location":"USER_GUIDE/#policy-evaluation","title":"Policy Evaluation","text":"<pre><code># Evaluate an operation\nlacuna evaluate \\\n  --operation read \\\n  --resource customers \\\n  --user analyst@company.com\n\n# Evaluate an export\nlacuna evaluate \\\n  --operation export \\\n  --resource customers \\\n  --destination /tmp/export.csv \\\n  --user analyst@company.com\n\n# With purpose justification\nlacuna evaluate \\\n  --operation export \\\n  --resource financial_data \\\n  --destination s3://bucket/path \\\n  --purpose \"Q4 reporting\" \\\n  --user analyst@company.com\n</code></pre>"},{"location":"USER_GUIDE/#lineage","title":"Lineage","text":"<pre><code># Get lineage for an artifact\nlacuna lineage get customers_table\n\n# Show upstream dependencies\nlacuna lineage upstream customers_table\n\n# Show downstream dependents  \nlacuna lineage downstream customers_table\n\n# Impact analysis (what would be affected by changes)\nlacuna lineage impact customers_table\n</code></pre>"},{"location":"USER_GUIDE/#audit","title":"Audit","text":"<pre><code># Query audit logs\nlacuna audit query --limit 100\n\n# Filter by user\nlacuna audit query --user analyst@company.com\n\n# Filter by result\nlacuna audit query --result denied --limit 50\n\n# Filter by date range\nlacuna audit query --start 2024-01-01 --end 2024-01-31\n\n# Export audit logs\nlacuna audit export --format csv --output audit_jan.csv\n\n# Verify audit log integrity\nlacuna audit verify --start 2024-01-01\n</code></pre>"},{"location":"USER_GUIDE/#admin-commands","title":"Admin Commands","text":"<p>Admin commands require appropriate permissions.</p>"},{"location":"USER_GUIDE/#configuration-management","title":"Configuration Management","text":"<pre><code># Show current config\nlacuna admin config show\n\n# Validate config\nlacuna admin config validate\n\n# Reload config (hot reload)\nlacuna admin config reload\n</code></pre>"},{"location":"USER_GUIDE/#proprietary-terms","title":"Proprietary Terms","text":"<pre><code># List proprietary terms\nlacuna admin terms list\n\n# Add a term\nlacuna admin terms add \"Project Phoenix\"\n\n# Remove a term\nlacuna admin terms remove \"Old Project\"\n\n# Bulk import from file\nlacuna admin terms import terms.txt\n</code></pre>"},{"location":"USER_GUIDE/#project-mappings","title":"Project Mappings","text":"<pre><code># List project mappings\nlacuna admin projects list\n\n# Add a project with classification\nlacuna admin projects add \"secret-project\" --tier PROPRIETARY\n\n# Remove a project\nlacuna admin projects remove \"old-project\"\n</code></pre>"},{"location":"USER_GUIDE/#customer-terms","title":"Customer Terms","text":"<pre><code># List customer terms\nlacuna admin customers list\n\n# Add customer-specific terms\nlacuna admin customers add \"Acme Corp\" --terms \"acme,acme-corp,acmecorp\"\n\n# Remove customer\nlacuna admin customers remove \"Old Customer\"\n</code></pre>"},{"location":"USER_GUIDE/#policy-management","title":"Policy Management","text":"<pre><code># List policies\nlacuna admin policy list\n\n# Show policy details\nlacuna admin policy show export-policy\n\n# Validate policy syntax\nlacuna admin policy validate policies/new-policy.rego\n\n# Deploy a policy\nlacuna admin policy deploy policies/new-policy.rego\n</code></pre>"},{"location":"USER_GUIDE/#user-management","title":"User Management","text":"<pre><code># List users\nlacuna admin users list\n\n# Show user details\nlacuna admin users show analyst@company.com\n\n# View user violations\nlacuna admin users violations analyst@company.com\n</code></pre>"},{"location":"USER_GUIDE/#api-key-management","title":"API Key Management","text":"<pre><code># List API keys\nlacuna admin apikey list\n\n# Create a new API key\nlacuna admin apikey create \\\n  --name \"dbt-production\" \\\n  --service-account \"svc-dbt\" \\\n  --groups \"data-engineers\"\n\n# Revoke a key\nlacuna admin apikey revoke KEY_ID\n\n# Delete a key\nlacuna admin apikey delete KEY_ID\n</code></pre>"},{"location":"USER_GUIDE/#server-management","title":"Server Management","text":"<pre><code># Start production server\nlacuna server --host 0.0.0.0 --port 8000\n\n# With workers\nlacuna server --workers 4\n\n# With SSL\nlacuna server --ssl-keyfile key.pem --ssl-certfile cert.pem\n</code></pre>"},{"location":"USER_GUIDE/#configuration","title":"Configuration","text":"<pre><code># Show effective configuration\nlacuna config show\n\n# Validate configuration\nlacuna config validate\n\n# Show config file location\nlacuna config path\n</code></pre>"},{"location":"USER_GUIDE/#api-usage","title":"API Usage","text":""},{"location":"USER_GUIDE/#authentication","title":"Authentication","text":"<p>For production, include authentication headers:</p> <pre><code># With API key\ncurl -H \"Authorization: Bearer lac_your_key_here\" \\\n  http://localhost:8000/api/v1/classify\n\n# Behind reverse proxy (headers set by proxy)\n# X-User, X-Email, X-Groups headers are used\n</code></pre>"},{"location":"USER_GUIDE/#classification-api","title":"Classification API","text":"<pre><code># Classify a query\ncurl -X POST http://localhost:8000/api/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"SELECT email, ssn FROM users\",\n    \"project\": \"analytics\",\n    \"user_id\": \"analyst@company.com\"\n  }'\n\n# Response\n{\n  \"tier\": \"PROPRIETARY\",\n  \"confidence\": 0.95,\n  \"reasoning\": \"Contains PII (SSN pattern detected)\",\n  \"tags\": [\"PII\", \"SSN\"],\n  \"classifier\": \"heuristic\",\n  \"latency_ms\": 2.5\n}\n</code></pre>"},{"location":"USER_GUIDE/#evaluation-api","title":"Evaluation API","text":"<pre><code># Evaluate an operation\ncurl -X POST http://localhost:8000/api/v1/evaluate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"operation_type\": \"export\",\n    \"resource_type\": \"table\",\n    \"resource_id\": \"customers\",\n    \"destination\": \"/tmp/export.csv\"\n  }'\n\n# Response\n{\n  \"allowed\": false,\n  \"classification_tier\": \"PROPRIETARY\",\n  \"reasoning\": \"Export of PROPRIETARY data to unencrypted destination denied\",\n  \"alternatives\": [\n    \"Export to encrypted S3 bucket\",\n    \"Request data access approval\",\n    \"Use anonymized view instead\"\n  ],\n  \"evaluation_id\": \"eval-123\"\n}\n</code></pre>"},{"location":"USER_GUIDE/#openapi-documentation","title":"OpenAPI Documentation","text":"<p>Interactive API documentation is available at: - Swagger UI: <code>http://localhost:8000/docs</code> - ReDoc: <code>http://localhost:8000/redoc</code> - OpenAPI JSON: <code>http://localhost:8000/openapi.json</code></p>"},{"location":"USER_GUIDE/#common-workflows","title":"Common Workflows","text":""},{"location":"USER_GUIDE/#setting-up-a-new-project","title":"Setting Up a New Project","text":"<ol> <li> <p>Add project to configuration:    <pre><code>lacuna admin projects add \"new-project\" --tier INTERNAL\n</code></pre></p> </li> <li> <p>Add project-specific terms:    <pre><code>lacuna admin terms add \"new-project-secret\"\n</code></pre></p> </li> <li> <p>Verify classification:    <pre><code>lacuna classify \"SELECT * FROM new_project_data\"\n</code></pre></p> </li> </ol>"},{"location":"USER_GUIDE/#investigating-a-violation","title":"Investigating a Violation","text":"<ol> <li> <p>Find the violation in audit logs:    <pre><code>lacuna audit query --user violator@company.com --result denied\n</code></pre></p> </li> <li> <p>Get details:    <pre><code>lacuna audit show EVENT_ID\n</code></pre></p> </li> <li> <p>Check user's violation history:    <pre><code>lacuna admin users violations violator@company.com\n</code></pre></p> </li> </ol>"},{"location":"USER_GUIDE/#setting-up-service-account-access","title":"Setting Up Service Account Access","text":"<ol> <li> <p>Create API key:    <pre><code>lacuna admin apikey create \\\n  --name \"dbt-production\" \\\n  --service-account \"svc-dbt\" \\\n  --groups \"data-engineers\" \\\n  --expires-days 90\n</code></pre></p> </li> <li> <p>Store the key securely (shown only once)</p> </li> <li> <p>Use in automation:    <pre><code>export LACUNA_API_KEY=\"lac_xxx...\"\ncurl -H \"Authorization: Bearer $LACUNA_API_KEY\" \\\n  http://lacuna.internal/api/v1/classify\n</code></pre></p> </li> </ol>"},{"location":"USER_GUIDE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"USER_GUIDE/#dev-mode-issues","title":"Dev Mode Issues","text":"<pre><code># Check if port is in use\nlsof -i :8000\n\n# Clear dev database\nrm -rf data/lacuna_dev.db\n\n# Restart with verbose logging\nLACUNA_LOG_LEVEL=DEBUG lacuna dev\n</code></pre>"},{"location":"USER_GUIDE/#authentication-issues","title":"Authentication Issues","text":"<pre><code># Check if running in dev mode (auth bypassed)\nlacuna config show | grep dev_mode\n\n# Verify API key is valid\ncurl -v -H \"Authorization: Bearer lac_xxx\" \\\n  http://localhost:8000/api/v1/health\n</code></pre>"},{"location":"USER_GUIDE/#classification-not-working","title":"Classification Not Working","text":"<pre><code># Check classifier configuration\nlacuna config show | grep classifier\n\n# Test with known PII\nlacuna classify \"email: test@example.com, SSN: 123-45-6789\"\n\n# Check if proprietary terms are loaded\nlacuna admin terms list\n</code></pre> <p>For more information: - Development Guide - Deployment Guide - Architecture</p>"},{"location":"license/","title":"License","text":"<p>Lacuna is licensed under the Apache License 2.0.</p>"},{"location":"license/#apache-license-20","title":"Apache License 2.0","text":"<pre><code>Copyright 2025 Lacuna Contributors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"},{"location":"license/#what-this-means","title":"What This Means","text":"<p>The Apache License 2.0 is a permissive open source license that allows you to:</p> <ul> <li>Use the software for any purpose, including commercial applications</li> <li>Modify the source code to fit your needs</li> <li>Distribute the software or your modifications</li> <li>Sublicense the software under different terms</li> </ul>"},{"location":"license/#requirements","title":"Requirements","text":"<p>When using Lacuna, you must:</p> <ul> <li>Include a copy of the Apache License 2.0</li> <li>Include a NOTICE file if we provide one</li> <li>State significant changes made to the software</li> <li>Retain all copyright, patent, trademark, and attribution notices</li> </ul>"},{"location":"license/#limitations","title":"Limitations","text":"<ul> <li>The license provides no warranty</li> <li>The license provides no trademark rights</li> <li>Contributors provide the software \"as is\"</li> </ul>"},{"location":"license/#third-party-licenses","title":"Third-Party Licenses","text":"<p>Lacuna depends on various open source libraries, each with their own licenses:</p> Library License Purpose FastAPI MIT Web framework SQLAlchemy MIT Database ORM Pydantic MIT Data validation PyTorch BSD-3-Clause ML framework sentence-transformers Apache 2.0 Embeddings NetworkX BSD-3-Clause Graph algorithms Redis BSD-3-Clause Caching PostgreSQL PostgreSQL License Database <p>See the full dependency list with licenses:</p> <pre><code>pip install pip-licenses\npip-licenses --with-urls\n</code></pre>"},{"location":"license/#fossa-compliance","title":"FOSSA Compliance","text":"<p>Lacuna uses FOSSA for automated license compliance scanning:</p> <p></p>"},{"location":"license/#contributing","title":"Contributing","text":"<p>By contributing to Lacuna, you agree that your contributions will be licensed under the Apache License 2.0.</p> <p>See CONTRIBUTING.md for details.</p>"},{"location":"license/#questions","title":"Questions","text":"<p>For licensing questions, please open an issue on GitHub.</p>"},{"location":"api/python/","title":"Python SDK Reference","text":"<p>The Python SDK provides programmatic access to Lacuna's core functionality.</p>"},{"location":"api/python/#installation","title":"Installation","text":"<pre><code>pip install lacuna\n</code></pre>"},{"location":"api/python/#core-modules","title":"Core Modules","text":""},{"location":"api/python/#classification-pipeline","title":"Classification Pipeline","text":"<p>Classify data for sensitivity:</p> <pre><code>from lacuna.classifier import ClassificationPipeline\nfrom lacuna.models import Classification\n\n# Initialize pipeline\npipeline = ClassificationPipeline()\n\n# Classify a query\nclassification = pipeline.classify(\n    query=\"Show me all customer emails and SSNs\"\n)\n\nprint(f\"Tier: {classification.tier}\")  # PROPRIETARY\nprint(f\"Confidence: {classification.confidence}\")  # 0.95\nprint(f\"Tags: {classification.tags}\")  # ['PII', 'GDPR', 'SSN']\n</code></pre>"},{"location":"api/python/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from lacuna.classifier import ClassificationPipeline\nfrom lacuna.config import ClassificationSettings\n\nsettings = ClassificationSettings(\n    strategy=\"fast\",  # Use only heuristics + embeddings\n    confidence_threshold=0.8,\n    default_tier=\"INTERNAL\"\n)\n\npipeline = ClassificationPipeline(settings=settings)\n</code></pre>"},{"location":"api/python/#governance-engine","title":"Governance Engine","text":"<p>Complete governance workflow:</p> <pre><code>from lacuna.engine import GovernanceEngine\nfrom lacuna.models import DataOperation, OperationType, UserContext\n\n# Initialize engine\nengine = GovernanceEngine()\n\n# Define operation\noperation = DataOperation(\n    operation_type=OperationType.EXPORT,\n    source_resources=[\"customers.csv\"],\n    destination_resource=\"/home/user/Downloads/export.csv\",\n    user_context=UserContext(\n        user_id=\"analyst@example.com\",\n        role=\"data_analyst\",\n        department=\"analytics\"\n    )\n)\n\n# Evaluate\nresult = engine.evaluate(operation)\n\nif result.allowed:\n    print(\"Operation allowed\")\nelse:\n    print(f\"Operation denied: {result.reasoning}\")\n    print(\"Alternatives:\")\n    for alt in result.alternatives:\n        print(f\"  - {alt}\")\n</code></pre>"},{"location":"api/python/#lineage-tracker","title":"Lineage Tracker","text":"<p>Track data dependencies:</p> <pre><code>from lacuna.lineage import LineageTracker\nfrom lacuna.models import DataOperation, OperationType\n\ntracker = LineageTracker()\n\n# Track an operation\noperation = DataOperation(\n    operation_type=OperationType.TRANSFORM,\n    source_resources=[\"customers.csv\", \"sales.csv\"],\n    destination_resource=\"customer_analysis.csv\"\n)\ntracker.track(operation)\n\n# Query lineage\nlineage = tracker.get_lineage(\"customer_analysis.csv\")\nprint(lineage.to_graph())\n\n# Get upstream dependencies\nupstream = tracker.get_upstream(\"customer_analysis.csv\", max_depth=5)\nprint(f\"Depends on {len(upstream)} resources\")\n\n# Get downstream impact\ndownstream = tracker.get_downstream(\"customers.csv\")\nprint(f\"Impacts {len(downstream)} resources\")\n</code></pre>"},{"location":"api/python/#policy-engine","title":"Policy Engine","text":"<p>Evaluate operations against policies:</p> <pre><code>from lacuna.policy import PolicyEngine\nfrom lacuna.models import DataTier, UserContext\n\nengine = PolicyEngine()\n\n# Evaluate export\nallowed = engine.evaluate_export(\n    data_tier=DataTier.PROPRIETARY,\n    destination=\"/home/user/Downloads/export.csv\",\n    user_context=UserContext(\n        user_id=\"analyst@example.com\",\n        role=\"data_analyst\"\n    )\n)\n\nprint(f\"Export allowed: {allowed}\")\n</code></pre>"},{"location":"api/python/#audit-logger","title":"Audit Logger","text":"<p>Query audit logs:</p> <pre><code>from lacuna.audit import AuditLogger\nfrom datetime import datetime, timedelta\n\nlogger = AuditLogger()\n\n# Query logs\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=30)\n\nlogs = logger.query(\n    user_id=\"analyst@example.com\",\n    start_date=start_date,\n    end_date=end_date,\n    operation_types=[\"READ\", \"EXPORT\"],\n    limit=100\n)\n\nfor log in logs:\n    print(f\"{log.timestamp}: {log.operation_type} on {log.resource}\")\n</code></pre>"},{"location":"api/python/#data-models","title":"Data Models","text":""},{"location":"api/python/#classification","title":"Classification","text":"<pre><code>from lacuna.models import Classification, DataTier\n\nclassification = Classification(\n    tier=DataTier.PROPRIETARY,\n    confidence=0.95,\n    tags=[\"PII\", \"GDPR\"],\n    reasoning=\"Contains personally identifiable information\"\n)\n</code></pre> <p>Fields:</p> <ul> <li><code>tier</code> - DataTier enum (PROPRIETARY, INTERNAL, PUBLIC)</li> <li><code>confidence</code> - float (0.0 to 1.0)</li> <li><code>tags</code> - List of classification tags</li> <li><code>reasoning</code> - String explaining the classification</li> </ul>"},{"location":"api/python/#dataoperation","title":"DataOperation","text":"<pre><code>from lacuna.models import DataOperation, OperationType, UserContext\n\noperation = DataOperation(\n    operation_type=OperationType.READ,\n    source_resources=[\"customers.csv\"],\n    destination_resource=\"analysis.csv\",\n    user_context=UserContext(\n        user_id=\"analyst@example.com\",\n        role=\"data_analyst\",\n        department=\"analytics\",\n        clearance_level=2\n    ),\n    purpose=\"Customer segmentation analysis\"\n)\n</code></pre> <p>OperationType Enum:</p> <ul> <li><code>READ</code> - Read data</li> <li><code>WRITE</code> - Write data</li> <li><code>DELETE</code> - Delete data</li> <li><code>EXPORT</code> - Export to external location</li> <li><code>QUERY</code> - Query database</li> <li><code>TRANSFORM</code> - Transform data</li> <li><code>JOIN</code> - Join datasets</li> <li><code>AGGREGATE</code> - Aggregate data</li> </ul>"},{"location":"api/python/#usercontext","title":"UserContext","text":"<pre><code>from lacuna.models import UserContext\n\ncontext = UserContext(\n    user_id=\"analyst@example.com\",\n    role=\"data_analyst\",\n    department=\"analytics\",\n    clearance_level=2,\n    session_id=\"session-123\",\n    ip_address=\"192.168.1.100\"\n)\n</code></pre>"},{"location":"api/python/#governanceresult","title":"GovernanceResult","text":"<pre><code>from lacuna.engine import GovernanceEngine\n\nresult = engine.evaluate(operation)\n\n# Fields\nprint(result.allowed)  # bool\nprint(result.reasoning)  # str\nprint(result.classification)  # Classification\nprint(result.policy_evaluation)  # PolicyEvaluation\nprint(result.alternatives)  # List[str]\nprint(result.latency_ms)  # float\n</code></pre>"},{"location":"api/python/#custom-classifiers","title":"Custom Classifiers","text":"<p>Extend the classification pipeline with custom logic:</p> <pre><code>from lacuna.classifier.base import Classifier\nfrom lacuna.models import Classification, DataTier\n\nclass CustomClassifier(Classifier):\n    \"\"\"Custom classifier for company-specific patterns.\"\"\"\n\n    def __init__(self):\n        super().__init__(priority=55)  # Between heuristic and embedding\n\n    def classify(self, query: str, **kwargs) -&gt; Classification:\n        # Custom classification logic\n        if \"project apollo\" in query.lower():\n            return Classification(\n                tier=DataTier.PROPRIETARY,\n                confidence=1.0,\n                tags=[\"PROJECT_APOLLO\", \"CONFIDENTIAL\"],\n                reasoning=\"Mentions classified project name\"\n            )\n\n        # Return None if can't classify\n        return None\n\n# Add to pipeline\nfrom lacuna.classifier import ClassificationPipeline\n\npipeline = ClassificationPipeline()\npipeline.add_classifier(CustomClassifier())\n</code></pre>"},{"location":"api/python/#configuration","title":"Configuration","text":""},{"location":"api/python/#settings","title":"Settings","text":"<pre><code>from lacuna.config import Settings\n\nsettings = Settings(\n    database_url=\"postgresql://user:pass@localhost/lacuna\",\n    redis_url=\"redis://localhost:6379/0\",\n    opa_url=\"http://localhost:8181\",\n    classification=ClassificationSettings(\n        strategy=\"comprehensive\",\n        confidence_threshold=0.75,\n        cache_ttl=300\n    ),\n    lineage=LineageSettings(\n        max_depth=10,\n        enable_tag_propagation=True\n    ),\n    audit=AuditSettings(\n        retention_days=2555  # 7 years\n    )\n)\n</code></pre>"},{"location":"api/python/#environment-variables","title":"Environment Variables","text":"<pre><code>import os\nfrom lacuna.config import Settings\n\n# Set environment variables\nos.environ[\"DATABASE_URL\"] = \"postgresql://...\"\nos.environ[\"REDIS_URL\"] = \"redis://...\"\n\n# Settings will auto-load from environment\nsettings = Settings()\n</code></pre>"},{"location":"api/python/#async-support","title":"Async Support","text":"<p>Most operations support async execution:</p> <pre><code>import asyncio\nfrom lacuna.classifier import AsyncClassificationPipeline\n\nasync def classify_batch():\n    pipeline = AsyncClassificationPipeline()\n\n    queries = [\n        \"Show me customer emails\",\n        \"Get sales data\",\n        \"Export financial reports\"\n    ]\n\n    # Classify concurrently\n    tasks = [pipeline.classify(q) for q in queries]\n    results = await asyncio.gather(*tasks)\n\n    for query, result in zip(queries, results):\n        print(f\"{query}: {result.tier}\")\n\n# Run\nasyncio.run(classify_batch())\n</code></pre>"},{"location":"api/python/#error-handling","title":"Error Handling","text":"<pre><code>from lacuna.exceptions import (\n    ClassificationError,\n    PolicyViolation,\n    LineageError,\n    AuditError\n)\n\ntry:\n    result = engine.evaluate(operation)\nexcept PolicyViolation as e:\n    print(f\"Policy violation: {e.message}\")\n    print(f\"Policy: {e.policy_id}\")\n    print(f\"Alternatives: {e.alternatives}\")\nexcept ClassificationError as e:\n    print(f\"Classification failed: {e.message}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"api/python/#examples","title":"Examples","text":"<p>See the <code>examples/</code> directory for complete examples:</p> <ul> <li><code>basic_classification.py</code> - Simple classification</li> <li><code>governance_workflow.py</code> - Complete governance workflow</li> <li><code>lineage_tracking.py</code> - Lineage tracking</li> <li><code>audit_logging.py</code> - Audit log queries</li> <li><code>custom_classifier.py</code> - Custom classifier implementation</li> <li><code>batch_classification.py</code> - Batch operations</li> </ul>"},{"location":"api/python/#next-steps","title":"Next Steps","text":"<ul> <li>REST API Reference - HTTP API documentation</li> <li>Plugin Development - Extend Lacuna</li> <li>Integration Guide - Platform integrations</li> </ul>"},{"location":"api/rest/","title":"REST API Reference","text":"<p>Lacuna provides a comprehensive REST API for integration with external systems.</p>"},{"location":"api/rest/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000/api/v1\n</code></pre> <p>All API endpoints are prefixed with <code>/api/v1</code>.</p>"},{"location":"api/rest/#authentication","title":"Authentication","text":"<p>Lacuna uses API key authentication for programmatic access:</p> <pre><code># Include API key in Authorization header\ncurl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  http://localhost:8000/api/v1/classify\n</code></pre> <p>To generate an API key, use the admin dashboard or CLI:</p> <pre><code>lacuna admin create-api-key --user analyst@example.com\n</code></pre>"},{"location":"api/rest/#endpoints","title":"Endpoints","text":""},{"location":"api/rest/#classification","title":"Classification","text":""},{"location":"api/rest/#classify-data","title":"Classify Data","text":"<p>Classify a query or data for sensitivity:</p> <pre><code>POST /api/v1/classify\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"query\": \"Show me all customer emails and SSNs\",\n  \"context\": {\n    \"user_id\": \"analyst@example.com\",\n    \"department\": \"analytics\"\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"tier\": \"PROPRIETARY\",\n  \"confidence\": 0.95,\n  \"tags\": [\"PII\", \"GDPR\", \"SSN\"],\n  \"reasoning\": \"Contains personally identifiable information (email, SSN)\",\n  \"classifier_used\": \"heuristic\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/classify \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"Show me all customer emails\",\n    \"context\": {\"user_id\": \"analyst@example.com\"}\n  }'\n</code></pre>"},{"location":"api/rest/#governance-evaluation","title":"Governance Evaluation","text":""},{"location":"api/rest/#evaluate-operation","title":"Evaluate Operation","text":"<p>Evaluate whether a data operation is allowed:</p> <pre><code>POST /api/v1/evaluate\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"operation_type\": \"EXPORT\",\n  \"source_resources\": [\"customers.csv\"],\n  \"destination_resource\": \"/home/user/Downloads/export.csv\",\n  \"user_context\": {\n    \"user_id\": \"analyst@example.com\",\n    \"role\": \"data_analyst\",\n    \"department\": \"analytics\"\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"allowed\": false,\n  \"reasoning\": \"Cannot export PII data to unmanaged location\",\n  \"classification\": {\n    \"tier\": \"PROPRIETARY\",\n    \"tags\": [\"PII\", \"GDPR\"]\n  },\n  \"policy_evaluation\": {\n    \"policy_id\": \"P-2024-001\",\n    \"policy_name\": \"PII Export Restrictions\"\n  },\n  \"alternatives\": [\n    \"Use anonymized version: anonymize(data, ['email', 'ssn'])\",\n    \"Save to governed location: /governed/workspace/\",\n    \"Request exception: https://governance.example.com/exception\"\n  ]\n}\n</code></pre>"},{"location":"api/rest/#lineage","title":"Lineage","text":""},{"location":"api/rest/#get-lineage","title":"Get Lineage","text":"<p>Get lineage graph for a resource:</p> <pre><code>GET /api/v1/lineage/{resource_id}\n</code></pre> <p>Parameters:</p> <ul> <li><code>resource_id</code> (path) - Resource identifier (e.g., \"customer_analysis.csv\")</li> <li><code>depth</code> (query, optional) - Maximum depth to traverse (default: 10)</li> <li><code>direction</code> (query, optional) - \"upstream\", \"downstream\", or \"both\" (default: \"both\")</li> </ul> <p>Response:</p> <pre><code>{\n  \"resource_id\": \"customer_analysis.csv\",\n  \"classification\": {\n    \"tier\": \"PROPRIETARY\",\n    \"tags\": [\"PII\", \"GDPR\"]\n  },\n  \"upstream\": [\n    {\n      \"resource_id\": \"customers.csv\",\n      \"classification\": {\"tier\": \"PROPRIETARY\", \"tags\": [\"PII\"]},\n      \"operation\": \"READ\",\n      \"timestamp\": \"2025-01-20T10:30:00Z\"\n    }\n  ],\n  \"downstream\": [],\n  \"depth\": 1\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/api/v1/lineage/customer_analysis.csv?depth=5\n</code></pre>"},{"location":"api/rest/#get-upstream-lineage","title":"Get Upstream Lineage","text":"<p>Get all upstream dependencies:</p> <pre><code>POST /api/v1/lineage/upstream\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"resource_id\": \"customer_analysis.csv\",\n  \"max_depth\": 10\n}\n</code></pre>"},{"location":"api/rest/#get-downstream-impact","title":"Get Downstream Impact","text":"<p>Get all downstream dependencies:</p> <pre><code>POST /api/v1/lineage/downstream\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"resource_id\": \"customers.csv\",\n  \"max_depth\": 10\n}\n</code></pre>"},{"location":"api/rest/#audit-logs","title":"Audit Logs","text":""},{"location":"api/rest/#query-audit-logs","title":"Query Audit Logs","text":"<p>Retrieve audit logs with filters:</p> <pre><code>POST /api/v1/audit/query\n</code></pre> <p>Request Body:</p> <pre><code>{\n  \"user_id\": \"analyst@example.com\",\n  \"start_date\": \"2025-01-01T00:00:00Z\",\n  \"end_date\": \"2025-01-31T23:59:59Z\",\n  \"operation_types\": [\"READ\", \"EXPORT\"],\n  \"allowed_only\": false,\n  \"limit\": 100,\n  \"offset\": 0\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"total\": 1247,\n  \"records\": [\n    {\n      \"id\": \"audit-123\",\n      \"timestamp\": \"2025-01-20T10:30:00Z\",\n      \"user_id\": \"analyst@example.com\",\n      \"operation_type\": \"EXPORT\",\n      \"resource\": \"customers.csv\",\n      \"allowed\": false,\n      \"classification\": {\n        \"tier\": \"PROPRIETARY\",\n        \"tags\": [\"PII\"]\n      },\n      \"reasoning\": \"Cannot export PII to unmanaged location\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api/rest/#get-audit-logs","title":"Get Audit Logs","text":"<p>Simple retrieval with pagination:</p> <pre><code>GET /api/v1/audit/logs\n</code></pre> <p>Parameters:</p> <ul> <li><code>limit</code> (query, optional) - Records per page (default: 100, max: 1000)</li> <li><code>offset</code> (query, optional) - Starting record (default: 0)</li> <li><code>user_id</code> (query, optional) - Filter by user</li> </ul> <p>Example:</p> <pre><code>curl \"http://localhost:8000/api/v1/audit/logs?limit=50&amp;user_id=analyst@example.com\"\n</code></pre>"},{"location":"api/rest/#health-checks","title":"Health Checks","text":""},{"location":"api/rest/#health-check","title":"Health Check","text":"<p>Basic health check:</p> <pre><code>GET /api/v1/health\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"version\": \"2025.1.42\",\n  \"timestamp\": \"2025-01-20T10:30:00Z\"\n}\n</code></pre>"},{"location":"api/rest/#readiness-check","title":"Readiness Check","text":"<p>Check if all services are ready:</p> <pre><code>GET /api/v1/health/ready\n</code></pre> <p>Response:</p> <pre><code>{\n  \"ready\": true,\n  \"services\": {\n    \"database\": \"connected\",\n    \"redis\": \"connected\",\n    \"opa\": \"connected\"\n  }\n}\n</code></pre>"},{"location":"api/rest/#error-handling","title":"Error Handling","text":"<p>All errors follow a consistent format:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_NOT_FOUND\",\n    \"message\": \"Resource 'unknown.csv' not found in lineage\",\n    \"details\": {\n      \"resource_id\": \"unknown.csv\"\n    }\n  }\n}\n</code></pre>"},{"location":"api/rest/#common-error-codes","title":"Common Error Codes","text":"Code HTTP Status Description <code>VALIDATION_ERROR</code> 400 Invalid request parameters <code>AUTHENTICATION_REQUIRED</code> 401 Missing or invalid API key <code>FORBIDDEN</code> 403 Insufficient permissions <code>RESOURCE_NOT_FOUND</code> 404 Resource doesn't exist <code>CLASSIFICATION_FAILED</code> 500 Classification pipeline error <code>POLICY_EVALUATION_FAILED</code> 500 Policy engine error"},{"location":"api/rest/#rate-limiting","title":"Rate Limiting","text":"<p>API requests are rate-limited:</p> <ul> <li>Authenticated: 1000 requests/hour</li> <li>Unauthenticated: 100 requests/hour</li> </ul> <p>Rate limit headers are included in responses:</p> <pre><code>X-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 987\nX-RateLimit-Reset: 1642694400\n</code></pre>"},{"location":"api/rest/#interactive-documentation","title":"Interactive Documentation","text":"<p>Lacuna provides interactive API documentation via Swagger UI:</p> <ul> <li>Swagger UI: http://localhost:8000/docs</li> <li>ReDoc: http://localhost:8000/redoc</li> </ul>"},{"location":"api/rest/#client-libraries","title":"Client Libraries","text":""},{"location":"api/rest/#python","title":"Python","text":"<pre><code>import requests\n\nclass LacunaClient:\n    def __init__(self, base_url=\"http://localhost:8000\", api_key=None):\n        self.base_url = base_url\n        self.headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n\n    def classify(self, query, context=None):\n        response = requests.post(\n            f\"{self.base_url}/api/v1/classify\",\n            json={\"query\": query, \"context\": context},\n            headers=self.headers\n        )\n        response.raise_for_status()\n        return response.json()\n\n    def evaluate(self, operation):\n        response = requests.post(\n            f\"{self.base_url}/api/v1/evaluate\",\n            json=operation,\n            headers=self.headers\n        )\n        response.raise_for_status()\n        return response.json()\n\n# Usage\nclient = LacunaClient(api_key=\"your-api-key\")\nresult = client.classify(\"Show me customer emails\")\nprint(result[\"tier\"])\n</code></pre> <p>See <code>examples/api_client.py</code> for a complete example.</p>"},{"location":"api/rest/#curl","title":"cURL","text":"<pre><code>#!/bin/bash\nAPI_KEY=\"your-api-key\"\nBASE_URL=\"http://localhost:8000/api/v1\"\n\n# Classify\ncurl -X POST \"$BASE_URL/classify\" \\\n  -H \"Authorization: Bearer $API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"Show me customer emails\"}'\n\n# Evaluate\ncurl -X POST \"$BASE_URL/evaluate\" \\\n  -H \"Authorization: Bearer $API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"operation_type\": \"EXPORT\",\n    \"source_resources\": [\"customers.csv\"],\n    \"user_context\": {\"user_id\": \"analyst@example.com\"}\n  }'\n</code></pre>"},{"location":"api/rest/#next-steps","title":"Next Steps","text":"<ul> <li>Python SDK Reference - Python API documentation</li> <li>Integration Guide - Platform integrations</li> <li>Examples - Code examples</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Multiple installation options for different use cases.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9, 3.10, 3.11, or 3.12</li> <li>pip (Python package installer)</li> </ul>"},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"getting-started/installation/#from-source-recommended-for-development","title":"From Source (Recommended for Development)","text":"<pre><code># Clone the repository\ngit clone https://github.com/witlox/lacuna.git\ncd lacuna\n\n# Install in development mode\npip install -e .\n\n# Install with development dependencies\npip install -e \".[dev]\"\n\n# Install with documentation dependencies\npip install -e \".[docs]\"\n</code></pre>"},{"location":"getting-started/installation/#from-pypi","title":"From PyPI","text":"<pre><code># Basic installation\npip install lacuna\n\n# With specific features\npip install lacuna[dev]\npip install lacuna[docs]\n</code></pre>"},{"location":"getting-started/installation/#using-docker","title":"Using Docker","text":"<pre><code># Pull the latest image\ndocker pull ghcr.io/witlox/lacuna:latest\n\n# Run with default settings\ndocker run -d -p 8000:8000 ghcr.io/witlox/lacuna:latest\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Lacuna has several optional dependency groups for different features:</p>"},{"location":"getting-started/installation/#development-tools","title":"Development Tools","text":"<pre><code>pip install lacuna[dev]\n</code></pre> <p>Includes: pytest, black, ruff, mypy, pre-commit</p>"},{"location":"getting-started/installation/#documentation","title":"Documentation","text":"<pre><code>pip install lacuna[docs]\n</code></pre> <p>Includes: mkdocs, mkdocs-material</p>"},{"location":"getting-started/installation/#rag-framework-integrations","title":"RAG Framework Integrations","text":"<pre><code># LlamaIndex\npip install lacuna[llamaindex]\n\n# LangChain\npip install lacuna[langchain]\n\n# Both\npip install lacuna[llamaindex,langchain]\n</code></pre>"},{"location":"getting-started/installation/#vector-database-backends","title":"Vector Database Backends","text":"<pre><code># ChromaDB\npip install lacuna[chromadb]\n\n# Milvus\npip install lacuna[milvus]\n</code></pre>"},{"location":"getting-started/installation/#classification-plugins","title":"Classification Plugins","text":"<pre><code># Individual users (basic PII detection)\npip install lacuna[plugins-individual]\n\n# Enterprise (includes OPA)\npip install lacuna[plugins-enterprise]\n\n# Healthcare (includes medical NER)\npip install lacuna[plugins-healthcare]\n\n# Finance\npip install lacuna[plugins-finance]\n\n# All plugins\npip install lacuna[plugins-all]\n</code></pre>"},{"location":"getting-started/installation/#complete-installation","title":"Complete Installation","text":"<p>Install everything:</p> <pre><code>pip install lacuna[all]\n</code></pre>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>Verify the installation:</p> <pre><code># Check version\nlacuna --version\n\n# Check available commands\nlacuna --help\n</code></pre>"},{"location":"getting-started/installation/#external-dependencies","title":"External Dependencies","text":"<p>Depending on your deployment mode, you may need:</p>"},{"location":"getting-started/installation/#development-mode","title":"Development Mode","text":"<p>No external dependencies required. Uses:</p> <ul> <li>SQLite (bundled with Python)</li> <li>In-memory cache</li> </ul>"},{"location":"getting-started/installation/#production-mode","title":"Production Mode","text":"<p>Recommended external services:</p> <ul> <li>PostgreSQL 13+ - Primary database</li> <li>Redis 6+ - Caching layer</li> <li>Open Policy Agent (OPA) - Policy engine (optional)</li> </ul>"},{"location":"getting-started/installation/#installing-external-dependencies","title":"Installing External Dependencies","text":""},{"location":"getting-started/installation/#postgresql","title":"PostgreSQL","text":"Ubuntu/DebianmacOSDocker <pre><code>sudo apt-get update\nsudo apt-get install postgresql postgresql-contrib\n</code></pre> <pre><code>brew install postgresql@15\nbrew services start postgresql@15\n</code></pre> <pre><code>docker run -d \\\n  --name lacuna-postgres \\\n  -e POSTGRES_PASSWORD=lacuna \\\n  -e POSTGRES_DB=lacuna \\\n  -p 5432:5432 \\\n  postgres:15\n</code></pre>"},{"location":"getting-started/installation/#redis","title":"Redis","text":"Ubuntu/DebianmacOSDocker <pre><code>sudo apt-get install redis-server\nsudo systemctl start redis\n</code></pre> <pre><code>brew install redis\nbrew services start redis\n</code></pre> <pre><code>docker run -d \\\n  --name lacuna-redis \\\n  -p 6379:6379 \\\n  redis:7-alpine\n</code></pre>"},{"location":"getting-started/installation/#open-policy-agent-optional","title":"Open Policy Agent (Optional)","text":"DockerBinary <pre><code>docker run -d \\\n  --name lacuna-opa \\\n  -p 8181:8181 \\\n  openpolicyagent/opa:latest \\\n  run --server\n</code></pre> <pre><code># Download OPA\ncurl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64\nchmod +x opa\n\n# Run server\n./opa run --server\n</code></pre>"},{"location":"getting-started/installation/#configuration","title":"Configuration","text":"<p>After installation, configure Lacuna:</p> <pre><code># Copy example config\ncp config/example.env .env\n\n# Edit configuration\nnano .env\n</code></pre> <p>Key settings:</p> <pre><code># Database\nDATABASE_URL=postgresql://user:password@localhost/lacuna\n\n# Redis\nREDIS_URL=redis://localhost:6379/0\n\n# OPA (optional)\nOPA_URL=http://localhost:8181\n\n# Classification\nOPENAI_API_KEY=your-key-here  # For LLM classification layer\n</code></pre> <p>See the Deployment Guide for detailed configuration options.</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Get up and running</li> <li>User Guide - Learn the features</li> <li>Deployment Guide - Production setup</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get Lacuna running in minutes with development mode or deploy to production.</p>"},{"location":"getting-started/quick-start/#development-mode","title":"Development Mode","text":"<p>The fastest way to try Lacuna locally with zero external dependencies:</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9 or higher</li> <li>pip</li> </ul>"},{"location":"getting-started/quick-start/#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone https://github.com/witlox/lacuna.git\ncd lacuna\n\n# Install in development mode\npip install -e .\n</code></pre>"},{"location":"getting-started/quick-start/#start-the-server","title":"Start the Server","text":"<pre><code># Start in dev mode (uses SQLite, no external dependencies)\nlacuna dev\n</code></pre> <p>This starts Lacuna with:</p> <ul> <li>SQLite database (no PostgreSQL needed)</li> <li>In-memory cache (no Redis needed)</li> <li>Built-in policies (no OPA needed)</li> <li>Auto-reload on code changes</li> </ul>"},{"location":"getting-started/quick-start/#access-the-interfaces","title":"Access the Interfaces","text":"<p>Once started, you can access:</p> <ul> <li>API Documentation: http://127.0.0.1:8000/docs</li> <li>User Dashboard: http://127.0.0.1:8000/user/dashboard</li> <li>Admin Dashboard: http://127.0.0.1:8000/admin/</li> </ul>"},{"location":"getting-started/quick-start/#your-first-classification","title":"Your First Classification","text":"<p>Try classifying some data using the Python SDK:</p> <pre><code>from lacuna.classifier import ClassificationPipeline\nfrom lacuna.models import Classification\n\n# Initialize the classifier\npipeline = ClassificationPipeline()\n\n# Classify a query\nquery = \"Show me all customer emails and social security numbers\"\nclassification = pipeline.classify(query)\n\nprint(f\"Tier: {classification.tier}\")\nprint(f\"Confidence: {classification.confidence}\")\nprint(f\"Tags: {classification.tags}\")\nprint(f\"Reasoning: {classification.reasoning}\")\n</code></pre> <p>Expected output:</p> <pre><code>Tier: PROPRIETARY\nConfidence: 0.95\nTags: ['PII', 'GDPR', 'SSN']\nReasoning: Contains personally identifiable information (email, SSN)\n</code></pre>"},{"location":"getting-started/quick-start/#track-lineage","title":"Track Lineage","text":"<p>Track data dependencies through operations:</p> <pre><code>from lacuna.lineage import LineageTracker\nfrom lacuna.models import DataOperation, OperationType, UserContext\n\n# Initialize tracker\ntracker = LineageTracker()\n\n# Record a data operation\noperation = DataOperation(\n    operation_type=OperationType.READ,\n    source_resources=[\"customers.csv\"],\n    destination_resource=\"customer_analysis.csv\",\n    user_context=UserContext(\n        user_id=\"analyst@example.com\",\n        role=\"data_analyst\",\n        department=\"analytics\"\n    )\n)\n\n# Track the operation\ntracker.track(operation)\n\n# Query lineage\nlineage = tracker.get_lineage(\"customer_analysis.csv\")\nprint(lineage.to_graph())\n</code></pre>"},{"location":"getting-started/quick-start/#evaluate-policies","title":"Evaluate Policies","text":"<p>Check if an operation is allowed:</p> <pre><code>from lacuna.engine import GovernanceEngine\nfrom lacuna.models import DataOperation, OperationType, UserContext\n\n# Initialize engine\nengine = GovernanceEngine()\n\n# Define an operation\noperation = DataOperation(\n    operation_type=OperationType.EXPORT,\n    source_resources=[\"customers.csv\"],\n    destination_resource=\"/home/user/Downloads/export.csv\",\n    user_context=UserContext(\n        user_id=\"analyst@example.com\",\n        role=\"data_analyst\"\n    )\n)\n\n# Evaluate\nresult = engine.evaluate(operation)\n\nprint(f\"Allowed: {result.allowed}\")\nprint(f\"Reasoning: {result.reasoning}\")\nif not result.allowed and result.alternatives:\n    print(\"Alternatives:\")\n    for alt in result.alternatives:\n        print(f\"  - {alt}\")\n</code></pre>"},{"location":"getting-started/quick-start/#run-the-examples","title":"Run the Examples","text":"<p>The <code>examples/</code> directory contains runnable scripts:</p> <pre><code># Start the dev server in the background\nlacuna dev &amp;\n\n# Run examples\npython examples/basic_classification.py\npython examples/lineage_tracking.py\npython examples/policy_evaluation.py\npython examples/audit_logging.py\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>User Guide - Learn about all features</li> <li>Architecture - Understand how it works</li> <li>Deployment Guide - Deploy to production</li> <li>Development Guide - Contribute to Lacuna</li> </ul>"},{"location":"getting-started/quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quick-start/#port-already-in-use","title":"Port Already in Use","text":"<p>If port 8000 is already in use:</p> <pre><code>lacuna dev --port 8001\n</code></pre>"},{"location":"getting-started/quick-start/#import-errors","title":"Import Errors","text":"<p>Make sure you installed in development mode:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"getting-started/quick-start/#database-issues","title":"Database Issues","text":"<p>Development mode uses SQLite. If you encounter database issues:</p> <pre><code># Remove the dev database\nrm lacuna_dev.db\n\n# Restart\nlacuna dev\n</code></pre> <p>For more help, see the User Guide or open an issue.</p>"}]}